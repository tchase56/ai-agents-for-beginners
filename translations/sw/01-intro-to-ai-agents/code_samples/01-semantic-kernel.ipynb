{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel ya Semantiki\n",
    "\n",
    "Katika mfano huu wa msimbo, utatumia Mfumo wa AI wa [Kernel ya Semantiki](https://aka.ms/ai-agents-beginners/semantic-kernel) kuunda wakala wa msingi.\n",
    "\n",
    "Lengo la mfano huu ni kukuonyesha hatua ambazo baadaye tutatumia katika mifano mingine ya msimbo tunapotekeleza mifumo tofauti ya kiwakala.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingiza Vifurushi vya Python Vinavyohitajika\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuunda Mteja\n",
    "\n",
    "Katika mfano huu, tutatumia [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) kwa ajili ya kupata LLM.\n",
    "\n",
    "`ai_model_id` imefafanuliwa kama `gpt-4o-mini`. Jaribu kubadilisha mfano huu na kutumia modeli nyingine inayopatikana kwenye soko la GitHub Models ili kuona matokeo tofauti.\n",
    "\n",
    "Ili tuweze kutumia `Azure Inference SDK` ambayo inatumika kwa `base_url` ya GitHub Models, tutatumia kiunganishi cha `OpenAIChatCompletion` ndani ya Semantic Kernel. Pia kuna [viunganishi vingine vinavyopatikana](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) vya kutumia Semantic Kernel kwa watoa huduma wengine wa modeli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuunda Wakala\n",
    "\n",
    "Hapa tunaunda Wakala anayeitwa `TravelAgent`.\n",
    "\n",
    "Kwa mfano huu, tunatumia maagizo rahisi sana. Unaweza kubadilisha maagizo haya ili kuona jinsi wakala anavyojibu kwa njia tofauti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuendesha Wakala\n",
    "\n",
    "Sasa tunaweza kuendesha Wakala kwa kufafanua thread ya aina `ChatHistoryAgentThread`. Ujumbe wowote wa mfumo unaohitajika hutolewa kwa neno la msingi `messages` la invoke_stream ya wakala.\n",
    "\n",
    "Baada ya haya kufafanuliwa, tunaunda `user_inputs` ambayo itakuwa kile mtumiaji anachotuma kwa wakala. Katika hali hii, tumeweka ujumbe huu kuwa `Plan me a sunny vacation`.\n",
    "\n",
    "Jisikie huru kubadilisha ujumbe huu ili kuona jinsi wakala anavyojibu kwa njia tofauti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Kanusho**:  \nHati hii imetafsiriwa kwa kutumia huduma ya kutafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kuhakikisha usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo cha mamlaka. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa kutoelewana au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T21:29:08+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "sw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}