<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-08-30T14:10:20+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "pt"
}
-->
# Agentes de IA em Produ√ß√£o: Observabilidade e Avalia√ß√£o

[![Agentes de IA em Produ√ß√£o](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.pt.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

√Ä medida que os agentes de IA passam de prot√≥tipos experimentais para aplica√ß√µes no mundo real, torna-se essencial compreender o seu comportamento, monitorizar o seu desempenho e avaliar sistematicamente os seus resultados.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, saber√° como/entender√°:
- Conceitos fundamentais de observabilidade e avalia√ß√£o de agentes
- T√©cnicas para melhorar o desempenho, os custos e a efic√°cia dos agentes
- O que avaliar e como avaliar sistematicamente os seus agentes de IA
- Como controlar os custos ao implementar agentes de IA em produ√ß√£o
- Como instrumentar agentes constru√≠dos com AutoGen

O objetivo √© equip√°-lo com o conhecimento necess√°rio para transformar os seus agentes de "caixa preta" em sistemas transparentes, ger√≠veis e confi√°veis.

_**Nota:** √â importante implementar agentes de IA que sejam seguros e confi√°veis. Consulte tamb√©m a li√ß√£o [Construir Agentes de IA Confi√°veis](./06-building-trustworthy-agents/README.md)._

## Tra√ßos e Spans

Ferramentas de observabilidade como [Langfuse](https://langfuse.com/) ou [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) geralmente representam as execu√ß√µes de agentes como tra√ßos e spans.

- **Tra√ßo** representa uma tarefa completa do agente do in√≠cio ao fim (como lidar com uma consulta de utilizador).
- **Spans** s√£o passos individuais dentro do tra√ßo (como chamar um modelo de linguagem ou recuperar dados).

![√Årvore de tra√ßos no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sem observabilidade, um agente de IA pode parecer uma "caixa preta" - o seu estado interno e racioc√≠nio s√£o opacos, dificultando o diagn√≥stico de problemas ou a otimiza√ß√£o do desempenho. Com a observabilidade, os agentes tornam-se "caixas de vidro", oferecendo a transpar√™ncia vital para construir confian√ßa e garantir que operam conforme o esperado.

## Por que a Observabilidade √© Importante em Ambientes de Produ√ß√£o

A transi√ß√£o de agentes de IA para ambientes de produ√ß√£o introduz um novo conjunto de desafios e requisitos. A observabilidade deixa de ser um "luxo" e torna-se uma capacidade cr√≠tica:

*   **Depura√ß√£o e An√°lise de Causa Raiz**: Quando um agente falha ou produz um resultado inesperado, as ferramentas de observabilidade fornecem os tra√ßos necess√°rios para identificar a origem do erro. Isto √© especialmente importante em agentes complexos que podem envolver m√∫ltiplas chamadas a LLMs, intera√ß√µes com ferramentas e l√≥gica condicional.
*   **Gest√£o de Lat√™ncia e Custos**: Os agentes de IA frequentemente dependem de LLMs e outras APIs externas que s√£o cobradas por token ou por chamada. A observabilidade permite o rastreamento preciso dessas chamadas, ajudando a identificar opera√ß√µes excessivamente lentas ou caras. Isto permite √†s equipas otimizar prompts, selecionar modelos mais eficientes ou redesenhar fluxos de trabalho para gerir custos operacionais e garantir uma boa experi√™ncia do utilizador.
*   **Confian√ßa, Seguran√ßa e Conformidade**: Em muitas aplica√ß√µes, √© importante garantir que os agentes se comportam de forma segura e √©tica. A observabilidade fornece um registo de auditoria das a√ß√µes e decis√µes do agente. Isto pode ser usado para detetar e mitigar problemas como inje√ß√£o de prompts, gera√ß√£o de conte√∫do prejudicial ou tratamento inadequado de informa√ß√µes pessoalmente identific√°veis (PII). Por exemplo, pode rever tra√ßos para entender por que um agente forneceu uma determinada resposta ou utilizou uma ferramenta espec√≠fica.
*   **Ciclos de Melhoria Cont√≠nua**: Os dados de observabilidade s√£o a base de um processo de desenvolvimento iterativo. Ao monitorizar como os agentes se comportam no mundo real, as equipas podem identificar √°reas de melhoria, recolher dados para ajustar modelos e validar o impacto das altera√ß√µes. Isto cria um ciclo de feedback onde os insights de produ√ß√£o da avalia√ß√£o online informam a experimenta√ß√£o offline e o refinamento, levando a um desempenho progressivamente melhor dos agentes.

## M√©tricas-Chave a Monitorizar

Para monitorizar e compreender o comportamento dos agentes, deve-se acompanhar uma s√©rie de m√©tricas e sinais. Embora as m√©tricas espec√≠ficas possam variar consoante o prop√≥sito do agente, algumas s√£o universalmente importantes.

Aqui est√£o algumas das m√©tricas mais comuns monitorizadas por ferramentas de observabilidade:

**Lat√™ncia:** Com que rapidez o agente responde? Tempos de espera longos impactam negativamente a experi√™ncia do utilizador. Deve medir a lat√™ncia para tarefas e passos individuais, rastreando as execu√ß√µes do agente. Por exemplo, um agente que demora 20 segundos para todas as chamadas ao modelo poderia ser acelerado utilizando um modelo mais r√°pido ou executando chamadas ao modelo em paralelo.

**Custos:** Qual √© o custo por execu√ß√£o do agente? Os agentes de IA dependem de chamadas a LLMs cobradas por token ou APIs externas. O uso frequente de ferramentas ou m√∫ltiplos prompts pode aumentar rapidamente os custos. Por exemplo, se um agente chamar um LLM cinco vezes para uma melhoria marginal na qualidade, deve avaliar se o custo √© justificado ou se poderia reduzir o n√∫mero de chamadas ou usar um modelo mais barato. A monitoriza√ß√£o em tempo real tamb√©m pode ajudar a identificar picos inesperados (por exemplo, bugs que causam loops excessivos de API).

**Erros de Pedido:** Quantos pedidos o agente falhou? Isto pode incluir erros de API ou falhas em chamadas de ferramentas. Para tornar o seu agente mais robusto em produ√ß√£o, pode configurar alternativas ou tentativas de repeti√ß√£o. Por exemplo, se o fornecedor de LLM A estiver indispon√≠vel, pode alternar para o fornecedor de LLM B como backup.

**Feedback do Utilizador:** Implementar avalia√ß√µes diretas dos utilizadores fornece insights valiosos. Isto pode incluir classifica√ß√µes expl√≠citas (üëçpositivo/üëénegativo, ‚≠ê1-5 estrelas) ou coment√°rios textuais. Feedback negativo consistente deve alert√°-lo, pois √© um sinal de que o agente n√£o est√° a funcionar como esperado.

**Feedback Impl√≠cito do Utilizador:** Os comportamentos dos utilizadores fornecem feedback indireto, mesmo sem classifica√ß√µes expl√≠citas. Isto pode incluir reformula√ß√µes imediatas de perguntas, consultas repetidas ou cliques num bot√£o de tentativa novamente. Por exemplo, se notar que os utilizadores fazem repetidamente a mesma pergunta, isto √© um sinal de que o agente n√£o est√° a funcionar como esperado.

**Precis√£o:** Com que frequ√™ncia o agente produz resultados corretos ou desej√°veis? As defini√ß√µes de precis√£o variam (por exemplo, corre√ß√£o na resolu√ß√£o de problemas, precis√£o na recupera√ß√£o de informa√ß√µes, satisfa√ß√£o do utilizador). O primeiro passo √© definir o que significa sucesso para o seu agente. Pode monitorizar a precis√£o atrav√©s de verifica√ß√µes autom√°ticas, pontua√ß√µes de avalia√ß√£o ou etiquetas de conclus√£o de tarefas. Por exemplo, marcar tra√ßos como "bem-sucedidos" ou "falhados".

**M√©tricas de Avalia√ß√£o Autom√°tica:** Tamb√©m pode configurar avalia√ß√µes autom√°ticas. Por exemplo, pode usar um LLM para pontuar a sa√≠da do agente, avaliando se √© √∫til, precisa ou n√£o. Existem tamb√©m v√°rias bibliotecas open source que ajudam a pontuar diferentes aspetos do agente. Por exemplo, [RAGAS](https://docs.ragas.io/) para agentes RAG ou [LLM Guard](https://llm-guard.com/) para detetar linguagem prejudicial ou inje√ß√£o de prompts.

Na pr√°tica, uma combina√ß√£o destas m√©tricas oferece a melhor cobertura da sa√∫de de um agente de IA. No [notebook de exemplo](./code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo, mostraremos como estas m√©tricas aparecem em exemplos reais, mas primeiro aprenderemos como √© um fluxo de trabalho t√≠pico de avalia√ß√£o.

## Instrumentar o seu Agente

Para recolher dados de tra√ßos, precisar√° de instrumentar o seu c√≥digo. O objetivo √© instrumentar o c√≥digo do agente para emitir tra√ßos e m√©tricas que possam ser capturados, processados e visualizados por uma plataforma de observabilidade.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) tornou-se um padr√£o da ind√∫stria para observabilidade de LLMs. Fornece um conjunto de APIs, SDKs e ferramentas para gerar, recolher e exportar dados de telemetria.

Existem muitas bibliotecas de instrumenta√ß√£o que envolvem frameworks de agentes existentes e facilitam a exporta√ß√£o de spans do OpenTelemetry para uma ferramenta de observabilidade. Abaixo est√° um exemplo de instrumenta√ß√£o de um agente AutoGen com a biblioteca de instrumenta√ß√£o [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

O [notebook de exemplo](./code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo demonstrar√° como instrumentar o seu agente AutoGen.

**Cria√ß√£o Manual de Spans:** Embora as bibliotecas de instrumenta√ß√£o forne√ßam uma boa base, h√° casos em que informa√ß√µes mais detalhadas ou personalizadas s√£o necess√°rias. Pode criar spans manualmente para adicionar l√≥gica de aplica√ß√£o personalizada. Mais importante, pode enriquecer spans criados automaticamente ou manualmente com atributos personalizados (tamb√©m conhecidos como tags ou metadados). Estes atributos podem incluir dados espec√≠ficos do neg√≥cio, c√°lculos interm√©dios ou qualquer contexto que possa ser √∫til para depura√ß√£o ou an√°lise, como `user_id`, `session_id` ou `model_version`.

Exemplo de cria√ß√£o manual de tra√ßos e spans com o [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Avalia√ß√£o de Agentes

A observabilidade fornece m√©tricas, mas a avalia√ß√£o √© o processo de analisar esses dados (e realizar testes) para determinar qu√£o bem um agente de IA est√° a desempenhar e como pode ser melhorado. Em outras palavras, uma vez que tenha esses tra√ßos e m√©tricas, como os utiliza para julgar o agente e tomar decis√µes?

A avalia√ß√£o regular √© importante porque os agentes de IA s√£o frequentemente n√£o determin√≠sticos e podem evoluir (atrav√©s de atualiza√ß√µes ou altera√ß√µes no comportamento do modelo) ‚Äì sem avalia√ß√£o, n√£o saberia se o seu "agente inteligente" est√° realmente a fazer bem o seu trabalho ou se regrediu.

Existem duas categorias de avalia√ß√µes para agentes de IA: **avalia√ß√£o offline** e **avalia√ß√£o online**. Ambas s√£o valiosas e complementam-se. Normalmente, come√ßamos com a avalia√ß√£o offline, pois este √© o passo m√≠nimo necess√°rio antes de implementar qualquer agente.

### Avalia√ß√£o Offline

![Itens de dataset no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Isto envolve avaliar o agente num ambiente controlado, tipicamente utilizando datasets de teste, e n√£o consultas de utilizadores ao vivo. Utiliza datasets curados onde sabe qual √© o resultado esperado ou o comportamento correto e, em seguida, executa o agente nesses dados.

Por exemplo, se construiu um agente para resolver problemas matem√°ticos, pode ter um [dataset de teste](https://huggingface.co/datasets/gsm8k) com 100 problemas e respostas conhecidas. A avalia√ß√£o offline √© frequentemente realizada durante o desenvolvimento (e pode fazer parte de pipelines CI/CD) para verificar melhorias ou prevenir regress√µes. A vantagem √© que √© **repet√≠vel e pode obter m√©tricas de precis√£o claras, uma vez que tem uma verdade de base**. Tamb√©m pode simular consultas de utilizadores e medir as respostas do agente em rela√ß√£o √†s respostas ideais ou usar m√©tricas autom√°ticas, como descrito acima.

O principal desafio da avalia√ß√£o offline √© garantir que o seu dataset de teste seja abrangente e permane√ßa relevante ‚Äì o agente pode ter um bom desempenho num conjunto de testes fixo, mas encontrar consultas muito diferentes em produ√ß√£o. Portanto, deve manter os conjuntos de testes atualizados com novos casos extremos e exemplos que reflitam cen√°rios do mundo real. Uma mistura de pequenos casos de "teste r√°pido" e conjuntos de avalia√ß√£o maiores √© √∫til: conjuntos pequenos para verifica√ß√µes r√°pidas e maiores para m√©tricas de desempenho mais amplas.

### Avalia√ß√£o Online

![Vis√£o geral das m√©tricas de observabilidade](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Isto refere-se a avaliar o agente num ambiente ao vivo, no mundo real, ou seja, durante a utiliza√ß√£o real em produ√ß√£o. A avalia√ß√£o online envolve monitorizar o desempenho do agente em intera√ß√µes reais com utilizadores e analisar continuamente os resultados.

Por exemplo, pode monitorizar taxas de sucesso, pontua√ß√µes de satisfa√ß√£o do utilizador ou outras m√©tricas em tr√°fego ao vivo. A vantagem da avalia√ß√£o online √© que **captura coisas que pode n√£o antecipar num ambiente de laborat√≥rio** ‚Äì pode observar a deriva do modelo ao longo do tempo (se a efic√°cia do agente diminuir √† medida que os padr√µes de entrada mudam) e detetar consultas ou situa√ß√µes inesperadas que n√£o estavam nos seus dados de teste. Fornece uma imagem real de como o agente se comporta no mundo real.

A avalia√ß√£o online frequentemente envolve a recolha de feedback impl√≠cito e expl√≠cito dos utilizadores, como discutido, e possivelmente a realiza√ß√£o de testes sombra ou testes A/B (onde uma nova vers√£o do agente √© executada em paralelo para compara√ß√£o com a antiga). O desafio √© que pode ser complicado obter etiquetas ou pontua√ß√µes confi√°veis para intera√ß√µes ao vivo ‚Äì pode depender de feedback dos utilizadores ou m√©tricas a jusante (como se o utilizador clicou no resultado).

### Combinando as duas

As avalia√ß√µes online e offline n√£o s√£o mutuamente exclusivas; s√£o altamente complementares. Insights da monitoriza√ß√£o online (por exemplo, novos tipos de consultas de utilizadores onde o agente tem um desempenho fraco) podem ser usados para aumentar e melhorar os datasets de teste offline. Por outro lado, agentes que t√™m um bom desempenho em testes offline podem ser implementados e monitorizados online com mais confian√ßa.

De facto, muitas equipas adotam um ciclo:

_avaliar offline -> implementar -> monitorizar online -> recolher novos casos de falha -> adicionar ao dataset offline -> refinar agente -> repetir_.

## Problemas Comuns

Ao implementar agentes de IA em produ√ß√£o, pode encontrar v√°rios desafios. Aqui est√£o alguns problemas comuns e as suas potenciais solu√ß√µes:

| **Problema**    | **Solu√ß√£o Potencial**   |
| ------------- | ------------------ |
| Agente de IA n√£o realiza tarefas de forma consistente | - Refine o prompt dado ao agente de IA; seja claro nos objetivos.<br>- Identifique onde dividir as tarefas em subtarefas e deleg√°-las a m√∫ltiplos agentes pode ajudar. |
| Agente de IA entra em loops cont√≠nuos  | - Certifique-se de que tem termos e condi√ß√µes de termina√ß√£o claros para que o agente saiba quando parar o processo. |

## Resolu√ß√£o de Problemas Comuns

Aqui est√£o algumas estrat√©gias para resolver problemas comuns ao trabalhar com agentes de IA:

| **Problema**                                | **Solu√ß√µes**                                                                                                                                                                                                 |
|---------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| O modelo n√£o est√° a responder corretamente  | - Ajuste os prompts para serem mais claros e espec√≠ficos.<br>- Experimente diferentes modelos para ver qual funciona melhor para o seu caso de uso.<br>- Ajuste os par√¢metros do modelo para melhorar o desempenho. |
| O modelo n√£o est√° a raciocinar corretamente | - Para tarefas complexas que exigem racioc√≠nio e planeamento, utilize um modelo maior especializado em tarefas de racioc√≠nio.                                                                               |
| As ferramentas chamadas pelo agente n√£o est√£o a funcionar bem | - Teste e valide a sa√≠da da ferramenta fora do sistema do agente.<br>- Refine os par√¢metros definidos, os prompts e os nomes das ferramentas.                                                              |
| O sistema multi-agente n√£o est√° a funcionar de forma consistente | - Refine os prompts dados a cada agente para garantir que s√£o espec√≠ficos e distintos uns dos outros.<br>- Construa um sistema hier√°rquico utilizando um agente "roteador" ou controlador para determinar qual agente √© o mais adequado. |

Muitos destes problemas podem ser identificados de forma mais eficaz com a implementa√ß√£o de ferramentas de observabilidade. As m√©tricas e rastreamentos que discutimos anteriormente ajudam a identificar exatamente onde, no fluxo de trabalho do agente, os problemas ocorrem, tornando a depura√ß√£o e a otimiza√ß√£o muito mais eficientes.

## Gerir Custos

Aqui est√£o algumas estrat√©gias para gerir os custos de implementar agentes de IA em produ√ß√£o:

**Utilizar Modelos Menores:** Modelos de Linguagem Pequenos (SLMs) podem ter um bom desempenho em certos casos de uso agentivos e reduzir significativamente os custos. Como mencionado anteriormente, construir um sistema de avalia√ß√£o para determinar e comparar o desempenho em rela√ß√£o a modelos maiores √© a melhor forma de entender como um SLM se comportar√° no seu caso de uso. Considere usar SLMs para tarefas mais simples, como classifica√ß√£o de inten√ß√µes ou extra√ß√£o de par√¢metros, reservando os modelos maiores para racioc√≠nios mais complexos.

**Utilizar um Modelo Roteador:** Uma estrat√©gia semelhante √© usar uma diversidade de modelos e tamanhos. Pode utilizar um LLM/SLM ou uma fun√ß√£o serverless para encaminhar pedidos com base na complexidade para os modelos mais adequados. Isto tamb√©m ajudar√° a reduzir custos, garantindo ao mesmo tempo o desempenho nas tarefas certas. Por exemplo, encaminhe consultas simples para modelos menores e mais r√°pidos, e utilize apenas modelos grandes e dispendiosos para tarefas de racioc√≠nio complexo.

**Cachear Respostas:** Identificar pedidos e tarefas comuns e fornecer as respostas antes que passem pelo seu sistema agentivo √© uma boa forma de reduzir o volume de pedidos semelhantes. Pode at√© implementar um fluxo para identificar qu√£o semelhante um pedido √© em rela√ß√£o aos pedidos em cache, utilizando modelos de IA mais b√°sicos. Esta estrat√©gia pode reduzir significativamente os custos para perguntas frequentes ou fluxos de trabalho comuns.

## Vamos ver como isto funciona na pr√°tica

No [notebook de exemplo desta sec√ß√£o](./code_samples/10_autogen_evaluation.ipynb), veremos exemplos de como podemos usar ferramentas de observabilidade para monitorizar e avaliar o nosso agente.

### Tem Mais Perguntas sobre Agentes de IA em Produ√ß√£o?

Junte-se ao [Discord do Azure AI Foundry](https://aka.ms/ai-agents/discord) para conhecer outros aprendizes, participar em hor√°rios de atendimento e obter respostas √†s suas perguntas sobre Agentes de IA.

## Aula Anterior

[Design Pattern de Metacogni√ß√£o](../09-metacognition/README.md)

## Pr√≥xima Aula

[Protocolos Agentivos](../11-agentic-protocols/README.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original no seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.