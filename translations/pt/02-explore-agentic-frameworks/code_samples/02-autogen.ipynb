{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo Básico do AutoGen\n",
    "\n",
    "Neste exemplo de código, irá utilizar o [AutoGen](https://aka.ms/ai-agents/autogen) AI Framework para criar um agente básico.\n",
    "\n",
    "O objetivo deste exemplo é mostrar-lhe os passos que iremos usar mais tarde nos exemplos de código adicionais ao implementar os diferentes padrões de agentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar os Pacotes Necessários de Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o Cliente\n",
    "\n",
    "Neste exemplo, utilizaremos os [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) para aceder ao LLM.\n",
    "\n",
    "O `model` está definido como `gpt-4o-mini`. Experimente alterar o modelo para outro disponível no marketplace do GitHub Models para observar resultados diferentes.\n",
    "\n",
    "Como um teste rápido, vamos executar um prompt simples - `Qual é a capital de França`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir o Agente\n",
    "\n",
    "Agora que configurámos o `client` e confirmámos que está a funcionar, vamos criar um `AssistantAgent`. Cada agente pode ter atribuído:  \n",
    "**name** - Um nome curto que será útil para referenciá-lo em fluxos com múltiplos agentes.  \n",
    "**model_client** - O cliente que criaste no passo anterior.  \n",
    "**tools** - Ferramentas disponíveis que o Agente pode usar para completar uma tarefa.  \n",
    "**system_message** - O metaprompt que define a tarefa, o comportamento e o tom do LLM.  \n",
    "\n",
    "Podes alterar a system message para ver como o LLM responde. Vamos abordar as `tools` na Aula #4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar o Agente\n",
    "\n",
    "A função abaixo irá executar o agente. Utilizamos o método `on_message` para atualizar o estado do Agente com a nova mensagem.\n",
    "\n",
    "Neste caso, atualizamos o estado com uma nova mensagem do utilizador, que é `\"Planeia-me umas ótimas férias ensolaradas\"`.\n",
    "\n",
    "Pode alterar o conteúdo da mensagem para ver como o LLM responde de forma diferente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precisão, é importante ter em conta que traduções automáticas podem conter erros ou imprecisões. O documento original na sua língua nativa deve ser considerado a fonte autoritária. Para informações críticas, recomenda-se a tradução profissional realizada por humanos. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes da utilização desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:10:16+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}