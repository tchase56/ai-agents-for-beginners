{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podstawowy Przykład AutoGen\n",
    "\n",
    "W tym przykładzie kodu użyjesz [AutoGen](https://aka.ms/ai-agents/autogen), frameworka AI, aby stworzyć podstawowego agenta.\n",
    "\n",
    "Celem tego przykładu jest pokazanie kroków, które później wykorzystamy w dodatkowych przykładach kodu podczas implementacji różnych wzorców agentowych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importuj potrzebne pakiety Pythona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utwórz klienta\n",
    "\n",
    "W tym przykładzie użyjemy [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) do uzyskania dostępu do LLM.\n",
    "\n",
    "`model` jest zdefiniowany jako `gpt-4o-mini`. Spróbuj zmienić model na inny dostępny w marketplace GitHub Models, aby zobaczyć różne wyniki.\n",
    "\n",
    "Na szybki test uruchomimy prostą komendę - `What is the capital of France`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiowanie Agenta\n",
    "\n",
    "Teraz, gdy skonfigurowaliśmy `client` i potwierdziliśmy, że działa poprawnie, stwórzmy `AssistantAgent`. Każdemu agentowi można przypisać:  \n",
    "**name** - Krótką nazwę, która będzie przydatna do odwoływania się do niego w przepływach z wieloma agentami.  \n",
    "**model_client** - Klienta, którego utworzyłeś w poprzednim kroku.  \n",
    "**tools** - Dostępne narzędzia, które Agent może wykorzystać do wykonania zadania.  \n",
    "**system_message** - Metaprompt definiujący zadanie, zachowanie i ton LLM.  \n",
    "\n",
    "Możesz zmienić wiadomość systemową, aby zobaczyć, jak LLM zareaguje. Omówimy `tools` w Lekcji #4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uruchom Agenta\n",
    "\n",
    "Poniższa funkcja uruchomi agenta. Używamy metody `on_message`, aby zaktualizować stan Agenta o nową wiadomość.\n",
    "\n",
    "W tym przypadku aktualizujemy stan o nową wiadomość od użytkownika, która brzmi: `\"Zaplanuj mi świetne, słoneczne wakacje\"`.\n",
    "\n",
    "Możesz zmienić treść wiadomości, aby zobaczyć, jak LLM odpowiada w różny sposób.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Zastrzeżenie**:  \nTen dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby zapewnić dokładność, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za wiarygodne źródło. W przypadku informacji o kluczowym znaczeniu zaleca się skorzystanie z profesjonalnego tłumaczenia przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:10:31+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "pl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}