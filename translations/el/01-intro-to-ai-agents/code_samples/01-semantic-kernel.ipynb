{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Σημασιολογικός Πυρήνας\n",
    "\n",
    "Σε αυτό το παράδειγμα κώδικα, θα χρησιμοποιήσετε το [Semantic Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) AI Framework για να δημιουργήσετε έναν βασικό πράκτορα.\n",
    "\n",
    "Ο στόχος αυτού του παραδείγματος είναι να σας δείξει τα βήματα που θα χρησιμοποιήσουμε αργότερα στα επιπλέον παραδείγματα κώδικα κατά την υλοποίηση των διαφορετικών προτύπων πρακτόρων.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εισαγωγή των Απαραίτητων Πακέτων Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δημιουργία του Πελάτη\n",
    "\n",
    "Σε αυτό το παράδειγμα, θα χρησιμοποιήσουμε τα [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) για πρόσβαση στο LLM.\n",
    "\n",
    "Το `ai_model_id` ορίζεται ως `gpt-4o-mini`. Δοκιμάστε να αλλάξετε το μοντέλο σε κάποιο άλλο διαθέσιμο στην αγορά των GitHub Models για να δείτε διαφορετικά αποτελέσματα.\n",
    "\n",
    "Για να χρησιμοποιήσουμε το `Azure Inference SDK`, που χρησιμοποιείται για το `base_url` των GitHub Models, θα χρησιμοποιήσουμε τον συνδετήρα `OpenAIChatCompletion` μέσα στο Semantic Kernel. Υπάρχουν επίσης άλλοι [διαθέσιμοι συνδετήρες](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) για τη χρήση του Semantic Kernel με άλλους παρόχους μοντέλων.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δημιουργία του Agent\n",
    "\n",
    "Παρακάτω δημιουργούμε τον Agent με το όνομα `TravelAgent`.\n",
    "\n",
    "Για αυτό το παράδειγμα, χρησιμοποιούμε πολύ απλές οδηγίες. Μπορείτε να αλλάξετε αυτές τις οδηγίες για να δείτε πώς ο agent ανταποκρίνεται διαφορετικά.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εκτέλεση του Agent\n",
    "\n",
    "Τώρα μπορούμε να εκτελέσουμε τον Agent ορίζοντας ένα νήμα τύπου `ChatHistoryAgentThread`. Οποιαδήποτε απαραίτητα μηνύματα συστήματος παρέχονται στο όρισμα `messages` της μεθόδου invoke_stream του agent.\n",
    "\n",
    "Αφού οριστούν αυτά, δημιουργούμε ένα `user_inputs`, το οποίο θα είναι αυτό που στέλνει ο χρήστης στον agent. Σε αυτή την περίπτωση, έχουμε ορίσει αυτό το μήνυμα ως `Σχεδίασέ μου διακοπές με ήλιο`.\n",
    "\n",
    "Μη διστάσετε να αλλάξετε αυτό το μήνυμα για να δείτε πώς αποκρίνεται διαφορετικά ο agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Αποποίηση ευθύνης**:  \nΑυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T16:16:38+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "el"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}