{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen बेसिक नमूना\n",
    "\n",
    "इस कोड नमूने में, आप [AutoGen](https://aka.ms/ai-agents/autogen) AI फ्रेमवर्क का उपयोग करके एक बेसिक एजेंट बनाएंगे।\n",
    "\n",
    "इस नमूने का उद्देश्य आपको उन चरणों को दिखाना है जिन्हें हम बाद में विभिन्न एजेंटिक पैटर्न को लागू करते समय अतिरिक्त कोड नमूनों में उपयोग करेंगे।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## आवश्यक पायथन पैकेज आयात करें\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## क्लाइंट बनाएं\n",
    "\n",
    "इस उदाहरण में, हम [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) का उपयोग LLM तक पहुंचने के लिए करेंगे।\n",
    "\n",
    "`model` को `gpt-4o-mini` के रूप में परिभाषित किया गया है। GitHub Models मार्केटप्लेस में उपलब्ध किसी अन्य मॉडल पर स्विच करके विभिन्न परिणाम देखने का प्रयास करें।\n",
    "\n",
    "एक त्वरित परीक्षण के रूप में, हम एक साधारण प्रॉम्प्ट चलाएंगे - `What is the capital of France`।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## एजेंट को परिभाषित करना\n",
    "\n",
    "अब जब हमने `client` सेट कर लिया है और यह सुनिश्चित कर लिया है कि यह काम कर रहा है, तो आइए एक `AssistantAgent` बनाते हैं। प्रत्येक एजेंट को निम्नलिखित सौंपा जा सकता है:  \n",
    "**name** - एक छोटा नाम जो इसे मल्टी-एजेंट फ्लो में संदर्भित करने में उपयोगी होगा।  \n",
    "**model_client** - वह क्लाइंट जिसे आपने पिछले चरण में बनाया था।  \n",
    "**tools** - उपलब्ध टूल्स जिनका उपयोग एजेंट किसी कार्य को पूरा करने के लिए कर सकता है।  \n",
    "**system_message** - वह मेटाप्रॉम्प्ट जो LLM के कार्य, व्यवहार और टोन को परिभाषित करता है।  \n",
    "\n",
    "आप सिस्टम संदेश को बदल सकते हैं यह देखने के लिए कि LLM कैसे प्रतिक्रिया करता है। हम `tools` को पाठ #4 में कवर करेंगे।  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## एजेंट चलाएं\n",
    "\n",
    "नीचे दी गई फ़ंक्शन एजेंट को चलाएगी। हम एजेंट की स्थिति को नए संदेश के साथ अपडेट करने के लिए `on_message` मेथड का उपयोग करते हैं।\n",
    "\n",
    "इस मामले में, हम उपयोगकर्ता से आने वाले नए संदेश, जो कि `\"Plan me a great sunny vacation\"` है, के साथ स्थिति को अपडेट करते हैं।\n",
    "\n",
    "आप संदेश की सामग्री बदल सकते हैं ताकि देख सकें कि LLM अलग-अलग तरीके से कैसे प्रतिक्रिया देता है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nयह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता सुनिश्चित करने का प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:10:03+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}