{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel\n",
    "\n",
    "ในตัวอย่างโค้ดนี้ คุณจะใช้ [Semantic Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) AI Framework เพื่อสร้างตัวแทนพื้นฐาน\n",
    "\n",
    "เป้าหมายของตัวอย่างนี้คือการแสดงขั้นตอนที่เราจะใช้ในตัวอย่างโค้ดเพิ่มเติมในภายหลังเมื่อดำเนินการรูปแบบตัวแทนต่างๆ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## นำเข้าแพ็คเกจ Python ที่จำเป็น\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การสร้าง Client\n",
    "\n",
    "ในตัวอย่างนี้ เราจะใช้ [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) เพื่อเข้าถึง LLM\n",
    "\n",
    "`ai_model_id` ถูกกำหนดเป็น `gpt-4o-mini` ลองเปลี่ยนโมเดลเป็นโมเดลอื่นที่มีอยู่ในตลาดของ GitHub Models เพื่อดูผลลัพธ์ที่แตกต่างกัน\n",
    "\n",
    "เพื่อให้เราใช้ `Azure Inference SDK` ซึ่งใช้สำหรับ `base_url` ของ GitHub Models เราจะใช้ตัวเชื่อมต่อ `OpenAIChatCompletion` ภายใน Semantic Kernel นอกจากนี้ยังมี [ตัวเชื่อมต่ออื่นๆ](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) ที่สามารถใช้ Semantic Kernel กับผู้ให้บริการโมเดลรายอื่นได้\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การสร้าง Agent\n",
    "\n",
    "ด้านล่างนี้เราจะสร้าง Agent ที่ชื่อว่า `TravelAgent`\n",
    "\n",
    "สำหรับตัวอย่างนี้ เราใช้คำแนะนำที่เรียบง่ายมาก คุณสามารถเปลี่ยนคำแนะนำเหล่านี้เพื่อดูว่า Agent ตอบสนองแตกต่างกันอย่างไร\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## การรัน Agent\n",
    "\n",
    "ตอนนี้เราสามารถรัน Agent ได้โดยการกำหนด thread ที่เป็นประเภท `ChatHistoryAgentThread` ข้อความระบบที่จำเป็นจะถูกส่งให้กับ invoke_stream ของ agent ผ่าน keyword argument `messages`\n",
    "\n",
    "หลังจากกำหนดสิ่งเหล่านี้แล้ว เราจะสร้าง `user_inputs` ซึ่งจะเป็นสิ่งที่ผู้ใช้ส่งไปยัง agent ในกรณีนี้ เราได้ตั้งข้อความนี้เป็น `Plan me a sunny vacation`\n",
    "\n",
    "คุณสามารถเปลี่ยนข้อความนี้ได้ตามต้องการเพื่อดูว่า agent จะตอบสนองแตกต่างกันอย่างไร\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ข้อจำกัดความรับผิดชอบ**:  \nเอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามให้การแปลมีความถูกต้องมากที่สุด แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาดั้งเดิมควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์ที่มีความเชี่ยวชาญ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T16:16:55+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "th"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}