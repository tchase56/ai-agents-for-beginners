{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Einfaches Beispiel\n",
    "\n",
    "In diesem Codebeispiel verwenden Sie das [AutoGen](https://aka.ms/ai-agents/autogen) KI-Framework, um einen einfachen Agenten zu erstellen.\n",
    "\n",
    "Das Ziel dieses Beispiels ist es, Ihnen die Schritte zu zeigen, die wir später in den zusätzlichen Codebeispielen verwenden werden, wenn wir die verschiedenen agentischen Muster implementieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren Sie die benötigten Python-Pakete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen des Clients\n",
    "\n",
    "In diesem Beispiel verwenden wir [GitHub Models](https://aka.ms/ai-agents-beginners/github-models), um auf das LLM zuzugreifen.\n",
    "\n",
    "Das `model` ist als `gpt-4o-mini` definiert. Versuchen Sie, das Modell auf ein anderes im GitHub Models-Marktplatz verfügbares Modell zu ändern, um unterschiedliche Ergebnisse zu sehen.\n",
    "\n",
    "Als schnellen Test führen wir einfach eine einfache Eingabeaufforderung aus – `What is the capital of France`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des Agenten\n",
    "\n",
    "Nachdem wir den `client` eingerichtet und bestätigt haben, dass er funktioniert, erstellen wir einen `AssistantAgent`. Jedem Agenten können folgende Eigenschaften zugewiesen werden:  \n",
    "**name** - Ein kurzer Name, der nützlich ist, um ihn in Multi-Agent-Workflows zu referenzieren.  \n",
    "**model_client** - Der Client, den Sie im vorherigen Schritt erstellt haben.  \n",
    "**tools** - Verfügbare Werkzeuge, die der Agent nutzen kann, um eine Aufgabe zu erledigen.  \n",
    "**system_message** - Die Metaprompt, die die Aufgabe, das Verhalten und den Ton des LLM definiert.  \n",
    "\n",
    "Sie können die Systemnachricht ändern, um zu sehen, wie das LLM reagiert. Wir werden `tools` in Lektion #4 behandeln.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent ausführen\n",
    "\n",
    "Die folgende Funktion wird den Agenten ausführen. Wir verwenden die Methode `on_message`, um den Zustand des Agenten mit der neuen Nachricht zu aktualisieren.\n",
    "\n",
    "In diesem Fall aktualisieren wir den Zustand mit einer neuen Nachricht vom Benutzer, die lautet: `\"Plane mir einen großartigen sonnigen Urlaub\"`.\n",
    "\n",
    "Du kannst den Nachrichteninhalt ändern, um zu sehen, wie das LLM unterschiedlich reagiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner ursprünglichen Sprache sollte als maßgebliche Quelle betrachtet werden. Für kritische Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:09:19+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}