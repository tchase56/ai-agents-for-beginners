{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anlamsal Çekirdek\n",
    "\n",
    "Bu kod örneğinde, temel bir ajan oluşturmak için [Semantic Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) AI Çerçevesini kullanacaksınız.\n",
    "\n",
    "Bu örneğin amacı, farklı ajan desenlerini uygularken sonraki kod örneklerinde kullanacağımız adımları size göstermektir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerekli Python Paketlerini İçe Aktar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## İstemciyi Oluşturma\n",
    "\n",
    "Bu örnekte, LLM'e erişim için [GitHub Modelleri](https://aka.ms/ai-agents-beginners/github-models) kullanılacaktır.\n",
    "\n",
    "`ai_model_id` olarak `gpt-4o-mini` tanımlanmıştır. Farklı sonuçları görmek için GitHub Modelleri pazarında bulunan başka bir modeli deneyerek değiştirebilirsiniz.\n",
    "\n",
    "GitHub Modelleri için `base_url` ile kullanılan `Azure Inference SDK`'yı kullanabilmemiz için, Semantic Kernel içinde `OpenAIChatCompletion` bağlayıcısını kullanacağız. Ayrıca, diğer model sağlayıcıları için Semantic Kernel'i kullanmak üzere başka [mevcut bağlayıcılar](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) da bulunmaktadır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajanı Oluşturma\n",
    "\n",
    "Aşağıda `TravelAgent` adında bir Ajan oluşturuyoruz.\n",
    "\n",
    "Bu örnek için oldukça basit talimatlar kullanıyoruz. Bu talimatları değiştirerek ajanın nasıl farklı tepkiler verdiğini görebilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajanı Çalıştırma\n",
    "\n",
    "Artık `ChatHistoryAgentThread` türünde bir thread tanımlayarak Ajanı çalıştırabiliriz. Gerekli olan sistem mesajları, ajanı invoke_stream'in `messages` anahtar argümanına sağlanır.\n",
    "\n",
    "Bunlar tanımlandıktan sonra, kullanıcının ajana göndereceği mesaj olan `user_inputs` oluşturulur. Bu örnekte, bu mesajı `Bana güneşli bir tatil planla` olarak ayarladık.\n",
    "\n",
    "Bu mesajı değiştirerek ajanın farklı şekilde nasıl yanıt verdiğini görmekten çekinmeyin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Feragatname**:  \nBu belge, [Co-op Translator](https://github.com/Azure/co-op-translator) adlı yapay zeka çeviri hizmeti kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlıklar içerebileceğini lütfen unutmayın. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlama veya yanlış yorumlamalardan sorumlu değiliz.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T13:39:28+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "tr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}