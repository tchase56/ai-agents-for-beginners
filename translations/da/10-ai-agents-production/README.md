<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-08-29T15:37:16+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "da"
}
-->
# AI-agenter i produktion: Observabilitet & Evaluering

[![AI-agenter i produktion](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.da.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

N√•r AI-agenter g√•r fra eksperimentelle prototyper til virkelige applikationer, bliver evnen til at forst√• deres adf√¶rd, overv√•ge deres pr√¶stationer og systematisk evaluere deres output afg√∏rende.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du vide hvordan/forst√•:
- Grundl√¶ggende begreber inden for agentobservabilitet og evaluering
- Teknikker til at forbedre agenters ydeevne, omkostninger og effektivitet
- Hvad og hvordan du systematisk evaluerer dine AI-agenter
- Hvordan du styrer omkostninger ved at implementere AI-agenter i produktion
- Hvordan du instrumenterer agenter bygget med AutoGen

M√•let er at give dig viden til at omdanne dine "black box"-agenter til transparente, h√•ndterbare og p√•lidelige systemer.

_**Bem√¶rk:** Det er vigtigt at implementere AI-agenter, der er sikre og p√•lidelige. Se lektionen [Bygning af p√•lidelige AI-agenter](./06-building-trustworthy-agents/README.md) for mere information._

## Traces og Spans

Observabilitetsv√¶rkt√∏jer som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) repr√¶senterer typisk agentk√∏rsler som traces og spans.

- **Trace** repr√¶senterer en komplet agentopgave fra start til slut (som at h√•ndtere en brugerforesp√∏rgsel).
- **Spans** er individuelle trin inden for trace (som at kalde en sprogmodel eller hente data).

![Trace-tr√¶ i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uden observabilitet kan en AI-agent f√∏les som en "black box" ‚Äì dens interne tilstand og r√¶sonnement er uigennemsigtige, hvilket g√∏r det sv√¶rt at diagnosticere problemer eller optimere ydeevnen. Med observabilitet bliver agenter "glass boxes," der tilbyder den gennemsigtighed, der er afg√∏rende for at opbygge tillid og sikre, at de fungerer som tilt√¶nkt.

## Hvorfor observabilitet er vigtigt i produktionsmilj√∏er

Overgangen af AI-agenter til produktionsmilj√∏er introducerer en r√¶kke nye udfordringer og krav. Observabilitet er ikke l√¶ngere en "nice-to-have," men en kritisk funktion:

*   **Fejlfinding og √•rsagsanalyse**: N√•r en agent fejler eller producerer et uventet output, giver observabilitetsv√¶rkt√∏jer de traces, der er n√∏dvendige for at finde kilden til fejlen. Dette er is√¶r vigtigt i komplekse agenter, der kan involvere flere LLM-kald, v√¶rkt√∏jsinteraktioner og betinget logik.
*   **Latens- og omkostningsstyring**: AI-agenter er ofte afh√¶ngige af LLM'er og andre eksterne API'er, der faktureres pr. token eller pr. kald. Observabilitet muligg√∏r pr√¶cis sporing af disse kald, hvilket hj√¶lper med at identificere operationer, der er un√∏dvendigt langsomme eller dyre. Dette g√∏r det muligt for teams at optimere prompts, v√¶lge mere effektive modeller eller redesigne workflows for at styre driftsomkostninger og sikre en god brugeroplevelse.
*   **Tillid, sikkerhed og overholdelse**: I mange applikationer er det vigtigt at sikre, at agenter opf√∏rer sig sikkert og etisk. Observabilitet giver en revisionsspor af agentens handlinger og beslutninger. Dette kan bruges til at opdage og afhj√¶lpe problemer som prompt-injektion, generering af skadeligt indhold eller forkert h√•ndtering af personligt identificerbare oplysninger (PII). For eksempel kan du gennemg√• traces for at forst√•, hvorfor en agent gav et bestemt svar eller brugte et specifikt v√¶rkt√∏j.
*   **Kontinuerlige forbedringssl√∏jfer**: Observabilitetsdata er fundamentet for en iterativ udviklingsproces. Ved at overv√•ge, hvordan agenter klarer sig i den virkelige verden, kan teams identificere omr√•der til forbedring, indsamle data til finjustering af modeller og validere effekten af √¶ndringer. Dette skaber en feedback-sl√∏jfe, hvor produktionsindsigter fra online evaluering informerer offline eksperimenter og forbedringer, hvilket f√∏rer til gradvist bedre agentpr√¶station.

## Vigtige metrics at spore

For at overv√•ge og forst√• agentadf√¶rd b√∏r en r√¶kke metrics og signaler spores. Selvom de specifikke metrics kan variere afh√¶ngigt af agentens form√•l, er nogle universelt vigtige.

Her er nogle af de mest almindelige metrics, som observabilitetsv√¶rkt√∏jer overv√•ger:

**Latens:** Hvor hurtigt reagerer agenten? Lange ventetider p√•virker brugeroplevelsen negativt. Du b√∏r m√•le latens for opgaver og individuelle trin ved at spore agentk√∏rsler. For eksempel kan en agent, der tager 20 sekunder for alle modelkald, accelereres ved at bruge en hurtigere model eller ved at k√∏re modelkald parallelt.

**Omkostninger:** Hvad er udgiften pr. agentk√∏rsel? AI-agenter er afh√¶ngige af LLM-kald, der faktureres pr. token eller eksterne API'er. Hyppig v√¶rkt√∏jsbrug eller flere prompts kan hurtigt √∏ge omkostningerne. For eksempel, hvis en agent kalder en LLM fem gange for marginal kvalitetsforbedring, skal du vurdere, om omkostningen er berettiget, eller om du kan reducere antallet af kald eller bruge en billigere model. Overv√•gning i realtid kan ogs√• hj√¶lpe med at identificere uventede stigninger (f.eks. fejl, der for√•rsager overdrevne API-l√∏kker).

**Foresp√∏rgselsfejl:** Hvor mange foresp√∏rgsler fejlede agenten? Dette kan inkludere API-fejl eller mislykkede v√¶rkt√∏jskald. For at g√∏re din agent mere robust mod disse i produktion kan du ops√¶tte fallback-mekanismer eller retries. F.eks. hvis LLM-udbyder A er nede, kan du skifte til LLM-udbyder B som backup.

**Brugerfeedback:** Implementering af direkte bruger-evalueringer giver v√¶rdifulde indsigter. Dette kan inkludere eksplicitte vurderinger (üëçthumbs-up/üëédown, ‚≠ê1-5 stjerner) eller tekstkommentarer. Konsistent negativ feedback b√∏r advare dig, da det er et tegn p√•, at agenten ikke fungerer som forventet.

**Implicit brugerfeedback:** Brugeradf√¶rd giver indirekte feedback, selv uden eksplicitte vurderinger. Dette kan inkludere √∏jeblikkelig omformulering af sp√∏rgsm√•l, gentagne foresp√∏rgsler eller klik p√• en retry-knap. F.eks. hvis du ser, at brugere gentagne gange stiller det samme sp√∏rgsm√•l, er det et tegn p√•, at agenten ikke fungerer som forventet.

**N√∏jagtighed:** Hvor ofte producerer agenten korrekte eller √∏nskede output? Definitionen af n√∏jagtighed varierer (f.eks. korrekthed i probleml√∏sning, informationshentning, bruger-tilfredshed). Det f√∏rste skridt er at definere, hvad succes betyder for din agent. Du kan spore n√∏jagtighed via automatiske checks, evalueringsscorer eller opgavem√¶rkater. For eksempel kan traces markeres som "lykkedes" eller "mislykkedes."

**Automatiske evalueringsmetrics:** Du kan ogs√• ops√¶tte automatiske evalueringer. For eksempel kan du bruge en LLM til at score agentens output, f.eks. om det er nyttigt, n√∏jagtigt eller ej. Der findes ogs√• flere open source-biblioteker, der hj√¶lper med at score forskellige aspekter af agenten. F.eks. [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) til at opdage skadeligt sprog eller prompt-injektion.

I praksis giver en kombination af disse metrics den bedste d√¶kning af en AI-agents sundhed. I dette kapitels [eksempelsnotebook](./code_samples/10_autogen_evaluation.ipynb) viser vi, hvordan disse metrics ser ud i virkelige eksempler, men f√∏rst l√¶rer vi, hvordan en typisk evalueringsworkflow ser ud.

## Instrument√©r din agent

For at indsamle tracing-data skal du instrumentere din kode. M√•let er at instrumentere agentkoden til at udsende traces og metrics, der kan indsamles, behandles og visualiseres af en observabilitetsplatform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) er blevet en industristandard for LLM-observabilitet. Det tilbyder et s√¶t API'er, SDK'er og v√¶rkt√∏jer til generering, indsamling og eksport af telemetridata.

Der findes mange instrumenteringsbiblioteker, der wrapper eksisterende agentframeworks og g√∏r det nemt at eksportere OpenTelemetry-spans til et observabilitetsv√¶rkt√∏j. Nedenfor er et eksempel p√• instrumentering af en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Eksempelsnotebooken](./code_samples/10_autogen_evaluation.ipynb) i dette kapitel vil demonstrere, hvordan du instrumenterer din AutoGen-agent.

**Manuel oprettelse af spans:** Mens instrumenteringsbiblioteker giver en god baseline, er der ofte tilf√¶lde, hvor mere detaljeret eller tilpasset information er n√∏dvendig. Du kan manuelt oprette spans for at tilf√∏je tilpasset applikationslogik. Endnu vigtigere kan de berige automatisk eller manuelt oprettede spans med brugerdefinerede attributter (ogs√• kendt som tags eller metadata). Disse attributter kan inkludere forretningsspecifikke data, mellemregninger eller enhver kontekst, der kan v√¶re nyttig til fejlfinding eller analyse, s√•som `user_id`, `session_id` eller `model_version`.

Eksempel p√• manuel oprettelse af traces og spans med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agent-evaluering

Observabilitet giver os metrics, men evaluering er processen med at analysere disse data (og udf√∏re tests) for at afg√∏re, hvor godt en AI-agent klarer sig, og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrics, hvordan bruger du dem til at bed√∏mme agenten og tr√¶ffe beslutninger?

Regelm√¶ssig evaluering er vigtig, fordi AI-agenter ofte er ikke-deterministiske og kan udvikle sig (gennem opdateringer eller √¶ndringer i modeladf√¶rd) ‚Äì uden evaluering ville du ikke vide, om din "smarte agent" faktisk g√∏r sit job godt eller om den er blevet d√•rligere.

Der er to kategorier af evalueringer for AI-agenter: **online evaluering** og **offline evaluering**. Begge er v√¶rdifulde og supplerer hinanden. Vi begynder normalt med offline evaluering, da dette er det minimum n√∏dvendige skridt, f√∏r en agent implementeres.

### Offline evaluering

![Datas√¶t-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette indeb√¶rer evaluering af agenten i et kontrolleret milj√∏, typisk ved hj√¶lp af testdatas√¶t, ikke live brugerforesp√∏rgsler. Du bruger kuraterede datas√¶t, hvor du ved, hvad det forventede output eller korrekte adf√¶rd er, og derefter k√∏rer din agent p√• disse.

For eksempel, hvis du har bygget en agent til matematiske tekstproblemer, kan du have et [testdatas√¶t](https://huggingface.co/datasets/gsm8k) med 100 problemer med kendte svar. Offline evaluering udf√∏res ofte under udvikling (og kan v√¶re en del af CI/CD-pipelines) for at kontrollere forbedringer eller beskytte mod regressioner. Fordelen er, at det er **gentageligt, og du kan f√• klare n√∏jagtighedsmetrics, da du har ground truth**. Du kan ogs√• simulere brugerforesp√∏rgsler og m√•le agentens svar mod ideelle svar eller bruge automatiske metrics som beskrevet ovenfor.

Den st√∏rste udfordring med offline evaluering er at sikre, at dit testdatas√¶t er omfattende og forbliver relevant ‚Äì agenten kan klare sig godt p√• et fast testdatas√¶t, men st√∏de p√• meget forskellige foresp√∏rgsler i produktion. Derfor b√∏r du holde testdatas√¶t opdateret med nye edge cases og eksempler, der afspejler virkelige scenarier‚Äã. En blanding af sm√• "smoke test"-cases og st√∏rre evalueringss√¶t er nyttig: sm√• s√¶t til hurtige checks og st√∏rre til bredere pr√¶stationsmetrics‚Äã.

### Online evaluering

![Oversigt over observabilitetsmetrics](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til evaluering af agenten i et live, virkeligt milj√∏, dvs. under faktisk brug i produktion. Online evaluering indeb√¶rer overv√•gning af agentens pr√¶station p√• rigtige brugerinteraktioner og kontinuerlig analyse af resultater.

For eksempel kan du spore succesrater, bruger-tilfredshedsscorer eller andre metrics p√• live trafik. Fordelen ved online evaluering er, at det **fanger ting, du m√•ske ikke forudser i et laboratoriemilj√∏** ‚Äì du kan observere modeldrift over tid (hvis agentens effektivitet forringes, n√•r inputm√∏nstre √¶ndrer sig) og fange uventede foresp√∏rgsler eller situationer, der ikke var i dit testdatas√¶t‚Äã. Det giver et sandt billede af, hvordan agenten opf√∏rer sig i praksis.

Online evaluering indeb√¶rer ofte indsamling af implicit og eksplicit brugerfeedback, som diskuteret, og muligvis k√∏rsel af shadow tests eller A/B-tests (hvor en ny version af agenten k√∏rer parallelt for at sammenligne med den gamle). Udfordringen er, at det kan v√¶re vanskeligt at f√• p√•lidelige labels eller scorer for live interaktioner ‚Äì du kan v√¶re afh√¶ngig af brugerfeedback eller downstream metrics (som om brugeren klikkede p√• resultatet).

### Kombination af de to

Online og offline evalueringer udelukker ikke hinanden; de supplerer hinanden. Indsigter fra online overv√•gning (f.eks. nye typer brugerforesp√∏rgsler, hvor agenten klarer sig d√•rligt) kan bruges til at udvide og forbedre offline testdatas√¶t. Omvendt kan agenter, der klarer sig godt i offline tests, derefter implementeres mere selvsikkert og overv√•ges online.

Faktisk adopterer mange teams en sl√∏jfe:

_evalu√©r offline -> implement√©r -> overv√•g online -> indsamle nye fejltilf√¶lde -> tilf√∏j til offline datas√¶t -> forbedr agent -> gentag_.

## Almindelige problemer

N√•r du implementerer AI-agenter i produktion, kan du st√∏de p√• forskellige udfordringer. Her er nogle almindelige problemer og deres potentielle l√∏sninger:

| **Problem**    | **Potentiel l√∏sning**   |
| ------------- | ------------------ |
| AI-agent udf√∏rer ikke opgaver konsekvent | - Forfin prompten, der gives til AI-agenten; v√¶r klar omkring m√•lene.<br>- Identific√©r, hvor opdeling af opgaver i delopgaver og h√•ndtering af dem af flere agenter kan hj√¶lpe. |
| AI-agent ender i kontinuerlige l√∏kker  | - S√∏rg for, at du har klare afslutningsbetingelser, s√• agenten ved, hvorn√•r processen skal stoppe. |

## Fejlfinding af AI-agenter i produktion

N√•r AI-agenter er implementeret i produktion, kan der opst√• en r√¶kke problemer. Her er nogle almindelige udfordringer og forslag til, hvordan de kan l√∏ses:

| **Problem** | **L√∏sning** |
|-------------|-------------|
| Agenten giver forkerte eller ufuldst√¶ndige svar | - Juster prompten for at give mere kontekst eller specifikke instruktioner.<br>- Brug en st√∏rre model, hvis den nuv√¶rende model ikke er i stand til at h√•ndtere komplekse opgaver. |
| Agenten er langsom til at svare | - Optimer prompten for at reducere kompleksiteten.<br>- Brug en mindre model til enklere opgaver.<br>- Implementer caching for at genbruge svar p√• gentagne foresp√∏rgsler. |
| Agenten misforst√•r input | - Forbedr inputvalidering og normalisering.<br>- Brug en model, der er bedre til at forst√• den specifikke type input.<br>- Implementer en forbehandlingspipeline for at standardisere input. |
| For komplekse opgaver, der kr√¶ver r√¶sonnement og planl√¶gning | - Brug en st√∏rre model, der er specialiseret i opgaver, der kr√¶ver avanceret r√¶sonnement. |
| AI-agentens v√¶rkt√∏jskald fungerer ikke optimalt | - Test og valider v√¶rkt√∏jets output uden for agentsystemet.<br>- Forfin de definerede parametre, prompts og navngivning af v√¶rkt√∏jer. |
| Multi-agent-systemet fungerer ikke konsekvent | - Forfin prompts til hver agent for at sikre, at de er specifikke og adskiller sig fra hinanden.<br>- Byg et hierarkisk system med en "routing"- eller controller-agent, der kan afg√∏re, hvilken agent der er den rette. |

Mange af disse problemer kan identificeres mere effektivt, hvis der er observabilitet p√• plads. De spor og metrikker, vi diskuterede tidligere, hj√¶lper med at lokalisere pr√¶cis, hvor i agentens arbejdsgang problemer opst√•r, hvilket g√∏r fejlfinding og optimering langt mere effektivt.

## H√•ndtering af omkostninger

Her er nogle strategier til at h√•ndtere omkostningerne ved at implementere AI-agenter i produktion:

**Brug af mindre modeller:** Sm√• sproglige modeller (SLMs) kan klare sig godt i visse agentbaserede brugsscenarier og vil reducere omkostningerne betydeligt. Som n√¶vnt tidligere er det bedste v√¶rkt√∏j til at forst√•, hvordan en SLM vil klare sig i din brugssituation, at opbygge et evalueringssystem til at sammenligne ydeevne med st√∏rre modeller. Overvej at bruge SLMs til enklere opgaver som klassificering af hensigt eller parameterudtr√¶kning, mens st√∏rre modeller reserveres til komplekse r√¶sonnementer.

**Brug af en router-model:** En lignende strategi er at bruge en diversitet af modeller og st√∏rrelser. Du kan bruge en LLM/SLM eller serverless funktion til at dirigere foresp√∏rgsler baseret p√• kompleksitet til de bedst egnede modeller. Dette vil ogs√• hj√¶lpe med at reducere omkostningerne, samtidig med at ydeevnen sikres p√• de rette opgaver. For eksempel kan simple foresp√∏rgsler dirigeres til mindre, hurtigere modeller, mens dyre store modeller kun bruges til komplekse r√¶sonnementer.

**Caching af svar:** Identificer almindelige foresp√∏rgsler og opgaver og lever svarene, f√∏r de g√•r gennem dit agentsystem. Du kan endda implementere en proces til at identificere, hvor lignende en foresp√∏rgsel er med dine cachede foresp√∏rgsler ved hj√¶lp af mere basale AI-modeller. Denne strategi kan reducere omkostningerne betydeligt for ofte stillede sp√∏rgsm√•l eller almindelige arbejdsgange.

## Lad os se, hvordan dette fungerer i praksis

I [eksempelsnotebooken for denne sektion](./code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√•, hvordan vi kan bruge observabilitetsv√¶rkt√∏jer til at overv√•ge og evaluere vores agent.

### Har du flere sp√∏rgsm√•l om AI-agenter i produktion?

Deltag i [Azure AI Foundry Discord](https://aka.ms/ai-agents/discord) for at m√∏de andre l√¶rende, deltage i kontortid og f√• svar p√• dine sp√∏rgsm√•l om AI-agenter.

## Forrige lektion

[Metakognitivt designm√∏nster](../09-metacognition/README.md)

## N√¶ste lektion

[Agentiske protokoller](../11-agentic-protocols/README.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.