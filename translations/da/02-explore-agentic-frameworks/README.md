<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a9631d0898fc3c6ecbb3a8a0da7aaba3",
  "translation_date": "2025-08-29T15:42:57+00:00",
  "source_file": "02-explore-agentic-frameworks/README.md",
  "language_code": "da"
}
-->
[![Udforsk AI Agent Frameworks](../../../translated_images/lesson-2-thumbnail.c65f44c93b8558df4d5d407e29970e654629e614f357444a9c27c80feb54c79d.da.png)](https://youtu.be/ODwF-EZo_O8?si=1xoy_B9RNQfrYdF7)

> _(Klik p친 billedet ovenfor for at se videoen til denne lektion)_

# Udforsk AI Agent Frameworks

AI agent frameworks er softwareplatforme designet til at forenkle oprettelsen, implementeringen og styringen af AI-agenter. Disse frameworks giver udviklere forudbyggede komponenter, abstraktioner og v칝rkt칮jer, der g칮r det lettere at udvikle komplekse AI-systemer.

Disse frameworks hj칝lper udviklere med at fokusere p친 de unikke aspekter af deres applikationer ved at tilbyde standardiserede l칮sninger p친 almindelige udfordringer inden for AI-agentudvikling. De forbedrer skalerbarhed, tilg칝ngelighed og effektivitet i opbygningen af AI-systemer.

## Introduktion 

Denne lektion vil d칝kke:

- Hvad er AI Agent Frameworks, og hvad g칮r de det muligt for udviklere at opn친?
- Hvordan kan teams bruge disse til hurtigt at prototype, iterere og forbedre deres agents kapaciteter?
- Hvad er forskellene mellem de frameworks og v칝rkt칮jer, der er skabt af Microsoft, og hvordan de adskiller sig?

- Kan jeg integrere mine eksisterende Azure-칮kosystemv칝rkt칮jer direkte, eller har jeg brug for selvst칝ndige l칮sninger?
- Hvad er Azure AI Agents-tjenesten, og hvordan kan den hj칝lpe mig?

## L칝ringsm친l

M친lene med denne lektion er at hj칝lpe dig med at forst친:

- AI Agent Frameworks' rolle i AI-udvikling.
- Hvordan man udnytter AI Agent Frameworks til at bygge intelligente agenter.
- N칮glefunktioner, der muligg칮res af AI Agent Frameworks.
- Forskellene mellem AutoGen, Semantic Kernel og Azure AI Agent Service.

## Hvad er AI Agent Frameworks, og hvad g칮r de det muligt for udviklere at opn친?

Traditionelle AI Frameworks kan hj칝lpe dig med at integrere AI i dine apps og forbedre disse apps p친 f칮lgende m친der:

- **Personalisering**: AI kan analysere brugeradf칝rd og pr칝ferencer for at give personlige anbefalinger, indhold og oplevelser.
Eksempel: Streamingtjenester som Netflix bruger AI til at foresl친 film og serier baseret p친 visningshistorik, hvilket 칮ger brugerengagement og tilfredshed.
- **Automatisering og effektivitet**: AI kan automatisere gentagne opgaver, str칮mline arbejdsgange og forbedre operationel effektivitet.
Eksempel: Kundeserviceapps bruger AI-drevne chatbots til at h친ndtere almindelige foresp칮rgsler, reducere svartider og frig칮re menneskelige agenter til mere komplekse problemer.
- **Forbedret brugeroplevelse**: AI kan forbedre den samlede brugeroplevelse ved at tilbyde intelligente funktioner som stemmegenkendelse, naturlig sprogbehandling og forudsigende tekst.
Eksempel: Virtuelle assistenter som Siri og Google Assistant bruger AI til at forst친 og reagere p친 stemmekommandoer, hvilket g칮r det lettere for brugere at interagere med deres enheder.

### Det lyder alt sammen godt, ikke? S친 hvorfor har vi brug for AI Agent Frameworks?

AI Agent Frameworks repr칝senterer noget mere end blot AI frameworks. De er designet til at muligg칮re oprettelsen af intelligente agenter, der kan interagere med brugere, andre agenter og milj칮et for at opn친 specifikke m친l. Disse agenter kan udvise autonom adf칝rd, tr칝ffe beslutninger og tilpasse sig 칝ndrede forhold. Lad os se p친 nogle n칮glefunktioner, der muligg칮res af AI Agent Frameworks:

- **Agent-samarbejde og koordinering**: Muligg칮r oprettelsen af flere AI-agenter, der kan arbejde sammen, kommunikere og koordinere for at l칮se komplekse opgaver.
- **Automatisering og opgavestyring**: Tilbyder mekanismer til automatisering af flertrins arbejdsgange, opgavefordeling og dynamisk opgavestyring blandt agenter.
- **Kontekstforst친else og tilpasning**: Udstyrer agenter med evnen til at forst친 kontekst, tilpasse sig 칝ndrede milj칮er og tr칝ffe beslutninger baseret p친 realtidsinformation.

S친 kort sagt giver agenter dig mulighed for at g칮re mere, tage automatisering til n칝ste niveau og skabe mere intelligente systemer, der kan tilpasse sig og l칝re af deres milj칮.

## Hvordan kan man hurtigt prototype, iterere og forbedre agentens kapaciteter?

Dette er et hurtigt udviklende omr친de, men der er nogle ting, der er f칝lles for de fleste AI Agent Frameworks, som kan hj칝lpe dig med hurtigt at prototype og iterere, nemlig modulkomponenter, samarbejdsv칝rkt칮jer og realtidsl칝ring. Lad os dykke ned i disse:

- **Brug modulkomponenter**: AI SDK'er tilbyder forudbyggede komponenter som AI- og hukommelsesforbindelser, funktionkald ved hj칝lp af naturligt sprog eller kodeplugins, promptskabeloner og mere.
- **Udnyt samarbejdsv칝rkt칮jer**: Design agenter med specifikke roller og opgaver, hvilket g칮r det muligt at teste og forfine samarbejdsarbejdsgange.
- **L칝r i realtid**: Implementer feedbackloops, hvor agenter l칝rer af interaktioner og justerer deres adf칝rd dynamisk.

### Brug modulkomponenter

SDK'er som Microsoft Semantic Kernel og LangChain tilbyder forudbyggede komponenter som AI-forbindelser, promptskabeloner og hukommelsesstyring.

**Hvordan teams kan bruge disse**: Teams kan hurtigt samle disse komponenter for at skabe en funktionel prototype uden at starte fra bunden, hvilket muligg칮r hurtig eksperimentering og iteration.

**Hvordan det fungerer i praksis**: Du kan bruge en forudbygget parser til at udtr칝kke information fra brugerinput, en hukommelsesmodul til at gemme og hente data og en promptgenerator til at interagere med brugere, alt sammen uden at skulle bygge disse komponenter fra bunden.

**Eksempelkode**. Lad os se p친 eksempler p친, hvordan du kan bruge en forudbygget AI Connector med Semantic Kernel Python og .Net, der bruger auto-funktionskald til at f친 modellen til at reagere p친 brugerinput:

``` python
# Semantic Kernel Python Example

import asyncio
from typing import Annotated

from semantic_kernel.connectors.ai import FunctionChoiceBehavior
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings
from semantic_kernel.contents import ChatHistory
from semantic_kernel.functions import kernel_function
from semantic_kernel.kernel import Kernel

# Define a ChatHistory object to hold the conversation's context
chat_history = ChatHistory()
chat_history.add_user_message("I'd like to go to New York on January 1, 2025")


# Define a sample plugin that contains the function to book travel
class BookTravelPlugin:
    """A Sample Book Travel Plugin"""

    @kernel_function(name="book_flight", description="Book travel given location and date")
    async def book_flight(
        self, date: Annotated[str, "The date of travel"], location: Annotated[str, "The location to travel to"]
    ) -> str:
        return f"Travel was booked to {location} on {date}"

# Create the Kernel
kernel = Kernel()

# Add the sample plugin to the Kernel object
kernel.add_plugin(BookTravelPlugin(), plugin_name="book_travel")

# Define the Azure OpenAI AI Connector
chat_service = AzureChatCompletion(
    deployment_name="YOUR_DEPLOYMENT_NAME", 
    api_key="YOUR_API_KEY", 
    endpoint="https://<your-resource>.azure.openai.com/",
)

# Define the request settings to configure the model with auto-function calling
request_settings = AzureChatPromptExecutionSettings(function_choice_behavior=FunctionChoiceBehavior.Auto())


async def main():
    # Make the request to the model for the given chat history and request settings
    # The Kernel contains the sample that the model will request to invoke
    response = await chat_service.get_chat_message_content(
        chat_history=chat_history, settings=request_settings, kernel=kernel
    )
    assert response is not None

    """
    Note: In the auto function calling process, the model determines it can invoke the 
    `BookTravelPlugin` using the `book_flight` function, supplying the necessary arguments. 
    
    For example:

    "tool_calls": [
        {
            "id": "call_abc123",
            "type": "function",
            "function": {
                "name": "BookTravelPlugin-book_flight",
                "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
            }
        }
    ]

    Since the location and date arguments are required (as defined by the kernel function), if the 
    model lacks either, it will prompt the user to provide them. For instance:

    User: Book me a flight to New York.
    Model: Sure, I'd love to help you book a flight. Could you please specify the date?
    User: I want to travel on January 1, 2025.
    Model: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels!
    """

    print(f"`{response}`")
    # Example AI Model Response: `Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! 九걾잺游딯`

    # Add the model's response to our chat history context
    chat_history.add_assistant_message(response.content)


if __name__ == "__main__":
    asyncio.run(main())
```
```csharp
// Semantic Kernel C# example

using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using System.ComponentModel;
using Microsoft.SemanticKernel.Connectors.AzureOpenAI;

ChatHistory chatHistory = [];
chatHistory.AddUserMessage("I'd like to go to New York on January 1, 2025");

var kernelBuilder = Kernel.CreateBuilder();
kernelBuilder.AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT"
);
kernelBuilder.Plugins.AddFromType<BookTravelPlugin>("BookTravel"); 
var kernel = kernelBuilder.Build();

var settings = new AzureOpenAIPromptExecutionSettings()
{
    FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
};

var chatCompletion = kernel.GetRequiredService<IChatCompletionService>();

var response = await chatCompletion.GetChatMessageContentAsync(chatHistory, settings, kernel);

/*
Behind the scenes, the model recognizes the tool to call, what arguments it already has (location) and (date)
{

"tool_calls": [
    {
        "id": "call_abc123",
        "type": "function",
        "function": {
            "name": "BookTravelPlugin-book_flight",
            "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
        }
    }
]
*/

Console.WriteLine(response.Content);
chatHistory.AddMessage(response!.Role, response!.Content!);

// Example AI Model Response: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! 九걾잺游딯

// Define a plugin that contains the function to book travel
public class BookTravelPlugin
{
    [KernelFunction("book_flight")]
    [Description("Book travel given location and date")]
    public async Task<string> BookFlight(DateTime date, string location)
    {
        return await Task.FromResult( $"Travel was booked to {location} on {date}");
    }
}
```

Hvad du kan se fra dette eksempel er, hvordan du kan udnytte en forudbygget parser til at udtr칝kke n칮gleinformation fra brugerinput, s친som oprindelse, destination og dato for en flybookinganmodning. Denne modul칝re tilgang giver dig mulighed for at fokusere p친 den overordnede logik.

### Udnyt samarbejdsv칝rkt칮jer

Frameworks som CrewAI, Microsoft AutoGen og Semantic Kernel muligg칮r oprettelsen af flere agenter, der kan arbejde sammen.

**Hvordan teams kan bruge disse**: Teams kan designe agenter med specifikke roller og opgaver, hvilket g칮r det muligt at teste og forfine samarbejdsarbejdsgange og forbedre den samlede systemeffektivitet.

**Hvordan det fungerer i praksis**: Du kan oprette et team af agenter, hvor hver agent har en specialiseret funktion, s친som datahentning, analyse eller beslutningstagning. Disse agenter kan kommunikere og dele information for at opn친 et f칝lles m친l, s친som at besvare en brugerforesp칮rgsel eller fuldf칮re en opgave.

**Eksempelkode (AutoGen)**:

```python
# creating agents, then create a round robin schedule where they can work together, in this case in order

# Data Retrieval Agent
# Data Analysis Agent
# Decision Making Agent

agent_retrieve = AssistantAgent(
    name="dataretrieval",
    model_client=model_client,
    tools=[retrieve_tool],
    system_message="Use tools to solve tasks."
)

agent_analyze = AssistantAgent(
    name="dataanalysis",
    model_client=model_client,
    tools=[analyze_tool],
    system_message="Use tools to solve tasks."
)

# conversation ends when user says "APPROVE"
termination = TextMentionTermination("APPROVE")

user_proxy = UserProxyAgent("user_proxy", input_func=input)

team = RoundRobinGroupChat([agent_retrieve, agent_analyze, user_proxy], termination_condition=termination)

stream = team.run_stream(task="Analyze data", max_turns=10)
# Use asyncio.run(...) when running in a script.
await Console(stream)
```

Hvad du ser i den tidligere kode er, hvordan du kan oprette en opgave, der involverer flere agenter, der arbejder sammen om at analysere data. Hver agent udf칮rer en specifik funktion, og opgaven udf칮res ved at koordinere agenterne for at opn친 det 칮nskede resultat. Ved at oprette dedikerede agenter med specialiserede roller kan du forbedre opgaveeffektiviteten og ydeevnen.

### L칝r i realtid

Avancerede frameworks giver muligheder for realtids kontekstforst친else og tilpasning.

**Hvordan teams kan bruge disse**: Teams kan implementere feedbackloops, hvor agenter l칝rer af interaktioner og justerer deres adf칝rd dynamisk, hvilket f칮rer til kontinuerlig forbedring og forfining af kapaciteter.

**Hvordan det fungerer i praksis**: Agenter kan analysere brugerfeedback, milj칮data og opgaveudfald for at opdatere deres vidensbase, justere beslutningsalgoritmer og forbedre ydeevnen over tid. Denne iterative l칝ringsproces g칮r det muligt for agenter at tilpasse sig 칝ndrede forhold og brugerpr칝ferencer, hvilket forbedrer den samlede systemeffektivitet.

## Hvad er forskellene mellem frameworks AutoGen, Semantic Kernel og Azure AI Agent Service?

Der er mange m친der at sammenligne disse frameworks p친, men lad os se p친 nogle n칮gleforskelle i forhold til deres design, kapaciteter og m친lgrupper:

## AutoGen

AutoGen er et open-source framework udviklet af Microsoft Research's AI Frontiers Lab. Det fokuserer p친 h칝ndelsesdrevne, distribuerede *agentiske* applikationer, der muligg칮r flere LLM'er og SLM'er, v칝rkt칮jer og avancerede multi-agent designm칮nstre.

AutoGen er bygget omkring kernekonceptet agenter, som er autonome enheder, der kan opfatte deres milj칮, tr칝ffe beslutninger og tage handlinger for at opn친 specifikke m친l. Agenter kommunikerer via asynkrone beskeder, hvilket g칮r det muligt for dem at arbejde uafh칝ngigt og parallelt, hvilket forbedrer systemets skalerbarhed og responsivitet.

If칮lge Wikipedia er en akt칮r _den grundl칝ggende byggesten for samtidig computation. Som svar p친 en besked, den modtager, kan en akt칮r: tr칝ffe lokale beslutninger, oprette flere akt칮rer, sende flere beskeder og bestemme, hvordan den skal reagere p친 den n칝ste besked, den modtager_.

**Anvendelsesomr친der**: Automatisering af kodegenerering, dataanalysetasks og opbygning af skr칝ddersyede agenter til planl칝gnings- og forskningsfunktioner.

Her er nogle vigtige kernekoncepter i AutoGen:

- **Agenter**. En agent er en softwareenhed, der:
  - **Kommunikerer via beskeder**, disse beskeder kan v칝re synkrone eller asynkrone.
  - **Vedligeholder sin egen tilstand**, som kan 칝ndres af indkommende beskeder.
  - **Udf칮rer handlinger** som svar p친 modtagne beskeder eller 칝ndringer i dens tilstand. Disse handlinger kan 칝ndre agentens tilstand og producere eksterne effekter, s친som opdatering af beskedlogfiler, afsendelse af nye beskeder, udf칮relse af kode eller foretage API-kald.
    
  Her er en kort kodeeksempel, hvor du opretter din egen agent med chatfunktioner:

    ```python
    from autogen_agentchat.agents import AssistantAgent
    from autogen_agentchat.messages import TextMessage
    from autogen_ext.models.openai import OpenAIChatCompletionClient


    class MyAssistant(RoutedAgent):
        def __init__(self, name: str) -> None:
            super().__init__(name)
            model_client = OpenAIChatCompletionClient(model="gpt-4o")
            self._delegate = AssistantAgent(name, model_client=model_client)
    
        @message_handler
        async def handle_my_message_type(self, message: MyMessageType, ctx: MessageContext) -> None:
            print(f"{self.id.type} received message: {message.content}")
            response = await self._delegate.on_messages(
                [TextMessage(content=message.content, source="user")], ctx.cancellation_token
            )
            print(f"{self.id.type} responded: {response.chat_message.content}")
    ```
    
    I den tidligere kode er `MyAssistant` blevet oprettet og arver fra `RoutedAgent`. Den har en beskedh친ndterer, der udskriver indholdet af beskeden og derefter sender et svar ved hj칝lp af `AssistantAgent`-delegeringen. Bem칝rk is칝r, hvordan vi tildeler `self._delegate` en instans af `AssistantAgent`, som er en forudbygget agent, der kan h친ndtere chatkompletteringer.


    Lad os informere AutoGen om denne agenttype og starte programmet:

    ```python
    
    # main.py
    runtime = SingleThreadedAgentRuntime()
    await MyAgent.register(runtime, "my_agent", lambda: MyAgent())

    runtime.start()  # Start processing messages in the background.
    await runtime.send_message(MyMessageType("Hello, World!"), AgentId("my_agent", "default"))
    ```

    I den tidligere kode registreres agenterne med runtime, og derefter sendes en besked til agenten, hvilket resulterer i f칮lgende output:

    ```text
    # Output from the console:
    my_agent received message: Hello, World!
    my_assistant received message: Hello, World!
    my_assistant responded: Hello! How can I assist you today?
    ```

- **Multi-agenter**. AutoGen underst칮tter oprettelsen af flere agenter, der kan arbejde sammen for at opn친 komplekse opgaver. Agenter kan kommunikere, dele information og koordinere deres handlinger for at l칮se problemer mere effektivt. For at oprette et multi-agent system kan du definere forskellige typer agenter med specialiserede funktioner og roller, s친som datahentning, analyse, beslutningstagning og brugerinteraktion. Lad os se, hvordan en s친dan oprettelse ser ud, s친 vi f친r en fornemmelse af det:

    ```python
    editor_description = "Editor for planning and reviewing the content."

    # Example of declaring an Agent
    editor_agent_type = await EditorAgent.register(
    runtime,
    editor_topic_type,  # Using topic type as the agent type.
    lambda: EditorAgent(
        description=editor_description,
        group_chat_topic_type=group_chat_topic_type,
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        ),
    )

    # remaining declarations shortened for brevity

    # Group chat
    group_chat_manager_type = await GroupChatManager.register(
    runtime,
    "group_chat_manager",
    lambda: GroupChatManager(
        participant_topic_types=[writer_topic_type, illustrator_topic_type, editor_topic_type, user_topic_type],
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        participant_descriptions=[
            writer_description, 
            illustrator_description, 
            editor_description, 
            user_description
        ],
        ),
    )
    ```

    I den tidligere kode har vi en `GroupChatManager`, der er registreret med runtime. Denne manager er ansvarlig for at koordinere interaktionerne mellem forskellige typer agenter, s친som forfattere, illustratorer, redakt칮rer og brugere.

- **Agent Runtime**. Frameworket tilbyder et runtime-milj칮, der muligg칮r kommunikation mellem agenter, styrer deres identiteter og livscyklusser og h친ndh칝ver sikkerheds- og privatlivsgr칝nser. Dette betyder, at du kan k칮re dine agenter i et sikkert og kontrolleret milj칮, hvilket sikrer, at de kan interagere sikkert og effektivt. Der er to interessante runtime-milj칮er:
  - **Stand-alone runtime**. Dette er et godt valg for enkeltprocesapplikationer, hvor alle agenter er implementeret i det samme programmeringssprog og k칮rer i den samme proces. Her er en illustration af, hvordan det fungerer:

Applikationsstak

    *agenter kommunikerer via beskeder gennem runtime, og runtime styrer agenternes livscyklus*

  - **Distribueret agent runtime**, er velegnet til multiprocesapplikationer, hvor agenter kan v칝re implementeret i forskellige programmeringssprog og k칮re p친 forskellige maskiner. Her er en illustration af, hvordan det fungerer:

## Semantic Kernel + Agent Framework

Semantic Kernel er en enterprise-klar AI Orchestration SDK. Den best친r af AI- og hukommelsesforbindelser sammen med et Agent Framework.

Lad os f칮rst d칝kke nogle kernekomponenter:

- **AI-forbindelser**: Dette er en gr칝nseflade til eksterne AI-tjenester og datakilder, der kan bruges i b친de Python og C#.

  ```python
  # Semantic Kernel Python
  from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
  from semantic_kernel.kernel import Kernel

  kernel = Kernel()
  kernel.add_service(
    AzureChatCompletion(
        deployment_name="your-deployment-name",
        api_key="your-api-key",
        endpoint="your-endpoint",
    )
  )
  ```  

    ```csharp
    // Semantic Kernel C#
    using Microsoft.SemanticKernel;

    // Create kernel
    var builder = Kernel.CreateBuilder();
    
    // Add a chat completion service:
    builder.Services.AddAzureOpenAIChatCompletion(
        "your-resource-name",
        "your-endpoint",
        "your-resource-key",
        "deployment-model");
    var kernel = builder.Build();
    ```

    Her har du et simpelt eksempel p친, hvordan du kan oprette en kernel og tilf칮je en chatkompletteringstjeneste. Semantic Kernel opretter en forbindelse til en ekstern AI-tjeneste, i dette tilf칝lde Azure OpenAI Chat Completion.

- **Plugins**: Disse indkapsler funktioner, som en applikation kan bruge. Der er b친de f칝rdiglavede plugins og brugerdefinerede, som du kan oprette. Et relateret koncept er "prompt-funktioner." I stedet for at give naturlige sprogkoder til funktionskald, udsender du visse funktioner til modellen. Baseret p친 den aktuelle chatkontekst kan modellen v칝lge at kalde en af disse funktioner for at fuldf칮re en anmodning eller foresp칮rgsel. Her er et eksempel:

  ```python
  from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion


  async def main():
      from semantic_kernel.functions import KernelFunctionFromPrompt
      from semantic_kernel.kernel import Kernel

      kernel = Kernel()
      kernel.add_service(AzureChatCompletion())

      user_input = input("User Input:> ")

      kernel_function = KernelFunctionFromPrompt(
          function_name="SummarizeText",
          prompt="""
          Summarize the provided unstructured text in a sentence that is easy to understand.
          Text to summarize: {{$user_input}}
          """,
      )

      response = await kernel_function.invoke(kernel=kernel, user_input=user_input)
      print(f"Model Response: {response}")

      """
      Sample Console Output:

      User Input:> I like dogs
      Model Response: The text expresses a preference for dogs.
      """


  if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
  ```

    ```csharp
    var userInput = Console.ReadLine();

    // Define semantic function inline.
    string skPrompt = @"Summarize the provided unstructured text in a sentence that is easy to understand.
                        Text to summarize: {{$userInput}}";
    
    // create the function from the prompt
    KernelFunction summarizeFunc = kernel.CreateFunctionFromPrompt(
        promptTemplate: skPrompt,
        functionName: "SummarizeText"
    );

    //then import into the current kernel
    kernel.ImportPluginFromFunctions("SemanticFunctions", [summarizeFunc]);

    ```

    Her har du f칮rst en skabelonprompt `skPrompt`, der giver plads til, at brugeren kan indtaste tekst, `$userInput`. Derefter opretter du kernel-funktionen `SummarizeText` og importerer den derefter i kernel med plugin-navnet `SemanticFunctions`. Bem칝rk navnet p친 funktionen, der hj칝lper Semantic Kernel med at forst친, hvad funktionen g칮r, og hvorn친r den skal kaldes.

- **Native funktion**: Der er ogs친 native funktioner, som frameworket kan kalde direkte for at udf칮re opgaven. Her er et eksempel p친 en s친dan funktion, der henter indhold fra en fil:

    ```csharp
    public class NativeFunctions {

        [SKFunction, Description("Retrieve content from local file")]
        public async Task<string> RetrieveLocalFile(string fileName, int maxSize = 5000)
        {
            string content = await File.ReadAllTextAsync(fileName);
            if (content.Length <= maxSize) return content;
            return content.Substring(0, maxSize);
        }
    }
    
    //Import native function
    string plugInName = "NativeFunction";
    string functionName = "RetrieveLocalFile";

   //To add the functions to a kernel use the following function
    kernel.ImportPluginFromType<NativeFunctions>();

    ```

- **Hukommelse**: Abstraherer og forenkler kontekststyring for AI-apps. Ideen med hukommelse er, at dette er noget, LLM'en b칮r vide om. Du kan gemme denne information i en vektorlagring, som ender med at v칝re en in-memory database eller en vektordatabase eller lignende. Her er et eksempel p친 et meget forenklet scenarie, hvor *fakta* tilf칮jes til hukommelsen:

    ```csharp
    var facts = new Dictionary<string,string>();
    facts.Add(
        "Azure Machine Learning; https://learn.microsoft.com/azure/machine-learning/",
        @"Azure Machine Learning is a cloud service for accelerating and
        managing the machine learning project lifecycle. Machine learning professionals,
        data scientists, and engineers can use it in their day-to-day workflows"
    );
    
    facts.Add(
        "Azure SQL Service; https://learn.microsoft.com/azure/azure-sql/",
        @"Azure SQL is a family of managed, secure, and intelligent products
        that use the SQL Server database engine in the Azure cloud."
    );
    
    string memoryCollectionName = "SummarizedAzureDocs";
    
    foreach (var fact in facts) {
        await memoryBuilder.SaveReferenceAsync(
            collection: memoryCollectionName,
            description: fact.Key.Split(";")[1].Trim(),
            text: fact.Value,
            externalId: fact.Key.Split(";")[2].Trim(),
            externalSourceName: "Azure Documentation"
        );
    }
    ```

    Disse fakta gemmes derefter i hukommelsessamlingen `SummarizedAzureDocs`. Dette er et meget forenklet eksempel, men du kan se, hvordan du kan gemme information i hukommelsen, som LLM'en kan bruge.
S친 det er grundl칝ggende om Semantic Kernel-frameworket, hvad med Agent Framework?

## Azure AI Agent Service

Azure AI Agent Service er en nyere tilf칮jelse, introduceret p친 Microsoft Ignite 2024. Det giver mulighed for udvikling og implementering af AI-agenter med mere fleksible modeller, s친som direkte opkald til open-source LLM'er som Llama 3, Mistral og Cohere.

Azure AI Agent Service tilbyder st칝rkere sikkerhedsmekanismer og metoder til datalagring, hvilket g칮r det velegnet til virksomhedsapplikationer.

Det fungerer direkte med multi-agent orkestreringsframeworks som AutoGen og Semantic Kernel.

Denne service er i 칮jeblikket i Public Preview og underst칮tter Python og C# til opbygning af agenter.

Ved hj칝lp af Semantic Kernel Python kan vi oprette en Azure AI Agent med et brugerdefineret plugin:

```python
import asyncio
from typing import Annotated

from azure.identity.aio import DefaultAzureCredential

from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread
from semantic_kernel.contents import ChatMessageContent
from semantic_kernel.contents import AuthorRole
from semantic_kernel.functions import kernel_function


# Define a sample plugin for the sample
class MenuPlugin:
    """A sample Menu Plugin used for the concept sample."""

    @kernel_function(description="Provides a list of specials from the menu.")
    def get_specials(self) -> Annotated[str, "Returns the specials from the menu."]:
        return """
        Special Soup: Clam Chowder
        Special Salad: Cobb Salad
        Special Drink: Chai Tea
        """

    @kernel_function(description="Provides the price of the requested menu item.")
    def get_item_price(
        self, menu_item: Annotated[str, "The name of the menu item."]
    ) -> Annotated[str, "Returns the price of the menu item."]:
        return "$9.99"


async def main() -> None:
    ai_agent_settings = AzureAIAgentSettings.create()

    async with (
        DefaultAzureCredential() as creds,
        AzureAIAgent.create_client(
            credential=creds,
            conn_str=ai_agent_settings.project_connection_string.get_secret_value(),
        ) as client,
    ):
        # Create agent definition
        agent_definition = await client.agents.create_agent(
            model=ai_agent_settings.model_deployment_name,
            name="Host",
            instructions="Answer questions about the menu.",
        )

        # Create the AzureAI Agent using the defined client and agent definition
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
            plugins=[MenuPlugin()],
        )

        # Create a thread to hold the conversation
        # If no thread is provided, a new thread will be
        # created and returned with the initial response
        thread: AzureAIAgentThread | None = None

        user_inputs = [
            "Hello",
            "What is the special soup?",
            "How much does that cost?",
            "Thank you",
        ]

        try:
            for user_input in user_inputs:
                print(f"# User: '{user_input}'")
                # Invoke the agent for the specified thread
                response = await agent.get_response(
                    messages=user_input,
                    thread_id=thread,
                )
                print(f"# {response.name}: {response.content}")
                thread = response.thread
        finally:
            await thread.delete() if thread else None
            await client.agents.delete_agent(agent.id)


if __name__ == "__main__":
    asyncio.run(main())
```

### Centrale begreber

Azure AI Agent Service har f칮lgende centrale begreber:

- **Agent**. Azure AI Agent Service integrerer med Azure AI Foundry. Inden for AI Foundry fungerer en AI-agent som en "intelligent" mikrotjeneste, der kan bruges til at besvare sp칮rgsm친l (RAG), udf칮re handlinger eller fuldst칝ndigt automatisere arbejdsprocesser. Dette opn친s ved at kombinere kraften fra generative AI-modeller med v칝rkt칮jer, der giver adgang til og interaktion med virkelige datakilder. Her er et eksempel p친 en agent:

    ```python
    agent = project_client.agents.create_agent(
        model="gpt-4o-mini",
        name="my-agent",
        instructions="You are helpful agent",
        tools=code_interpreter.definitions,
        tool_resources=code_interpreter.resources,
    )
    ```

    I dette eksempel oprettes en agent med modellen `gpt-4o-mini`, navnet `my-agent` og instruktionerne `You are helpful agent`. Agenten er udstyret med v칝rkt칮jer og ressourcer til at udf칮re opgaver som kodefortolkning.

- **Tr친d og beskeder**. Tr친den er et andet vigtigt begreb. Den repr칝senterer en samtale eller interaktion mellem en agent og en bruger. Tr친de kan bruges til at spore fremskridt i en samtale, gemme kontekstinformation og administrere tilstanden af interaktionen. Her er et eksempel p친 en tr친d:

    ```python
    thread = project_client.agents.create_thread()
    message = project_client.agents.create_message(
        thread_id=thread.id,
        role="user",
        content="Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million",
    )
    
    # Ask the agent to perform work on the thread
    run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)
    
    # Fetch and log all messages to see the agent's response
    messages = project_client.agents.list_messages(thread_id=thread.id)
    print(f"Messages: {messages}")
    ```

    I den tidligere kode oprettes en tr친d. Derefter sendes en besked til tr친den. Ved at kalde `create_and_process_run` bliver agenten bedt om at udf칮re arbejde p친 tr친den. Til sidst hentes og logges beskederne for at se agentens svar. Beskederne viser fremskridtene i samtalen mellem brugeren og agenten. Det er ogs친 vigtigt at forst친, at beskederne kan v칝re af forskellige typer, s친som tekst, billede eller fil, som er resultatet af agentens arbejde, f.eks. et billede eller et tekstsvar. Som udvikler kan du derefter bruge disse oplysninger til yderligere at behandle svaret eller pr칝sentere det for brugeren.

- **Integration med andre AI-frameworks**. Azure AI Agent Service kan interagere med andre frameworks som AutoGen og Semantic Kernel, hvilket betyder, at du kan bygge en del af din app i et af disse frameworks og f.eks. bruge Agent Service som en orkestrator, eller du kan bygge alt i Agent Service.

**Anvendelsesomr친der**: Azure AI Agent Service er designet til virksomhedsapplikationer, der kr칝ver sikker, skalerbar og fleksibel implementering af AI-agenter.

## Hvad er forskellen mellem disse frameworks?

Det lyder som om, der er en del overlap mellem disse frameworks, men der er nogle n칮gleforskelle i forhold til deres design, kapaciteter og m친lgrupper:

- **AutoGen**: Er et eksperimenteringsframework fokuseret p친 banebrydende forskning inden for multi-agent systemer. Det er det bedste sted at eksperimentere og prototype avancerede multi-agent systemer.
- **Semantic Kernel**: Er et produktionsklart agentbibliotek til opbygning af virksomhedsagent-applikationer. Fokuserer p친 h칝ndelsesdrevne, distribuerede agent-applikationer, der muligg칮r flere LLM'er og SLM'er, v칝rkt칮jer og enkelt-/multi-agent designm칮nstre.
- **Azure AI Agent Service**: Er en platform og implementeringstjeneste i Azure Foundry for agenter. Det tilbyder opbygning af forbindelser til tjenester underst칮ttet af Azure Foundry som Azure OpenAI, Azure AI Search, Bing Search og kodeudf칮relse.

Stadig i tvivl om, hvilken du skal v칝lge?

### Anvendelsesomr친der

Lad os se, om vi kan hj칝lpe dig ved at gennemg친 nogle almindelige anvendelsesomr친der:

> Q: Jeg eksperimenterer, l칝rer og bygger proof-of-concept agent-applikationer, og jeg vil kunne bygge og eksperimentere hurtigt
>

>A: AutoGen ville v칝re et godt valg til dette scenarie, da det fokuserer p친 h칝ndelsesdrevne, distribuerede agent-applikationer og underst칮tter avancerede multi-agent designm칮nstre.

> Q: Hvad g칮r AutoGen til et bedre valg end Semantic Kernel og Azure AI Agent Service til dette anvendelsesomr친de?
>
> A: AutoGen er specifikt designet til h칝ndelsesdrevne, distribuerede agent-applikationer, hvilket g칮r det velegnet til automatisering af kodegenerering og dataanalyseopgaver. Det giver de n칮dvendige v칝rkt칮jer og kapaciteter til effektivt at bygge komplekse multi-agent systemer.

>Q: Det lyder som om Azure AI Agent Service ogs친 kunne fungere her, det har v칝rkt칮jer til kodegenerering og mere?

>
> A: Ja, Azure AI Agent Service er en platformtjeneste for agenter og tilf칮jer indbyggede kapaciteter for flere modeller, Azure AI Search, Bing Search og Azure Functions. Det g칮r det nemt at bygge dine agenter i Foundry Portal og implementere dem i stor skala.

> Q: Jeg er stadig forvirret, giv mig bare 칠n mulighed
>
> A: Et godt valg er at bygge din applikation i Semantic Kernel f칮rst og derefter bruge Azure AI Agent Service til at implementere din agent. Denne tilgang giver dig mulighed for nemt at gemme dine agenter, samtidig med at du udnytter kraften til at bygge multi-agent systemer i Semantic Kernel. Derudover har Semantic Kernel en connector i AutoGen, hvilket g칮r det nemt at bruge begge frameworks sammen.

Lad os opsummere de vigtigste forskelle i en tabel:

| Framework | Fokus | Centrale begreber | Anvendelsesomr친der |
| --- | --- | --- | --- |
| AutoGen | H칝ndelsesdrevne, distribuerede agent-applikationer | Agenter, Personas, Funktioner, Data | Kodegenerering, dataanalyseopgaver |
| Semantic Kernel | Forst친else og generering af menneskelignende tekstindhold | Agenter, Moduler, Samarbejde | Naturlig sprogforst친else, indholdsgenerering |
| Azure AI Agent Service | Fleksible modeller, virksomheds-sikkerhed, Kodegenerering, V칝rkt칮jskald | Modularitet, Samarbejde, Procesorkestrering | Sikker, skalerbar og fleksibel implementering af AI-agenter |

Hvad er det ideelle anvendelsesomr친de for hvert af disse frameworks?

## Kan jeg integrere mine eksisterende Azure-칮kosystemv칝rkt칮jer direkte, eller har jeg brug for selvst칝ndige l칮sninger?

Svaret er ja, du kan integrere dine eksisterende Azure-칮kosystemv칝rkt칮jer direkte med Azure AI Agent Service, is칝r fordi det er bygget til at fungere problemfrit med andre Azure-tjenester. Du kunne for eksempel integrere Bing, Azure AI Search og Azure Functions. Der er ogs친 dyb integration med Azure AI Foundry.

For AutoGen og Semantic Kernel kan du ogs친 integrere med Azure-tjenester, men det kan kr칝ve, at du kalder Azure-tjenesterne fra din kode. En anden m친de at integrere p친 er at bruge Azure SDK'er til at interagere med Azure-tjenester fra dine agenter. Derudover, som n칝vnt, kan du bruge Azure AI Agent Service som en orkestrator for dine agenter bygget i AutoGen eller Semantic Kernel, hvilket ville give nem adgang til Azure-칮kosystemet.

### Har du flere sp칮rgsm친l om AI Agent Frameworks?

Deltag i [Azure AI Foundry Discord](https://aka.ms/ai-agents/discord) for at m칮de andre l칝rende, deltage i kontortimer og f친 svar p친 dine sp칮rgsm친l om AI-agenter.

## Referencer

## Forrige lektion

[Introduktion til AI-agenter og anvendelsesomr친der](../01-intro-to-ai-agents/README.md)

## N칝ste lektion

[Forst친else af agentiske designm칮nstre](../03-agentic-design-patterns/README.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 n칮jagtighed, skal det bem칝rkes, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi p친tager os ikke ansvar for eventuelle misforst친elser eller fejltolkninger, der m친tte opst친 som f칮lge af brugen af denne overs칝ttelse.