<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-08-29T15:49:02+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "no"
}
-->
# AI-agenter i produksjon: Observabilitet og evaluering

[![AI-agenter i produksjon](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.no.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

N√•r AI-agenter g√•r fra eksperimentelle prototyper til virkelige applikasjoner, blir det viktig √• forst√• deres oppf√∏rsel, overv√•ke ytelsen og systematisk evaluere resultatene deres.

## L√¶ringsm√•l

Etter √• ha fullf√∏rt denne leksjonen, vil du vite hvordan du/forst√•:
- Grunnleggende konsepter for observabilitet og evaluering av agenter
- Teknikker for √• forbedre agenters ytelse, kostnader og effektivitet
- Hva og hvordan du systematisk evaluerer AI-agentene dine
- Hvordan kontrollere kostnader ved √• sette AI-agenter i produksjon
- Hvordan instrumentere agenter bygget med AutoGen

M√•let er √• gi deg kunnskapen som trengs for √• forvandle "svarte bokser" til transparente, h√•ndterbare og p√•litelige systemer.

_**Merk:** Det er viktig √• distribuere AI-agenter som er trygge og p√•litelige. Ta en titt p√• leksjonen [Bygge p√•litelige AI-agenter](./06-building-trustworthy-agents/README.md) ogs√•._

## Traces og Spans

Observabilitetsverkt√∏y som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerer vanligvis agentkj√∏ringer som traces og spans.

- **Trace** representerer en komplett agentoppgave fra start til slutt (som √• h√•ndtere en brukerforesp√∏rsel).
- **Spans** er individuelle steg innenfor en trace (som √• kalle en spr√•kmodell eller hente data).

![Trace-tre i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uten observabilitet kan en AI-agent f√∏les som en "svart boks" ‚Äì dens interne tilstand og resonnement er uklare, noe som gj√∏r det vanskelig √• diagnostisere problemer eller optimalisere ytelsen. Med observabilitet blir agenter "glassbokser," som gir den n√∏dvendige gjennomsiktigheten for √• bygge tillit og sikre at de fungerer som tiltenkt.

## Hvorfor observabilitet er viktig i produksjonsmilj√∏er

√Ö flytte AI-agenter til produksjonsmilj√∏er introduserer nye utfordringer og krav. Observabilitet er ikke lenger en "hyggelig √• ha"-funksjon, men en kritisk evne:

*   **Feils√∏king og √•rsaksanalyse**: N√•r en agent feiler eller gir et uventet resultat, gir observabilitetsverkt√∏y traces som trengs for √• finne kilden til feilen. Dette er spesielt viktig i komplekse agenter som kan involvere flere LLM-kall, verkt√∏ysinteraksjoner og betinget logikk.
*   **Latens- og kostnadsstyring**: AI-agenter er ofte avhengige av LLM-er og andre eksterne API-er som faktureres per token eller per kall. Observabilitet muliggj√∏r presis sporing av disse kallene, noe som hjelper med √• identifisere operasjoner som er un√∏dvendig trege eller dyre. Dette gj√∏r det mulig for team √• optimalisere prompts, velge mer effektive modeller eller redesigne arbeidsflyter for √• h√•ndtere driftskostnader og sikre en god brukeropplevelse.
*   **Tillit, sikkerhet og samsvar**: I mange applikasjoner er det viktig √• sikre at agenter oppf√∏rer seg trygt og etisk. Observabilitet gir en revisjonsspor av agentens handlinger og beslutninger. Dette kan brukes til √• oppdage og h√•ndtere problemer som promptinjeksjon, generering av skadelig innhold eller feilbehandling av personlig identifiserbar informasjon (PII). For eksempel kan du gjennomg√• traces for √• forst√• hvorfor en agent ga et bestemt svar eller brukte et spesifikt verkt√∏y.
*   **Kontinuerlige forbedringssl√∏yfer**: Observabilitetsdata er grunnlaget for en iterativ utviklingsprosess. Ved √• overv√•ke hvordan agenter presterer i den virkelige verden, kan team identifisere forbedringsomr√•der, samle data for finjustering av modeller og validere effekten av endringer. Dette skaper en tilbakemeldingssl√∏yfe der produksjonsinnsikt fra online evaluering informerer offline eksperimentering og forbedring, noe som f√∏rer til gradvis bedre agentytelse.

## Viktige metrikker √• spore

For √• overv√•ke og forst√• agentens oppf√∏rsel, b√∏r en rekke metrikker og signaler spores. Selv om de spesifikke metrikker kan variere basert p√• agentens form√•l, er noen universelt viktige.

Her er noen av de vanligste metrikker som observabilitetsverkt√∏y overv√•ker:

**Latens:** Hvor raskt svarer agenten? Lange ventetider p√•virker brukeropplevelsen negativt. Du b√∏r m√•le latens for oppgaver og individuelle steg ved √• spore agentkj√∏ringer. For eksempel kan en agent som bruker 20 sekunder p√• alle modellkall akselereres ved √• bruke en raskere modell eller ved √• kj√∏re modellkall parallelt.

**Kostnader:** Hva er kostnaden per agentkj√∏ring? AI-agenter er avhengige av LLM-kall som faktureres per token eller eksterne API-er. Hyppig verkt√∏ybruk eller flere prompts kan raskt √∏ke kostnadene. For eksempel, hvis en agent kaller en LLM fem ganger for marginal kvalitetsforbedring, m√• du vurdere om kostnaden er berettiget eller om du kan redusere antall kall eller bruke en billigere modell. Sanntidsoverv√•king kan ogs√• hjelpe med √• identifisere uventede topper (f.eks. feil som for√•rsaker overdrevne API-l√∏kker).

**Foresp√∏rselsfeil:** Hvor mange foresp√∏rsler feilet agenten? Dette kan inkludere API-feil eller mislykkede verkt√∏ykall. For √• gj√∏re agenten mer robust i produksjon, kan du sette opp fallbacks eller retries. F.eks. hvis LLM-leverand√∏r A er nede, bytter du til LLM-leverand√∏r B som backup.

**Brukerfeedback:** Implementering av direkte brukerevalueringer gir verdifull innsikt. Dette kan inkludere eksplisitte vurderinger (üëç tommel opp/üëé ned, ‚≠ê 1-5 stjerner) eller tekstlige kommentarer. Konsistent negativ feedback b√∏r varsle deg, da dette er et tegn p√• at agenten ikke fungerer som forventet.

**Implisitt brukerfeedback:** Brukeratferd gir indirekte tilbakemelding selv uten eksplisitte vurderinger. Dette kan inkludere umiddelbar omformulering av sp√∏rsm√•l, gjentatte foresp√∏rsler eller klikk p√• en pr√∏v-igjen-knapp. F.eks. hvis du ser at brukere gjentatte ganger stiller det samme sp√∏rsm√•let, er dette et tegn p√• at agenten ikke fungerer som forventet.

**N√∏yaktighet:** Hvor ofte produserer agenten korrekte eller √∏nskelige resultater? Definisjoner av n√∏yaktighet varierer (f.eks. korrekthet i probleml√∏sning, n√∏yaktighet i informasjonsinnhenting, brukertilfredshet). Det f√∏rste steget er √• definere hva suksess betyr for agenten din. Du kan spore n√∏yaktighet via automatiserte sjekker, evalueringspoeng eller oppgavefullf√∏ringsetiketter. For eksempel kan du merke traces som "lyktes" eller "feilet".

**Automatiserte evalueringsmetrikker:** Du kan ogs√• sette opp automatiserte evalueringer. For eksempel kan du bruke en LLM til √• vurdere agentens output, f.eks. om det er nyttig, n√∏yaktig eller ikke. Det finnes ogs√• flere √•pne kildebiblioteker som hjelper deg med √• vurdere ulike aspekter av agenten. F.eks. [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) for √• oppdage skadelig spr√•k eller promptinjeksjon.

I praksis gir en kombinasjon av disse metrikker den beste dekningen av en AI-agents helse. I dette kapitlets [eksempelskript](./code_samples/10_autogen_evaluation.ipynb) viser vi hvordan disse metrikker ser ut i virkelige eksempler, men f√∏rst skal vi l√¶re hvordan en typisk evalueringsarbeidsflyt ser ut.

## Instrumenter agenten din

For √• samle sporingsdata m√• du instrumentere koden din. M√•let er √• instrumentere agentkoden slik at den sender ut traces og metrikker som kan fanges opp, behandles og visualiseres av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har blitt en industristandard for observabilitet av LLM-er. Det gir et sett med API-er, SDK-er og verkt√∏y for √• generere, samle inn og eksportere telemetridata.

Det finnes mange instrumenteringsbiblioteker som omfavner eksisterende agentrammeverk og gj√∏r det enkelt √• eksportere OpenTelemetry spans til et observabilitetsverkt√∏y. Nedenfor er et eksempel p√• instrumentering av en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Eksempelskriptet](./code_samples/10_autogen_evaluation.ipynb) i dette kapitlet vil demonstrere hvordan du instrumenterer AutoGen-agenten din.

**Manuell opprettelse av spans:** Selv om instrumenteringsbiblioteker gir et godt utgangspunkt, er det ofte tilfeller der mer detaljerte eller tilpassede data er n√∏dvendig. Du kan manuelt opprette spans for √• legge til tilpasset applikasjonslogikk. Enda viktigere, de kan berike automatisk eller manuelt opprettede spans med tilpassede attributter (ogs√• kjent som tags eller metadata). Disse attributtene kan inkludere forretningsspesifikke data, mellomliggende beregninger eller annen kontekst som kan v√¶re nyttig for feils√∏king eller analyse, som `user_id`, `session_id` eller `model_version`.

Eksempel p√• manuell opprettelse av traces og spans med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agent-evaluering

Observabilitet gir oss metrikker, men evaluering er prosessen med √• analysere disse dataene (og utf√∏re tester) for √• avgj√∏re hvor godt en AI-agent presterer og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrikker, hvordan bruker du dem til √• vurdere agenten og ta beslutninger?

Regelmessig evaluering er viktig fordi AI-agenter ofte er ikke-deterministiske og kan utvikle seg (gjennom oppdateringer eller endringer i modellatferd) ‚Äì uten evaluering ville du ikke vite om din "smarte agent" faktisk gj√∏r jobben sin godt eller om den har blitt d√•rligere.

Det finnes to kategorier av evalueringer for AI-agenter: **offline evaluering** og **online evaluering**. Begge er verdifulle, og de utfyller hverandre. Vi begynner vanligvis med offline evaluering, da dette er det minste n√∏dvendige steget f√∏r distribusjon av en agent.

### Offline evaluering

![Datasett-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette inneb√¶rer √• evaluere agenten i et kontrollert milj√∏, vanligvis ved bruk av testdatasett, ikke live brukerforesp√∏rsler. Du bruker kuraterte datasett der du vet hva det forventede resultatet eller korrekt oppf√∏rsel er, og kj√∏rer agenten p√• disse.

For eksempel, hvis du har bygget en agent for matematiske tekstoppgaver, kan du ha et [testdatasett](https://huggingface.co/datasets/gsm8k) med 100 oppgaver med kjente svar. Offline evaluering gj√∏res ofte under utvikling (og kan v√¶re en del av CI/CD-pipelines) for √• sjekke forbedringer eller beskytte mot regresjoner. Fordelen er at det er **repeterbart, og du kan f√• klare n√∏yaktighetsmetrikker siden du har fasit**. Du kan ogs√• simulere brukerforesp√∏rsler og m√•le agentens svar opp mot ideelle svar eller bruke automatiserte metrikker som beskrevet ovenfor.

Den st√∏rste utfordringen med offline evaluering er √• sikre at testdatasettet ditt er omfattende og forblir relevant ‚Äì agenten kan prestere godt p√• et fast testsett, men m√∏te helt andre foresp√∏rsler i produksjon. Derfor b√∏r du holde testsettene oppdatert med nye edge cases og eksempler som reflekterer virkelige scenarier. En blanding av sm√• "smoke test"-caser og st√∏rre evalueringssett er nyttig: sm√• sett for raske sjekker og st√∏rre sett for bredere ytelsesmetrikker.

### Online evaluering

![Oversikt over observabilitetsmetrikker](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til √• evaluere agenten i et levende, virkelighetsn√¶rt milj√∏, alts√• under faktisk bruk i produksjon. Online evaluering inneb√¶rer √• overv√•ke agentens ytelse p√• ekte brukerinteraksjoner og kontinuerlig analysere resultatene.

For eksempel kan du spore suksessrater, brukertilfredshetspoeng eller andre metrikker p√• live trafikk. Fordelen med online evaluering er at den **fanger opp ting du kanskje ikke foruts√• i et laboratoriemilj√∏** ‚Äì du kan observere modellens drift over tid (om agentens effektivitet reduseres etter hvert som innspillm√∏nstre endres) og oppdage uventede foresp√∏rsler eller situasjoner som ikke var i testdataene dine. Den gir et sant bilde av hvordan agenten oppf√∏rer seg i praksis.

Online evaluering inneb√¶rer ofte √• samle implisitt og eksplisitt brukerfeedback, som diskutert, og muligens kj√∏re shadow tests eller A/B-tester (der en ny versjon av agenten kj√∏rer parallelt for √• sammenligne med den gamle). Utfordringen er at det kan v√¶re vanskelig √• f√• p√•litelige etiketter eller poeng for live interaksjoner ‚Äì du kan v√¶re avhengig av brukerfeedback eller nedstr√∏msmetrikker (som om brukeren klikket p√• resultatet).

### Kombinere de to

Online og offline evalueringer utelukker ikke hverandre; de utfyller hverandre sterkt. Innsikt fra online overv√•king (f.eks. nye typer brukerforesp√∏rsler der agenten presterer d√•rlig) kan brukes til √• utvide og forbedre offline testdatasett. Omvendt kan agenter som presterer godt i offline tester, deretter distribueres og overv√•kes online med st√∏rre selvtillit.

Faktisk adopterer mange team en sl√∏yfe:

_evaluere offline -> distribuere -> overv√•ke online -> samle nye feiltilfeller -> legge til i offline datasett -> forbedre agent -> gjenta_.

## Vanlige problemer

N√•r du distribuerer AI-agenter til produksjon, kan du m√∏te ulike utfordringer. Her er noen vanlige problemer og deres potensielle l√∏sninger:

| **Problem**    | **Potensiell l√∏sning**   |
| ------------- | ------------------ |
| AI-agenten utf√∏rer ikke oppgaver konsekvent | - Forbedre prompten som gis til AI-agenten; v√¶r tydelig p√• m√•lene.<br>- Identifiser hvor det kan hjelpe √• dele opp oppgavene i deloppgaver og h√•ndtere dem med flere agenter. |
| AI-agenten havner i kontinuerlige l√∏kker  | - S√∏rg for at du har klare avslutningsbetingelser slik at agenten vet n√•r prosessen skal stoppes. |

## Vanlige Problemer og L√∏sninger

Her er noen vanlige problemer du kan m√∏te p√• n√•r du jobber med AI-agenter, og forslag til l√∏sninger:

| **Problem**                                   | **L√∏sning**                                                                                     |
|-----------------------------------------------|-------------------------------------------------------------------------------------------------|
| Agenten gir feil eller ufullstendige svar     | - S√∏rg for at treningsdataene er omfattende og relevante.<br>- Juster promptene for √• v√¶re mer spesifikke. |
| Agenten bruker for mye tid p√• oppgaver        | - Optimaliser agentens arbeidsflyt.<br>- Bruk mindre modeller for enklere oppgaver.            |
| Agenten feiler p√• komplekse oppgaver          | - For komplekse oppgaver som krever resonnering og planlegging, bruk en st√∏rre modell som er spesialisert for slike oppgaver. |
| Verkt√∏y som brukes av AI-agenten fungerer d√•rlig | - Test og valider verkt√∏yets output utenfor agentsystemet.<br>- Forbedre definerte parametere, prompts og navngivning av verkt√∏y. |
| Multi-agent-systemet fungerer ikke konsekvent | - Forbedre promptene som gis til hver agent for √• sikre at de er spesifikke og tydelig skiller seg fra hverandre.<br>- Bygg et hierarkisk system med en "rute"- eller kontrollagent som bestemmer hvilken agent som er riktig. |

Mange av disse problemene kan identifiseres mer effektivt med observabilitet p√• plass. Sporene og m√•ledataene vi diskuterte tidligere hjelper med √• finne n√∏yaktig hvor i agentens arbeidsflyt problemene oppst√•r, noe som gj√∏r feils√∏king og optimalisering mye mer effektivt.

## H√•ndtering av Kostnader

Her er noen strategier for √• h√•ndtere kostnadene ved √• sette AI-agenter i produksjon:

**Bruke Mindre Modeller:** Sm√• spr√•kmodeller (SLMs) kan fungere godt for visse agentiske bruksomr√•der og vil redusere kostnadene betydelig. Som nevnt tidligere, er det beste √• bygge et evalueringssystem for √• bestemme og sammenligne ytelsen mot st√∏rre modeller for √• forst√• hvor godt en SLM vil fungere for ditt bruksomr√•de. Vurder √• bruke SLMs for enklere oppgaver som intensjonsklassifisering eller parameteruttrekk, og reserver st√∏rre modeller for komplekse resonneringsoppgaver.

**Bruke en Ruter-Modell:** En lignende strategi er √• bruke en variasjon av modeller og st√∏rrelser. Du kan bruke en LLM/SLM eller serverl√∏se funksjoner for √• rute foresp√∏rsler basert p√• kompleksitet til de modellene som passer best. Dette vil ogs√• bidra til √• redusere kostnader samtidig som ytelsen opprettholdes for de riktige oppgavene. For eksempel kan du rute enkle foresp√∏rsler til mindre, raskere modeller, og kun bruke dyre, store modeller for komplekse resonneringsoppgaver.

**Bufring av Svar:** Identifisere vanlige foresp√∏rsler og oppgaver og gi svarene f√∏r de g√•r gjennom ditt agentiske system er en god m√•te √• redusere volumet av lignende foresp√∏rsler. Du kan til og med implementere en flyt for √• identifisere hvor lik en foresp√∏rsel er med dine bufrede foresp√∏rsler ved hjelp av enklere AI-modeller. Denne strategien kan redusere kostnadene betydelig for ofte stilte sp√∏rsm√•l eller vanlige arbeidsflyter.

## La oss se hvordan dette fungerer i praksis

I [eksempelfilen for denne seksjonen](./code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√• hvordan vi kan bruke observasjonsverkt√∏y for √• overv√•ke og evaluere agenten v√•r.

### Har du flere sp√∏rsm√•l om AI-agenter i produksjon?

Bli med i [Azure AI Foundry Discord](https://aka.ms/ai-agents/discord) for √• m√∏te andre l√¶rende, delta p√• kontortid og f√• svar p√• dine sp√∏rsm√•l om AI-agenter.

## Forrige Leksjon

[Metakognitivt Designm√∏nster](../09-metacognition/README.md)

## Neste Leksjon

[Agentiske Protokoller](../11-agentic-protocols/README.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.