{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksempel på bruk av Semantic Kernel-verktøy\n",
    "\n",
    "Dette dokumentet gir en oversikt og forklaring av koden som brukes til å lage et verktøy basert på Semantic Kernel som integreres med Azure AI Search for Retrieval-Augmented Generation (RAG). Eksemplet viser hvordan man bygger en AI-agent som henter reisedokumenter fra en Azure AI Search-indeks, utvider brukerforespørsler med semantiske søkeresultater, og strømmer detaljerte reiseforslag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importere Pakker\n",
    "Følgende kode importerer de nødvendige pakkene:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opprette Semantic Kernel og AI-tjeneste\n",
    "\n",
    "En instans av Semantic Kernel opprettes og konfigureres med en asynkron OpenAI chat fullføringstjeneste. Tjenesten legges til kjernen for bruk i generering av svar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Initialize the asynchronous OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "    base_url=\"https://models.inference.ai.azure.com/\"\n",
    ")\n",
    "\n",
    "# Create the OpenAI Chat Completion Service\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definere PromptPlugin\n",
    "\n",
    "PromptPlugin er et innebygd plugin som definerer en funksjon for å bygge en utvidet prompt ved hjelp av kontekst for gjenfinning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchPlugin:\n",
    "\n",
    "    def __init__(self, search_client: SearchClient):\n",
    "        self.search_client = search_client\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"build_augmented_prompt\",\n",
    "        description=\"Build an augmented prompt using retrieval context or function results.\",\n",
    "    )\n",
    "    def build_augmented_prompt(self, query: str, retrieval_context: str) -> str:\n",
    "        return (\n",
    "            f\"Retrieved Context:\\n{retrieval_context}\\n\\n\"\n",
    "            f\"User Query: {query}\\n\\n\"\n",
    "            \"First review the retrieved context, if this does not answer the query, try calling an available plugin functions that might give you an answer. If no context is available, say so.\"\n",
    "        )\n",
    "    \n",
    "    @kernel_function(\n",
    "        name=\"retrieve_documents\",\n",
    "        description=\"Retrieve documents from the Azure Search service.\",\n",
    "    )\n",
    "    def get_retrieval_context(self, query: str) -> str:\n",
    "        results = self.search_client.search(query)\n",
    "        context_strings = []\n",
    "        for result in results:\n",
    "            context_strings.append(f\"Document: {result['content']}\")\n",
    "        return \"\\n\\n\".join(context_strings) if context_strings else \"No results found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherInfoPlugin:\n",
    "    \"\"\"A Plugin that provides the average temperature for a travel destination.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Dictionary of destinations and their average temperatures\n",
    "        self.destination_temperatures = {\n",
    "            \"maldives\": \"82°F (28°C)\",\n",
    "            \"swiss alps\": \"45°F (7°C)\",\n",
    "            \"african safaris\": \"75°F (24°C)\"\n",
    "        }\n",
    "\n",
    "    @kernel_function(description=\"Get the average temperature for a specific travel destination.\")\n",
    "    def get_destination_temperature(self, destination: str) -> Annotated[str, \"Returns the average temperature for the destination.\"]:\n",
    "        \"\"\"Get the average temperature for a travel destination.\"\"\"\n",
    "        # Normalize the input destination (lowercase)\n",
    "        normalized_destination = destination.lower()\n",
    "\n",
    "        # Look up the temperature for the destination\n",
    "        if normalized_destination in self.destination_temperatures:\n",
    "            return f\"The average temperature in {destination} is {self.destination_temperatures[normalized_destination]}.\"\n",
    "        else:\n",
    "            return f\"Sorry, I don't have temperature information for {destination}. Available destinations are: Maldives, Swiss Alps, and African safaris.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisering av vektordatabasen\n",
    "\n",
    "Vi initialiserer Azure AI Search med vedvarende lagring og legger til forbedrede eksempeldokumenter. Azure AI Search vil bli brukt til å lagre og hente dokumenter som gir kontekst for å generere nøyaktige svar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure AI Search with persistent storage\n",
    "search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = \"travel-documents\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Define the index schema\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String)\n",
    "]\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "# Check if index already exists if not, create it\n",
    "try:\n",
    "    existing_index = index_client.get_index(index_name)\n",
    "    print(f\"Index '{index_name}' already exists, using the existing index.\")\n",
    "except Exception:\n",
    "    # Create the index if it doesn't exist\n",
    "    print(f\"Creating new index '{index_name}'...\")\n",
    "    index_client.create_index(index)\n",
    "\n",
    "\n",
    "# Enhanced sample documents\n",
    "documents = [\n",
    "    {\"id\": \"1\", \"content\": \"Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\"},\n",
    "    {\"id\": \"2\", \"content\": \"Our premium travel services include personalized itinerary planning and 24/7 concierge support.\"},\n",
    "    {\"id\": \"3\", \"content\": \"Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\"},\n",
    "    {\"id\": \"4\", \"content\": \"Popular destinations include the Maldives, Swiss Alps, and African safaris.\"},\n",
    "    {\"id\": \"5\", \"content\": \"Contoso Travel provides exclusive access to boutique hotels and private guided tours.\"}\n",
    "]\n",
    "\n",
    "# Add documents to the index\n",
    "search_client.upload_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    plugins=[SearchPlugin(search_client=search_client), WeatherInfoPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"Answer travel queries using the provided tools and context. If context is provided, do not say 'I have no context for that.'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kjøre agenten med streaming-kall\n",
    "\n",
    "Den viktigste asynkrone løkken oppretter en tråd for samtalen og, for hver brukerinput, slik at agenten ser gjenfinningskonteksten. Brukermeldingen legges også til, og deretter kalles agenten ved bruk av streaming. Utdataene skrives ut etter hvert som de strømmer inn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Can you explain Contoso's travel insurance coverage?\",\n",
    "        \"What is the average temperature of the Maldives?\",\n",
    "        \"What is a good cold destination offered by Contoso and what is it average temperature?\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        html_output = (\n",
    "            f\"<div style='margin-bottom:10px'>\"\n",
    "            f\"<div style='font-weight:bold'>User:</div>\"\n",
    "            f\"<div style='margin-left:20px'>{user_input}</div></div>\"\n",
    "        )\n",
    "\n",
    "        agent_name = None\n",
    "        full_response: list[str] = []\n",
    "        function_calls: list[str] = []\n",
    "\n",
    "        # Buffer to reconstruct streaming function call\n",
    "        current_function_name = None\n",
    "        argument_buffer = \"\"\n",
    "\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            thread = response.thread\n",
    "            agent_name = response.name\n",
    "            content_items = list(response.items)\n",
    "\n",
    "            for item in content_items:\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    if item.function_name:\n",
    "                        current_function_name = item.function_name\n",
    "\n",
    "                    # Accumulate arguments (streamed in chunks)\n",
    "                    if isinstance(item.arguments, str):\n",
    "                        argument_buffer += item.arguments\n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    # Finalize any pending function call before showing result\n",
    "                    if current_function_name:\n",
    "                        formatted_args = argument_buffer.strip()\n",
    "                        try:\n",
    "                            parsed_args = json.loads(formatted_args)\n",
    "                            formatted_args = json.dumps(parsed_args)\n",
    "                        except Exception:\n",
    "                            pass  # leave as raw string\n",
    "\n",
    "                        function_calls.append(f\"Calling function: {current_function_name}({formatted_args})\")\n",
    "                        current_function_name = None\n",
    "                        argument_buffer = \"\"\n",
    "\n",
    "                    function_calls.append(f\"\\nFunction Result:\\n\\n{item.result}\")\n",
    "                elif isinstance(item, StreamingTextContent) and item.text:\n",
    "                    full_response.append(item.text)\n",
    "\n",
    "        if function_calls:\n",
    "            html_output += (\n",
    "                \"<div style='margin-bottom:10px'>\"\n",
    "                \"<details>\"\n",
    "                \"<summary style='cursor:pointer; font-weight:bold; color:#0066cc;'>Function Calls (click to expand)</summary>\"\n",
    "                \"<div style='margin:10px; padding:10px; background-color:#f8f8f8; \"\n",
    "                \"border:1px solid #ddd; border-radius:4px; white-space:pre-wrap; font-size:14px; color:#333;'>\"\n",
    "                f\"{chr(10).join(function_calls)}\"\n",
    "                \"</div></details></div>\"\n",
    "            )\n",
    "\n",
    "        html_output += (\n",
    "            \"<div style='margin-bottom:20px'>\"\n",
    "            f\"<div style='font-weight:bold'>{agent_name or 'Assistant'}:</div>\"\n",
    "            f\"<div style='margin-left:20px; white-space:pre-wrap'>{''.join(full_response)}</div></div><hr>\"\n",
    "        )\n",
    "\n",
    "        display(HTML(html_output))\n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understood! Please provide the markdown file you'd like me to translate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det originale dokumentet på sitt opprinnelige språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "638589ff731b23cc6c6629dfa7804be9",
   "translation_date": "2025-08-29T16:49:06+00:00",
   "source_file": "05-agentic-rag/code_samples/05-semantic-kernel-azuresearch.ipynb",
   "language_code": "no"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}