{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‡§∏‡•á‡§Æ‡•Ö‡§Ç‡§ü‡§ø‡§ï ‡§ï‡§∞‡•ç‡§®‡§≤‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§∏‡§π ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•á\n",
    "\n",
    "‡§π‡•á ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï ‡§∏‡•á‡§Æ‡•Ö‡§Ç‡§ü‡§ø‡§ï ‡§ï‡§∞‡•ç‡§®‡§≤‡§ö‡•ç‡§Ø‡§æ ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•à‡§∂‡§ø‡§∑‡•ç‡§ü‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∏‡§æ ‡§ï‡§∞‡§æ‡§Ø‡§ö‡§æ ‡§Ø‡§æ‡§ö‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§∞‡§§‡•á, ‡§§‡§∏‡•á‡§ö ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ü‡§ø‡§ï‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§ö‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∏‡§æ ‡§ï‡§∞‡§æ‡§Ø‡§ö‡§æ ‡§π‡•á ‡§¶‡§æ‡§ñ‡§µ‡§§‡•á. ‡§π‡•á ‡§¶‡•Ä‡§∞‡•ç‡§ò ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ AI ‡§è‡§ú‡§Ç‡§ü ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§Ü‡§π‡•á, ‡§ú‡•á ‡§ü‡•ã‡§ï‡§® ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§ì‡§≤‡§æ‡§Ç‡§°‡§§ ‡§®‡§æ‡§π‡•Ä‡§§.\n",
    "\n",
    "## ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§æ‡§Ø ‡§∂‡§ø‡§ï‡§æ‡§≤:\n",
    "1. **‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•á**: ‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§ö‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§Ü‡§™‡•ã‡§Ü‡§™ ‡§ï‡§∏‡§æ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™ ‡§ï‡§∞‡§æ‡§Ø‡§ö‡§æ\n",
    "2. **‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°**: ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡§∏‡§Ç‡§§‡•Ä ‡§Ü‡§£‡§ø ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§Æ‡§æ‡§ó‡•ã‡§µ‡§æ ‡§†‡•á‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§è‡§ï ‡§∏‡§§‡§§ ‡§Æ‡•á‡§Æ‡§∞‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä\n",
    "3. **‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞ ‡§ü‡•ç‡§∞‡•Ö‡§ï‡§ø‡§Ç‡§ó**: ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§π ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§∂‡§ø‡§µ‡§æ‡§Ø ‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∏‡§æ ‡§¨‡§¶‡§≤‡§§‡•ã ‡§π‡•á ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§ï‡§∞‡§æ\n",
    "\n",
    "## ‡§™‡•Ç‡§∞‡•ç‡§µ‡§§‡§Ø‡§æ‡§∞‡•Ä:\n",
    "- ‡§™‡§∞‡•ç‡§Ø‡§æ‡§µ‡§∞‡§£‡•Ä‡§Ø ‡§µ‡•ç‡§π‡•á‡§∞‡§ø‡§è‡§¨‡§≤‡•ç‡§∏‡§∏‡§π Azure OpenAI ‡§∏‡•á‡§ü‡§Ö‡§™\n",
    "- ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§ß‡§°‡•ç‡§Ø‡§æ‡§Ç‡§Æ‡§ß‡•Ç‡§® ‡§Æ‡•Ç‡§≤‡§≠‡•Ç‡§§ ‡§è‡§ú‡§Ç‡§ü ‡§∏‡§Ç‡§ï‡§≤‡•ç‡§™‡§®‡§æ‡§Ç‡§ö‡•Ä ‡§∏‡§Æ‡§ú\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.completion_usage import CompletionUsage\n",
    "from semantic_kernel.contents import ChatHistorySummarizationReducer\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§∏‡§Æ‡§ú‡•Ç‡§® ‡§ò‡•á‡§£‡•á\n",
    "\n",
    "### ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§Æ‡•ç‡§π‡§£‡§ú‡•á ‡§ï‡§æ‡§Ø?\n",
    "\n",
    "**‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°** ‡§π‡•Ä ‡§è‡§ï ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§Æ‡•á‡§Æ‡§∞‡•Ä ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä ‡§Ü‡§π‡•á ‡§ú‡•Ä ‡§è‡§ú‡§Ç‡§ü‡•ç‡§∏ ‡§µ‡§æ‡§™‡§∞‡§§‡§æ‡§§:\n",
    "- **‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§Ç‡§ö‡§æ ‡§Æ‡§æ‡§ó‡•ã‡§µ‡§æ ‡§†‡•á‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä**: ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ï‡§æ‡§Ø ‡§ï‡•á‡§≤‡•á ‡§Ü‡§π‡•á ‡§§‡•á ‡§®‡•ã‡§Ç‡§¶‡§µ‡§£‡•á\n",
    "- **‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡•ç‡§∞‡§æ‡§ß‡§æ‡§®‡•ç‡§Ø‡•á ‡§∏‡§æ‡§†‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä**: ‡§Ü‡§µ‡§°‡•Ä, ‡§®‡§æ‡§™‡§∏‡§Ç‡§§‡•Ä ‡§Ü‡§£‡§ø ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§£‡•á\n",
    "- **‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ü‡§ø‡§ï‡§µ‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä**: ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§∏‡§π‡§ú ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§†‡•á‡§µ‡§£‡•á\n",
    "- **‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§™‡•Å‡§®‡§∞‡§æ‡§µ‡•É‡§§‡•ç‡§§‡•Ä ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä**: ‡§è‡§ï‡§æ‡§ö ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§Ç‡§ö‡•Ä ‡§µ‡§æ‡§∞‡§Ç‡§µ‡§æ‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞‡§£‡§æ ‡§ü‡§æ‡§≥‡§£‡•á\n",
    "\n",
    "### ‡§π‡•á ‡§ï‡§∏‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡§∞‡§§‡•á:\n",
    "1. **‡§≤‡§ø‡§π‡§ø‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ**: ‡§è‡§ú‡§Ç‡§ü ‡§®‡§µ‡•Ä‡§® ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∂‡§ø‡§ï‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞ ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§∞‡§§‡•ã\n",
    "2. **‡§µ‡§æ‡§ö‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ**: ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§ò‡•á‡§§‡§æ‡§®‡§æ ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§ö‡§æ ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§ò‡•á‡§§‡•ã\n",
    "3. **‡§∏‡•ç‡§•‡§ø‡§∞‡§§‡§æ**: ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§ü‡§ø‡§ï‡•Ç‡§® ‡§∞‡§æ‡§π‡§§‡•á, ‡§ú‡§∞‡•Ä ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ù‡§æ‡§≤‡§æ ‡§§‡§∞‡•Ä\n",
    "\n",
    "‡§Ø‡§æ‡§ö‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§è‡§ú‡§Ç‡§ü‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•à‡§Ø‡§ï‡•ç‡§§‡§ø‡§ï ‡§®‡•ã‡§ü‡§¨‡•Å‡§ï‡§∏‡§æ‡§∞‡§ñ‡§æ ‡§ï‡§∞‡§æ, ‡§ú‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏‡§æ‡§≤‡§æ ‡§™‡•Ç‡§∞‡§ï ‡§Ö‡§∏‡§§‡•ã.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create Azure OpenAI service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI service configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§™‡•ç‡§≤‡§ó‡§á‡§® ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§æ\n",
    "\n",
    "‡§π‡§æ ‡§™‡•ç‡§≤‡§ó‡§á‡§® ‡§è‡§ú‡§Ç‡§ü‡§≤‡§æ ‡§∏‡§§‡§§‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§´‡§æ‡§á‡§≤‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§µ‡§æ‡§ö‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§Ü‡§£‡§ø ‡§≤‡§ø‡§π‡§ø‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§™‡§∞‡§µ‡§æ‡§®‡§ó‡•Ä ‡§¶‡•á‡§§‡•ã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchpadPlugin:\n",
    "    \"\"\"Plugin for managing agent scratchpad - a persistent memory for user preferences and completed tasks\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath: str = \"agent_scratchpad.md\"):\n",
    "        self.filepath = Path(filepath)\n",
    "        # Initialize scratchpad if it doesn't exist\n",
    "        if not self.filepath.exists():\n",
    "            self.filepath.write_text(\"# Agent Scratchpad\\n\\n## User Preferences\\n\\n## Completed Tasks\\n\\n\")\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Read the current agent scratchpad to get user's travel preferences and completed tasks\"\n",
    "    )\n",
    "    def read_scratchpad(self) -> Annotated[str, \"The contents of the agent scratchpad\"]:\n",
    "        \"\"\"Read the current scratchpad contents\"\"\"\n",
    "        return self.filepath.read_text()\n",
    "    \n",
    "    @kernel_function(\n",
    "        description=\"Update the agent scratchpad with new user's travel preference or completed tasks\"\n",
    "    )\n",
    "    def update_scratchpad(\n",
    "        self,\n",
    "        category: Annotated[str, \"Category to update: 'preferences' or 'tasks'\"],\n",
    "        content: Annotated[str, \"The new content to add\"]\n",
    "    ) -> Annotated[str, \"Confirmation of the update\"]:\n",
    "        \"\"\"Update the scratchpad with new information\"\"\"\n",
    "        current_content = self.filepath.read_text()\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        if category.lower() == \"preferences\":\n",
    "            # Find the preferences section and append\n",
    "            lines = current_content.split(\"\\n\")\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"## User Preferences\" in line:\n",
    "                    lines.insert(i + 1, f\"\\n- [{timestamp}] {content}\")\n",
    "                    break\n",
    "            current_content = \"\\n\".join(lines)\n",
    "        elif category.lower() == \"tasks\":\n",
    "            # Find the tasks section and append\n",
    "            lines = current_content.split(\"\\n\")\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"## Completed Tasks\" in line:\n",
    "                    lines.insert(i + 1, f\"\\n- [{timestamp}] {content}\")\n",
    "                    break\n",
    "            current_content = \"\\n\".join(lines)\n",
    "        \n",
    "        self.filepath.write_text(current_content)\n",
    "        return f\"‚úÖ Scratchpad updated with {category}: {content}\"\n",
    "\n",
    "# Create the scratchpad plugin\n",
    "scratchpad_plugin = ScratchpadPlugin(\"vacation_agent_scratchpad.md\")\n",
    "print(\"üìù Scratchpad plugin created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™‡§ï ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§ï‡§∞‡§æ\n",
    "\n",
    "ChatHistorySummarizationReducer ‡§Ü‡§™‡•ã‡§Ü‡§™ ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§ö‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™‡§ø‡§§ ‡§ï‡§∞‡§§‡•ã ‡§ú‡•á‡§µ‡•ç‡§π‡§æ ‡§§‡•ã ‡§†‡§∞‡§æ‡§µ‡§ø‡§ï ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡•á‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ú‡§æ‡§∏‡•ç‡§§ ‡§π‡•ã‡§§‡•ã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure reduction parameters\n",
    "REDUCER_TARGET_COUNT = 5  # Target number of messages to keep after reduction\n",
    "REDUCER_THRESHOLD = 15    # Trigger reduction when message count exceeds this\n",
    "\n",
    "# Create the history summarization reducer\n",
    "history_reducer = ChatHistorySummarizationReducer(\n",
    "    service=chat_service,\n",
    "    target_count=REDUCER_TARGET_COUNT,\n",
    "    threshold_count=REDUCER_THRESHOLD,\n",
    ")\n",
    "\n",
    "print(f\"üîÑ Chat History Reducer configured:\")\n",
    "print(f\"   - Reduction triggered at: {REDUCER_THRESHOLD} messages\")\n",
    "print(f\"   - Reduces history to: {REDUCER_TARGET_COUNT} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§∏‡•Å‡§ü‡•ç‡§ü‡•Ä ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§è‡§ú‡§Ç‡§ü ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§æ\n",
    "\n",
    "‡§π‡§æ ‡§è‡§ú‡§Ç‡§ü ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§Ç‡§®‡§æ ‡§∏‡•Å‡§ü‡•ç‡§ü‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•á ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡•á‡§≤ ‡§Ü‡§£‡§ø ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§¶‡•ç‡§µ‡§æ‡§∞‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ü‡§ø‡§ï‡§µ‡•Ç‡§® ‡§†‡•á‡§µ‡•á‡§≤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vacation planning agent with detailed instructions\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=\"VacationPlannerAgent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful vacation planning assistant. Your job is to help users plan their perfect vacation.\n",
    "    \n",
    "    CRITICAL SCRATCHPAD RULES - YOU MUST FOLLOW THESE:\n",
    "    1. FIRST ACTION: When starting ANY conversation, immediately call read_scratchpad() to check existing preferences\n",
    "    2. AFTER LEARNING PREFERENCES: When user mentions ANY preference (destinations, activities, budget, dates), \n",
    "       immediately call update_scratchpad() with category 'preferences'\n",
    "    3. AFTER COMPLETING TASKS: When you finish creating an itinerary or completing any task,\n",
    "       immediately call update_scratchpad() with category 'tasks'\n",
    "    4. BEFORE NEW ITINERARY: Always call read_scratchpad() before creating any itinerary\n",
    "    \n",
    "    EXAMPLES OF WHEN TO UPDATE SCRATCHPAD:\n",
    "    - User says \"I love beaches\" ‚Üí update_scratchpad('preferences', 'Loves beach destinations')\n",
    "    - User says \"budget is $3000\" ‚Üí update_scratchpad('preferences', 'Budget: $3000 per person for a week')\n",
    "    - You create an itinerary ‚Üí update_scratchpad('tasks', 'Created Bali itinerary for beach vacation')\n",
    "    \n",
    "    PLANNING PROCESS:\n",
    "    1. Read scratchpad first\n",
    "    2. Ask about preferences if not found\n",
    "    3. Update scratchpad with new information\n",
    "    4. Create detailed itineraries\n",
    "    5. Update scratchpad with completed tasks\n",
    "    \n",
    "    BE EXPLICIT: Always announce when you're checking or updating the scratchpad.\n",
    "    \"\"\",\n",
    "    plugins=[scratchpad_plugin],\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Vacation Planning Agent created with enhanced scratchpad instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token tracking class\n",
    "class TokenTracker:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        self.total_usage = CompletionUsage()\n",
    "        self.reduction_events = []  # Track when reductions occur\n",
    "\n",
    "    def add_usage(self, usage: CompletionUsage, message_num: int, thread_length: int = None):\n",
    "        if usage:\n",
    "            self.total_usage += usage\n",
    "            entry = {\n",
    "                \"message_num\": message_num,\n",
    "                \"prompt_tokens\": usage.prompt_tokens,\n",
    "                \"completion_tokens\": usage.completion_tokens,\n",
    "                \"total_tokens\": usage.prompt_tokens + usage.completion_tokens,\n",
    "                \"cumulative_tokens\": self.total_usage.prompt_tokens + self.total_usage.completion_tokens,\n",
    "                \"thread_length\": thread_length\n",
    "            }\n",
    "            self.history.append(entry)\n",
    "\n",
    "    def mark_reduction(self, message_num: int):\n",
    "        self.reduction_events.append(message_num)\n",
    "\n",
    "    def display_chart(self):\n",
    "        \"\"\"Display a chart showing token usage per message and the impact of reduction\"\"\"\n",
    "        if not self.history:\n",
    "            return\n",
    "\n",
    "        html = \"<div style='font-family: monospace; background: #2d2d2d; color: #f0f0f0; padding: 15px; border-radius: 8px; border: 1px solid #444;'>\"\n",
    "        html += \"<h4 style='color: #4fc3f7; margin-top: 0;'>üìä Token Usage Analysis</h4>\"\n",
    "        html += \"<pre style='color: #f0f0f0; margin: 0;'>\"\n",
    "\n",
    "        # Show prompt tokens per message to see reduction impact\n",
    "        html += \"<span style='color: #81c784;'>Prompt Tokens per Message (shows conversation context size):</span>\\n\"\n",
    "        max_prompt = max(h[\"prompt_tokens\"] for h in self.history)\n",
    "        scale = 50 / max_prompt if max_prompt > 0 else 1\n",
    "\n",
    "        for i, h in enumerate(self.history):\n",
    "            bar_length = int(h[\"prompt_tokens\"] * scale)\n",
    "            bar = \"‚ñà\" * bar_length\n",
    "            reduction_marker = \" <span style='color: #ff6b6b;'>‚Üê REDUCTION!</span>\" if h[\n",
    "                \"message_num\"] in self.reduction_events else \"\"\n",
    "            html += f\"<span style='color: #aaa;'>Msg {h['message_num']:2d}:</span> <span style='color: #4fc3f7;'>{bar}</span> <span style='color: #ffd93d;'>{h['prompt_tokens']:,} tokens</span>{reduction_marker}\\n\"\n",
    "\n",
    "        html += \"\\n</pre></div>\"\n",
    "        display(HTML(html))\n",
    "\n",
    "        # Calculate reduction impact\n",
    "        if self.reduction_events:\n",
    "            # Find the message before and after first reduction\n",
    "            first_reduction_msg = self.reduction_events[0]\n",
    "            before_reduction = None\n",
    "            after_reduction = None\n",
    "\n",
    "            for h in self.history:\n",
    "                if h[\"message_num\"] == first_reduction_msg - 1:\n",
    "                    before_reduction = h[\"prompt_tokens\"]\n",
    "                elif h[\"message_num\"] == first_reduction_msg:\n",
    "                    after_reduction = h[\"prompt_tokens\"]\n",
    "\n",
    "            if before_reduction and after_reduction:\n",
    "                reduction_amount = before_reduction - after_reduction\n",
    "                reduction_percent = (reduction_amount / before_reduction * 100)\n",
    "                print(f\"\\nüîÑ Actual Reduction Impact:\")\n",
    "                print(f\"Prompt tokens before reduction: {before_reduction:,}\")\n",
    "                print(f\"Prompt tokens after reduction: {after_reduction:,}\")\n",
    "                print(\n",
    "                    f\"Tokens saved: {reduction_amount:,} ({reduction_percent:.1f}%)\")\n",
    "\n",
    "# Display function for clean output\n",
    "\n",
    "\n",
    "def display_message(role: str, content: str, color: str = \"#2E8B57\"):\n",
    "    \"\"\"Display a message with nice formatting that works in both light and dark themes\"\"\"\n",
    "    # Use a semi-transparent background that adapts to the theme\n",
    "    html = f\"\"\"\n",
    "    <div style='\n",
    "        margin: 10px 0; \n",
    "        padding: 12px 15px; \n",
    "        border-left: 4px solid {color}; \n",
    "        background: rgba(128, 128, 128, 0.1); \n",
    "        border-radius: 4px;\n",
    "        color: inherit;\n",
    "    '>\n",
    "        <strong style='color: {color}; font-size: 14px;'>{role}:</strong><br>\n",
    "        <div style='margin-top: 8px; white-space: pre-wrap; color: inherit; font-size: 14px;'>{content}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "# Initialize token tracker\n",
    "token_tracker = TokenTracker()\n",
    "print(\"üìä Token tracking initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§∏‡•Å‡§ü‡•ç‡§ü‡•Ä ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§ö‡§æ‡§≤‡§µ‡§æ\n",
    "\n",
    "‡§Ü‡§§‡§æ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§ö‡§æ‡§≤‡§µ‡•Ç‡§Ø‡§æ ‡§ú‡•ç‡§Ø‡§æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§¶‡§æ‡§ñ‡§µ‡§≤‡•á ‡§Ü‡§π‡•á:\n",
    "1. ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§®‡§ø‡§Ø‡•ã‡§ú‡§® ‡§µ‡§ø‡§®‡§Ç‡§§‡•Ä\n",
    "2. ‡§™‡•ç‡§∞‡§æ‡§ß‡§æ‡§®‡•ç‡§Ø ‡§ó‡•ã‡§≥‡§æ ‡§ï‡§∞‡§£‡•á\n",
    "3. ‡§™‡•ç‡§∞‡§µ‡§æ‡§∏‡§æ‡§ö‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§£‡•á\n",
    "4. ‡§∏‡•ç‡§•‡§æ‡§® ‡§¨‡§¶‡§≤\n",
    "5. ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•á\n",
    "6. ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conversation flow\n",
    "user_inputs = [\n",
    "    \"I'm thinking about planning a vacation. Can you help me?\",\n",
    "    \"I love beach destinations with great food and culture. I enjoy water sports, exploring local markets, and trying authentic cuisine. My budget is around $3000 per person for a week.\",\n",
    "    \"That sounds perfect! Please create a detailed itinerary for Bali.\",\n",
    "    \"Actually, I've changed my mind. I'd prefer to go to the Greek islands instead. Can you create a new itinerary?\",\n",
    "    \"What's the weather like there?\",\n",
    "    \"What should I pack?\",\n",
    "    \"Are there any cultural customs I should know about?\",\n",
    "    \"What's the best way to get around?\"\n",
    "]\n",
    "\n",
    "\n",
    "async def run_vacation_planning():\n",
    "    \"\"\"Run the vacation planning conversation with token tracking and history reduction\"\"\"\n",
    "\n",
    "    # Create thread with history reducer\n",
    "    thread = ChatHistoryAgentThread(chat_history=history_reducer)\n",
    "    message_count = 0\n",
    "    scratchpad_operations = 0  # Track scratchpad usage\n",
    "\n",
    "    print(\"üöÄ Starting Vacation Planning Session\\n\")\n",
    "\n",
    "    # Process conversation\n",
    "    for i, user_input in enumerate(user_inputs):\n",
    "        message_count += 1\n",
    "        display_message(\"User\", user_input, \"#4fc3f7\")  # Blue for user\n",
    "\n",
    "        # Get agent response\n",
    "        full_response = \"\"\n",
    "        usage = None\n",
    "        function_calls = []  # Track function calls\n",
    "\n",
    "        async for response in agent.invoke(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            if response.content:\n",
    "                full_response += str(response.content)\n",
    "            if response.metadata.get(\"usage\"):\n",
    "                usage = response.metadata[\"usage\"]\n",
    "            thread = response.thread\n",
    "\n",
    "        display_message(f\"{agent.name}\", full_response,\n",
    "                        \"#81c784\")  # Green for agent\n",
    "\n",
    "        # Track tokens with thread length\n",
    "        if usage:\n",
    "            token_tracker.add_usage(usage, message_count, len(thread))\n",
    "\n",
    "        # Check thread status and look for scratchpad operations\n",
    "        print(f\"üìù Thread has {len(thread)} messages\")\n",
    "\n",
    "        # Count scratchpad operations in this turn\n",
    "        turn_scratchpad_ops = 0\n",
    "        async for msg in thread.get_messages():\n",
    "            if hasattr(msg, 'content') and msg.content:\n",
    "                content_str = str(msg.content)\n",
    "                if 'read_scratchpad' in content_str or 'update_scratchpad' in content_str:\n",
    "                    turn_scratchpad_ops += 1\n",
    "\n",
    "        if turn_scratchpad_ops > scratchpad_operations:\n",
    "            print(\n",
    "                f\"   üìù Scratchpad operations detected: {turn_scratchpad_ops - scratchpad_operations} new operations\")\n",
    "            scratchpad_operations = turn_scratchpad_ops\n",
    "\n",
    "        # Show message types for first message\n",
    "        if i == 0:\n",
    "            message_types = []\n",
    "            async for msg in thread.get_messages():\n",
    "                msg_type = msg.role.value if hasattr(\n",
    "                    msg.role, 'value') else str(msg.role)\n",
    "                message_types.append(msg_type)\n",
    "            print(f\"   Message types: {message_types[:10]}...\" if len(\n",
    "                message_types) > 10 else f\"   Message types: {message_types}\")\n",
    "\n",
    "        # Check if reduction should happen\n",
    "        if len(thread) > REDUCER_THRESHOLD:\n",
    "            print(\n",
    "                f\"   ‚ö†Ô∏è Thread length ({len(thread)}) exceeds threshold ({REDUCER_THRESHOLD})\")\n",
    "\n",
    "            # Attempt reduction\n",
    "            is_reduced = await thread.reduce()\n",
    "            if is_reduced:\n",
    "                print(\n",
    "                    f\"\\nüîÑ HISTORY REDUCED! Thread now has {len(thread)} messages\\n\")\n",
    "                token_tracker.mark_reduction(message_count + 1)\n",
    "\n",
    "                # Show summary if available\n",
    "                async for msg in thread.get_messages():\n",
    "                    if msg.metadata and msg.metadata.get(\"__summary__\"):\n",
    "                        display_message(\"System Summary\", str(\n",
    "                            msg.content), \"#ff6b6b\")\n",
    "                        break\n",
    "\n",
    "    # Display final token usage chart\n",
    "    print(\"\\n--- Token Usage Analysis ---\")\n",
    "    token_tracker.display_chart()\n",
    "\n",
    "    # Show final scratchpad contents\n",
    "    print(\"\\n--- Final Scratchpad Contents ---\")\n",
    "    scratchpad_contents = scratchpad_plugin.read_scratchpad()\n",
    "    display(Markdown(scratchpad_contents))\n",
    "\n",
    "    print(f\"\\nüìä Total scratchpad operations: {scratchpad_operations}\")\n",
    "\n",
    "    return thread\n",
    "\n",
    "# Run the conversation\n",
    "thread = await run_vacation_planning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡§æ‡§Ç‡§ö‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£\n",
    "\n",
    "‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§¶‡§∞‡§Æ‡•ç‡§Ø‡§æ‡§® ‡§ï‡§æ‡§Ø ‡§ò‡§°‡§≤‡•á ‡§§‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§ø‡§§ ‡§ï‡§∞‡•Ç‡§Ø‡§æ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token usage\n",
    "print(\"üìä Total Token Usage Summary\\n\")\n",
    "print(f\"Total Prompt Tokens: {token_tracker.total_usage.prompt_tokens:,}\")\n",
    "print(\n",
    "    f\"Total Completion Tokens: {token_tracker.total_usage.completion_tokens:,}\")\n",
    "print(\n",
    "    f\"Total Tokens Used: {token_tracker.total_usage.prompt_tokens + token_tracker.total_usage.completion_tokens:,}\")\n",
    "\n",
    "print(\"\\nüí° Note: The reduction impact is shown in the chart above.\")\n",
    "print(\"Look for the dramatic drop in prompt tokens after the REDUCTION marker.\")\n",
    "print(\"This shows how chat history summarization reduces the context size for future messages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á\n",
    "\n",
    "### 1. ‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•á\n",
    "- **‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§ ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ**: ‡§∏‡§Ç‡§¶‡•á‡§∂‡§æ‡§Ç‡§ö‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§†‡§∞‡§æ‡§µ‡•Ä‡§ï ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡•á‡§™‡•á‡§ï‡•ç‡§∑‡§æ ‡§ú‡§æ‡§∏‡•ç‡§§ ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§µ‡§∞ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§§‡•á\n",
    "- **‡§ü‡•ã‡§ï‡§® ‡§¨‡§ö‡§§**: ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™‡§£‡§æ‡§®‡§Ç‡§§‡§∞ ‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞‡§æ‡§§ ‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§ò‡§ü ‡§π‡•ã‡§§‡•á\n",
    "- **‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ü‡§ø‡§ï‡§µ‡§£‡•á**: ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∏‡§Ç‡§ï‡•ç‡§∑‡•á‡§™‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ü‡§ø‡§ï‡§µ‡§≤‡•Ä ‡§ú‡§æ‡§§‡•á\n",
    "\n",
    "### 2. ‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°‡§ö‡•á ‡§´‡§æ‡§Ø‡§¶‡•á\n",
    "- **‡§∏‡§§‡§§‡§ö‡•Ä ‡§∏‡•ç‡§Æ‡•É‡§§‡•Ä**: ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡§∏‡§Ç‡§§‡•Ä ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞‡§π‡•Ä ‡§ü‡§ø‡§ï‡•Ç‡§® ‡§∞‡§æ‡§π‡§§‡•á\n",
    "- **‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ü‡•ç‡§∞‡•Ö‡§ï‡§ø‡§Ç‡§ó**: ‡§è‡§ú‡§Ç‡§ü ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§Æ‡§æ‡§ö‡§æ ‡§®‡•ã‡§Ç‡§¶ ‡§†‡•á‡§µ‡§§‡•ã\n",
    "- **‡§â‡§§‡•ç‡§§‡§Æ ‡§Ö‡§®‡•Å‡§≠‡§µ**: ‡§™‡§∏‡§Ç‡§§‡•Ä ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§∏‡§æ‡§Ç‡§ó‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§ó‡§∞‡§ú ‡§®‡§æ‡§π‡•Ä\n",
    "\n",
    "### 3. ‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞‡§æ‡§ö‡•á ‡§®‡§Æ‡•Å‡§®‡•á\n",
    "- **‡§∞‡•á‡§ñ‡•Ä‡§Ø ‡§µ‡§æ‡§¢**: ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡§Ç‡§¶‡•á‡§∂‡§æ‡§∏‡•ã‡§¨‡§§ ‡§ü‡•ã‡§ï‡§®‡§ö‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§µ‡§æ‡§¢‡§§‡•á\n",
    "- **‡§≤‡§ï‡•ç‡§∑‡§£‡•Ä‡§Ø ‡§ò‡§ü**: ‡§ï‡§Æ‡•Ä ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞ ‡§ü‡•ã‡§ï‡§®‡§ö‡•Ä ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§Æ‡•ã‡§†‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡§æ‡§§ ‡§ï‡§Æ‡•Ä ‡§π‡•ã‡§§‡•á\n",
    "- **‡§∂‡§æ‡§∂‡•ç‡§µ‡§§ ‡§∏‡§Ç‡§µ‡§æ‡§¶**: ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡•á‡§§ ‡§¶‡•Ä‡§∞‡•ç‡§ò ‡§∏‡§Ç‡§µ‡§æ‡§¶ ‡§∏‡§æ‡§ß‡§£‡•ç‡§Ø‡§æ‡§∏ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§¨‡§®‡§µ‡§§‡•á\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡§∏‡§æ‡§´‡§∏‡§´‡§æ‡§à\n",
    "\n",
    "‡§Ø‡§æ ‡§°‡•á‡§Æ‡•ã‡§¶‡§∞‡§Æ‡•ç‡§Ø‡§æ‡§® ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡•á‡§≤‡•á‡§≤‡•Ä ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§´‡§æ‡§á‡§≤ ‡§∏‡§æ‡§´ ‡§ï‡§∞‡§æ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up the scratchpad file\n",
    "# Uncomment the next line to delete the scratchpad\n",
    "# Path(\"vacation_agent_scratchpad.md\").unlink(missing_ok=True)\n",
    "\n",
    "print(\"‚úÖ Demo complete! The scratchpad file 'vacation_agent_scratchpad.md' has been preserved for your review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂\n",
    "\n",
    "‡§Ö‡§≠‡§ø‡§®‡§Ç‡§¶‡§®! ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Ø‡§∂‡§∏‡•ç‡§µ‡•Ä‡§™‡§£‡•á ‡§™‡•ç‡§∞‡§ó‡§§ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ‡§Ç‡§∏‡§π AI ‡§è‡§ú‡§Ç‡§ü ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡•á‡§≤‡§æ ‡§Ü‡§π‡•á:\n",
    "\n",
    "## ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§æ‡§Ø ‡§∂‡§ø‡§ï‡§≤‡•á:\n",
    "- **‡§ö‡•Ö‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•á**: ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§Ç‡§ö‡•á ‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•Ç‡§® ‡§ü‡•ã‡§ï‡§® ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§£‡•á\n",
    "- **‡§è‡§ú‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§°**: ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§æ‡§ß‡§æ‡§®‡•ç‡§Ø‡•á ‡§Ü‡§£‡§ø ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§∏‡•ç‡§•‡§ø‡§∞ ‡§Æ‡•á‡§Æ‡§∞‡•Ä ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§£‡•á\n",
    "- **‡§ü‡•ã‡§ï‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®**: ‡§¶‡•Ä‡§∞‡•ç‡§ò ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ü‡•ã‡§ï‡§® ‡§µ‡§æ‡§™‡§∞ ‡§ü‡•ç‡§∞‡•Ö‡§ï ‡§ï‡§∞‡§£‡•á ‡§Ü‡§£‡§ø ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§ï‡§∞‡§£‡•á\n",
    "- **‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ü‡§ø‡§ï‡§µ‡§£‡•á**: ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§§‡§æ‡§®‡§æ ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§ï‡§æ‡§Ø‡§Æ ‡§†‡•á‡§µ‡§£‡•á\n",
    "\n",
    "## ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï-‡§ú‡§ó‡§æ‡§§‡•Ä‡§≤ ‡§â‡§™‡§Ø‡•ã‡§ó:\n",
    "- **‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§¨‡•â‡§ü‡•ç‡§∏**: ‡§∏‡§§‡•ç‡§∞‡§æ‡§Ç‡§¶‡§∞‡§Æ‡•ç‡§Ø‡§æ‡§® ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§æ‡§ß‡§æ‡§®‡•ç‡§Ø‡•á ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§£‡•á\n",
    "- **‡§µ‡•à‡§Ø‡§ï‡•ç‡§§‡§ø‡§ï ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï**: ‡§ö‡§æ‡§≤‡•Ç ‡§™‡•ç‡§∞‡§ï‡§≤‡•ç‡§™ ‡§Ü‡§£‡§ø ‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡§µ‡§Ø‡•Ä‡§Ç‡§ö‡§æ ‡§Æ‡§æ‡§ó‡•ã‡§µ‡§æ ‡§†‡•á‡§µ‡§£‡•á\n",
    "- **‡§∂‡•à‡§ï‡•ç‡§∑‡§£‡§ø‡§ï ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï**: ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•Ä ‡§™‡•ç‡§∞‡§ó‡§§‡•Ä ‡§Ü‡§£‡§ø ‡§∂‡§ø‡§ï‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§æ‡§ß‡§æ‡§®‡•ç‡§Ø‡•á ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§£‡•á\n",
    "- **‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï**: ‡§ü‡•ã‡§ï‡§® ‡§Æ‡§∞‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡•Ç‡§® ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§Ç‡§ö‡§æ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ú‡§§‡§® ‡§ï‡§∞‡§£‡•á\n",
    "\n",
    "## ‡§™‡•Å‡§¢‡•Ä‡§≤ ‡§™‡§æ‡§µ‡§≤‡•á:\n",
    "- ‡§Ö‡§ß‡§ø‡§ï ‡§™‡•ç‡§∞‡§ó‡§§ ‡§∏‡•ç‡§ï‡•ç‡§∞‡•Ö‡§ö‡§™‡•Ö‡§° ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§æ\n",
    "- ‡§¨‡§π‡•Å-‡§µ‡§æ‡§™‡§∞‡§ï‡§∞‡•ç‡§§‡§æ ‡§™‡§∞‡§ø‡§∏‡•ç‡§•‡§ø‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§∏‡•ç‡§ü‡•ã‡§∞‡•á‡§ú ‡§ú‡•ã‡§°‡§æ\n",
    "- ‡§°‡•ã‡§Æ‡•á‡§®-‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§ó‡§∞‡§ú‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§∏‡§æ‡§®‡•Å‡§ï‡•Ç‡§≤ ‡§ï‡§Æ‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∞‡§£‡§®‡•Ä‡§§‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§æ\n",
    "- ‡§∏‡•á‡§Æ‡•Ö‡§Ç‡§ü‡§ø‡§ï ‡§Æ‡•á‡§Æ‡§∞‡•Ä ‡§∂‡•ã‡§ß‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡•ç‡§π‡•á‡§ï‡•ç‡§ü‡§∞ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏‡§∏‡§π ‡§è‡§ï‡§§‡•ç‡§∞ ‡§ï‡§∞‡§æ\n",
    "- ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠‡§æ‡§∏‡§π ‡§ï‡§æ‡§π‡•Ä ‡§¶‡§ø‡§µ‡§∏‡§æ‡§Ç‡§®‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§∏‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§£‡§æ‡§∞‡•á ‡§è‡§ú‡§Ç‡§ü ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§æ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  \n‡§π‡§æ ‡§¶‡§∏‡•ç‡§§‡§ê‡§µ‡§ú AI ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∞‡•Ç‡§® ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡§æ ‡§Ü‡§π‡•á. ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§Ö‡§ö‡•Ç‡§ï‡§§‡•á‡§∏‡§æ‡§†‡•Ä ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§®‡§∂‡•Ä‡§≤ ‡§Ö‡§∏‡§≤‡•ã ‡§§‡§∞‡•Ä, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§ò‡•ç‡§Ø‡§æ ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§ ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§ö‡•Ç‡§ï‡§§‡•á‡§ö‡§æ ‡§Ö‡§≠‡§æ‡§µ ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•ã. ‡§Æ‡•Ç‡§≥ ‡§≠‡§æ‡§∑‡•á‡§§‡•Ä‡§≤ ‡§¶‡§∏‡•ç‡§§‡§ê‡§µ‡§ú ‡§π‡§æ ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§≤‡§æ ‡§ú‡§æ‡§µ‡§æ. ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡§æ‡§®‡§µ‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§ö‡•Ä ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§§‡•á. ‡§Ø‡§æ ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§Æ‡•Å‡§≥‡•á ‡§â‡§¶‡•ç‡§≠‡§µ‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä ‡§ó‡•à‡§∞‡§∏‡§Æ‡§ú ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§ö‡•Å‡§ï‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§Ö‡§∞‡•ç‡§•‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞ ‡§∞‡§æ‡§π‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9f75bedd745f507daf46d809cd6e2795",
   "translation_date": "2025-09-04T10:44:44+00:00",
   "source_file": "12-context-engineering/code_samples/12-chat_summarization.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}