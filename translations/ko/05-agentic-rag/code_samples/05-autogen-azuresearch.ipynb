{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autogen을 활용한 Azure AI 서비스 기반 Agentic RAG\n",
    "\n",
    "이 노트북은 향상된 평가 기능을 갖춘 Autogen 에이전트를 사용하여 검색 증강 생성(RAG)을 구현하는 방법을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "from typing import List, Dict\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클라이언트 생성\n",
    "\n",
    "먼저 Azure AI Chat Completion 클라이언트를 초기화합니다. 이 클라이언트는 사용자 질문에 대한 응답을 생성하기 위해 Azure OpenAI 서비스를 활용하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 초기화\n",
    "\n",
    "Azure AI Search를 영구 저장소와 함께 초기화하고 향상된 샘플 문서를 추가합니다. Azure AI Search는 문서를 저장하고 검색하여 정확한 응답을 생성하는 데 필요한 컨텍스트를 제공합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.search.documents._generated.models._models_py3.IndexingResult at 0x2299c1b8200>,\n",
       " <azure.search.documents._generated.models._models_py3.IndexingResult at 0x2299c1b9d90>,\n",
       " <azure.search.documents._generated.models._models_py3.IndexingResult at 0x2299c1b9bb0>,\n",
       " <azure.search.documents._generated.models._models_py3.IndexingResult at 0x2299c1b9d00>,\n",
       " <azure.search.documents._generated.models._models_py3.IndexingResult at 0x2299c1b9c70>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Azure AI Search with persistent storage\n",
    "search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "search_api_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = \"travel-documents\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_service_endpoint,\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# Define the index schema\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String)\n",
    "]\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "\n",
    "# Create the index\n",
    "index_client.create_index(index)\n",
    "\n",
    "# Enhanced sample documents\n",
    "documents = [\n",
    "    {\"id\": \"1\", \"content\": \"Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\"},\n",
    "    {\"id\": \"2\", \"content\": \"Our premium travel services include personalized itinerary planning and 24/7 concierge support.\"},\n",
    "    {\"id\": \"3\", \"content\": \"Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\"},\n",
    "    {\"id\": \"4\", \"content\": \"Popular destinations include the Maldives, Swiss Alps, and African safaris.\"},\n",
    "    {\"id\": \"5\", \"content\": \"Contoso Travel provides exclusive access to boutique hotels and private guided tours.\"}\n",
    "]\n",
    "\n",
    "# Add documents to the index\n",
    "search_client.upload_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_context(query: str) -> str:\n",
    "    results = search_client.search(query)\n",
    "    context_strings = []\n",
    "    for result in results:\n",
    "        context_strings.append(f\"Document: {result['content']}\")\n",
    "    return \"\\n\\n\".join(context_strings) if context_strings else \"No results found\"\n",
    "\n",
    "def get_weather_data(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates retrieving weather data for a given location.\n",
    "    In a real-world scenario, this would call a weather API.\n",
    "    \"\"\"\n",
    "    # Simulated weather data for common locations\n",
    "    weather_database = {\n",
    "        \"new york\": {\"temperature\": 72, \"condition\": \"Partly Cloudy\", \"humidity\": 65, \"wind\": \"10 mph\"},\n",
    "        \"london\": {\"temperature\": 60, \"condition\": \"Rainy\", \"humidity\": 80, \"wind\": \"15 mph\"},\n",
    "        \"tokyo\": {\"temperature\": 75, \"condition\": \"Sunny\", \"humidity\": 50, \"wind\": \"5 mph\"},\n",
    "        \"sydney\": {\"temperature\": 80, \"condition\": \"Clear\", \"humidity\": 45, \"wind\": \"12 mph\"},\n",
    "        \"paris\": {\"temperature\": 68, \"condition\": \"Cloudy\", \"humidity\": 70, \"wind\": \"8 mph\"},\n",
    "    }\n",
    "    \n",
    "    # Normalize the location string\n",
    "    location_key = location.lower()\n",
    "    \n",
    "    # Check if we have data for this location\n",
    "    if location_key in weather_database:\n",
    "        data = weather_database[location_key]\n",
    "        return f\"Weather for {location.title()}:\\n\" \\\n",
    "               f\"Temperature: {data['temperature']}°F\\n\" \\\n",
    "               f\"Condition: {data['condition']}\\n\" \\\n",
    "               f\"Humidity: {data['humidity']}%\\n\" \\\n",
    "               f\"Wind: {data['wind']}\"\n",
    "    else:\n",
    "        return f\"No weather data available for {location}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에이전트 구성\n",
    "\n",
    "우리는 검색 에이전트와 어시스턴트 에이전트를 구성합니다. 검색 에이전트는 시맨틱 검색을 사용하여 관련 정보를 찾는 데 특화되어 있으며, 어시스턴트는 검색된 정보를 바탕으로 상세한 응답을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with enhanced capabilities\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    system_message=(\n",
    "        \"You are a helpful AI assistant that provides answers using ONLY the provided context. \"\n",
    "        \"Do NOT include any external information. Base your answer entirely on the context given below.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGEvaluator 클래스\n",
    "\n",
    "`RAGEvaluator` 클래스는 응답 길이, 출처 인용, 응답 시간, 문맥 적합성 등 다양한 지표를 기반으로 응답을 평가하기 위해 정의됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    def __init__(self):\n",
    "        self.responses: List[Dict] = []\n",
    "\n",
    "    def evaluate_response(self, query: str, response: str, context: List[Dict]) -> Dict:\n",
    "        # Basic metrics: response length, citation count, and a simple relevance score.\n",
    "        start_time = time.time()\n",
    "        metrics = {\n",
    "            'response_length': len(response),\n",
    "            'source_citations': sum(1 for doc in context if doc[\"content\"] in response),\n",
    "            'evaluation_time': time.time() - start_time,\n",
    "            'context_relevance': self._calculate_relevance(query, context)\n",
    "        }\n",
    "        self.responses.append({\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        return metrics\n",
    "\n",
    "    def _calculate_relevance(self, query: str, context: List[Dict]) -> float:\n",
    "        # Simple relevance score: fraction of the documents where the query appears.\n",
    "        return sum(1 for c in context if query.lower() in c[\"content\"].lower()) / len(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG을 활용한 질의 처리\n",
    "\n",
    "`ask_rag` 함수는 질의를 어시스턴트에게 전달하고, 응답을 처리하며, 이를 평가하는 역할을 합니다. 이 함수는 어시스턴트와의 상호작용을 관리하며, 응답의 품질을 측정하기 위해 평가기를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_unified_rag(query: str, evaluator: RAGEvaluator, location: str = None):\n",
    "    \"\"\"\n",
    "    A unified RAG function that combines both document retrieval and weather data\n",
    "    based on the query and optional location parameter.\n",
    "    \n",
    "    Args:\n",
    "        query: The user's question\n",
    "        evaluator: The RAG evaluator to measure response quality\n",
    "        location: Optional location for weather queries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get context from both sources\n",
    "        retrieval_context = get_retrieval_context(query)\n",
    "        \n",
    "        # If location is provided, add weather data\n",
    "        weather_context = \"\"\n",
    "        if location:\n",
    "            weather_context = get_weather_data(location)\n",
    "            weather_intro = f\"\\nWeather Information for {location}:\\n\"\n",
    "        else:\n",
    "            weather_intro = \"\"\n",
    "        \n",
    "        # Augment the query with both contexts if available\n",
    "        augmented_query = (\n",
    "            f\"Retrieved Context:\\n{retrieval_context}\\n\\n\"\n",
    "            f\"{weather_intro}{weather_context}\\n\\n\"\n",
    "            f\"User Query: {query}\\n\\n\"\n",
    "            \"Based ONLY on the above context, please provide the answer.\"\n",
    "        )\n",
    "\n",
    "        # Send the augmented query as a user message\n",
    "        start_time = time.time()\n",
    "        response = await assistant.on_messages(\n",
    "            [TextMessage(content=augmented_query, source=\"user\")],\n",
    "            cancellation_token=CancellationToken(),\n",
    "        )\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        # Create combined context for evaluation\n",
    "        combined_context = documents.copy()  # Start with travel documents\n",
    "        \n",
    "        # Add weather as a document if it exists\n",
    "        if location and weather_context:\n",
    "            combined_context.append({\"id\": f\"weather-{location}\", \"content\": weather_context})\n",
    "        \n",
    "        # Evaluate the response\n",
    "        metrics = evaluator.evaluate_response(\n",
    "            query=query,\n",
    "            response=response.chat_message.content,\n",
    "            context=combined_context\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'response': response.chat_message.content,\n",
    "            'processing_time': processing_time,\n",
    "            'metrics': metrics,\n",
    "        }\n",
    "        \n",
    "        # Add location to result if provided\n",
    "        if location:\n",
    "            result['location'] = location\n",
    "            \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing unified query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 예시\n",
    "\n",
    "평가기를 초기화하고 처리 및 평가하려는 쿼리를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    evaluator = RAGEvaluator()\n",
    "    \n",
    "    # Define user queries similar to the Semantic Kernel example\n",
    "    user_inputs = [\n",
    "        # Travel-only queries\n",
    "        {\"query\": \"Can you explain Contoso's travel insurance coverage?\"},\n",
    "        \n",
    "        # Weather-only queries \n",
    "        {\"query\": \"What's the current weather condition in London?\", \"location\": \"london\"},\n",
    "        \n",
    "        # Combined queries\n",
    "        {\"query\": \"What is a good cold destination offered by Contoso and what is its temperature?\", \"location\": \"london\"},\n",
    "    ]\n",
    "    \n",
    "    print(\"Processing Queries:\")\n",
    "    for query_data in user_inputs:\n",
    "        query = query_data[\"query\"]\n",
    "        location = query_data.get(\"location\")\n",
    "        \n",
    "        if location:\n",
    "            print(f\"\\nProcessing Query for {location}: {query}\")\n",
    "        else:\n",
    "            print(f\"\\nProcessing Query: {query}\")\n",
    "        \n",
    "        # Get the RAG context for printing (similar to the Semantic Kernel example)\n",
    "        retrieval_context = get_retrieval_context(query)\n",
    "        weather_context = get_weather_data(location) if location else \"\"\n",
    "        \n",
    "        # Print the RAG context for transparency\n",
    "        print(\"\\n--- RAG Context ---\")\n",
    "        print(retrieval_context)\n",
    "        if weather_context:\n",
    "            print(f\"\\n--- Weather Context for {location} ---\")\n",
    "            print(weather_context)\n",
    "        print(\"-------------------\\n\")\n",
    "            \n",
    "        result = await ask_unified_rag(query, evaluator, location)\n",
    "        if result:\n",
    "            print(\"Response:\", result['response'])\n",
    "            print(\"\\nMetrics:\", result['metrics'])\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스크립트 실행하기\n",
    "\n",
    "스크립트가 인터랙티브 환경에서 실행 중인지 또는 일반 스크립트로 실행 중인지 확인한 후, 이에 따라 메인 함수를 실행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Queries:\n",
      "\n",
      "Processing Query: Can you explain Contoso's travel insurance coverage?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "Document: Our premium travel services include personalized itinerary planning and 24/7 concierge support.\n",
      "\n",
      "Document: Contoso Travel provides exclusive access to boutique hotels and private guided tours.\n",
      "\n",
      "Document: Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\n",
      "-------------------\n",
      "\n",
      "Response: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "Metrics: {'response_length': 92, 'source_citations': 1, 'evaluation_time': 0.0, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Processing Query for london: What's the current weather condition in London?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Popular destinations include the Maldives, Swiss Alps, and African safaris.\n",
      "\n",
      "--- Weather Context for london ---\n",
      "Weather for London:\n",
      "Temperature: 60°F\n",
      "Condition: Rainy\n",
      "Humidity: 80%\n",
      "Wind: 15 mph\n",
      "-------------------\n",
      "\n",
      "Response: The current weather condition in London is rainy.\n",
      "\n",
      "Metrics: {'response_length': 49, 'source_citations': 0, 'evaluation_time': 0.0, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Processing Query for london: What is a good cold destination offered by Contoso and what is its temperature?\n",
      "\n",
      "--- RAG Context ---\n",
      "Document: Contoso Travel provides exclusive access to boutique hotels and private guided tours.\n",
      "\n",
      "Document: Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\n",
      "\n",
      "Document: Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\n",
      "\n",
      "Document: Popular destinations include the Maldives, Swiss Alps, and African safaris.\n",
      "\n",
      "Document: Our premium travel services include personalized itinerary planning and 24/7 concierge support.\n",
      "\n",
      "--- Weather Context for london ---\n",
      "Weather for London:\n",
      "Temperature: 60°F\n",
      "Condition: Rainy\n",
      "Humidity: 80%\n",
      "Wind: 15 mph\n",
      "-------------------\n",
      "\n",
      "Response: A good cold destination offered by Contoso is the Swiss Alps. However, the temperature for this destination is not provided in the context.\n",
      "\n",
      "Metrics: {'response_length': 139, 'source_citations': 0, 'evaluation_time': 0.0, 'context_relevance': 0.0}\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if asyncio.get_event_loop().is_running():\n",
    "        await main()\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**면책 조항**:  \n이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서의 원어 버전을 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 책임을 지지 않습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "coopTranslator": {
   "original_hash": "4c444b552d38d312f9e39a18b31c5855",
   "translation_date": "2025-08-30T16:07:06+00:00",
   "source_file": "05-agentic-rag/code_samples/05-autogen-azuresearch.ipynb",
   "language_code": "ko"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}