{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Szemantikus Kernel\n",
    "\n",
    "Ebben a kódmintában a [Szemantikus Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) AI keretrendszert fogod használni egy alapvető ügynök létrehozásához.\n",
    "\n",
    "Ennek a mintának a célja, hogy bemutassa azokat a lépéseket, amelyeket később a további kódmintákban fogunk alkalmazni a különböző ügynöki minták megvalósításakor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importálja a szükséges Python csomagokat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Az ügyfél létrehozása\n",
    "\n",
    "Ebben a példában a [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) szolgáltatást fogjuk használni az LLM eléréséhez.\n",
    "\n",
    "Az `ai_model_id` értéke `gpt-4o-mini`. Próbálja meg megváltoztatni a modellt egy másikra, amely elérhető a GitHub Models piacterén, hogy lássa a különböző eredményeket.\n",
    "\n",
    "Ahhoz, hogy használni tudjuk az `Azure Inference SDK`-t, amelyet a GitHub Models `base_url`-jához használunk, a Semantic Kernel-en belül az `OpenAIChatCompletion` csatlakozót fogjuk alkalmazni. További [elérhető csatlakozók](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) is rendelkezésre állnak, amelyek lehetővé teszik a Semantic Kernel használatát más modell szolgáltatók esetében.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Az ügynök létrehozása\n",
    "\n",
    "Az alábbiakban létrehozzuk a `TravelAgent` nevű ügynököt.\n",
    "\n",
    "Ebben a példában nagyon egyszerű utasításokat használunk. Az utasításokat módosíthatod, hogy megnézd, hogyan reagál az ügynök eltérően.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Az ügynök futtatása\n",
    "\n",
    "Most futtathatjuk az ügynököt egy `ChatHistoryAgentThread` típusú szál definiálásával. Az ügynök invoke_stream `messages` kulcsszó argumentumában megadjuk a szükséges rendszerüzeneteket.\n",
    "\n",
    "Miután ezek definiálva lettek, létrehozunk egy `user_inputs`-ot, amelyet a felhasználó küld az ügynöknek. Ebben az esetben ezt az üzenetet állítottuk be: `Plan me a sunny vacation`.\n",
    "\n",
    "Nyugodtan változtasd meg ezt az üzenetet, hogy lásd, hogyan reagál az ügynök különböző módon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Felelősség kizárása**:  \nEz a dokumentum az AI fordítási szolgáltatás [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével lett lefordítva. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Fontos információk esetén javasolt professzionális, emberi fordítást igénybe venni. Nem vállalunk felelősséget semmilyen félreértésért vagy téves értelmezésért, amely a fordítás használatából eredhet.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T21:29:24+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "hu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}