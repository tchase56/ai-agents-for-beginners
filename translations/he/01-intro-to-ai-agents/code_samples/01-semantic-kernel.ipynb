{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ליבת סמנטיקה\n",
    "\n",
    "בדוגמת קוד זו, תשתמשו במסגרת ה-AI [Semantic Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) כדי ליצור סוכן בסיסי.\n",
    "\n",
    "מטרת הדוגמה הזו היא להציג את השלבים שבהם נשתמש בהמשך בדוגמאות קוד נוספות בעת יישום דפוסי סוכנות שונים.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ייבוא חבילות הפייתון הנדרשות\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import Annotated\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## יצירת הלקוח\n",
    "\n",
    "בדוגמה זו, נשתמש ב-[GitHub Models](https://aka.ms/ai-agents-beginners/github-models) לצורך גישה ל-LLM.\n",
    "\n",
    "ה-`ai_model_id` מוגדר כ-`gpt-4o-mini`. נסו לשנות את המודל למודל אחר הזמין בשוק של GitHub Models כדי לראות תוצאות שונות.\n",
    "\n",
    "כדי שנוכל להשתמש ב-`Azure Inference SDK` שמשמש עבור ה-`base_url` של GitHub Models, נשתמש במחבר `OpenAIChatCompletion` בתוך Semantic Kernel. ישנם גם [מחברים זמינים נוספים](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) לשימוש ב-Semantic Kernel עבור ספקי מודלים אחרים.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   \n",
    "\n",
    "# Define a sample plugin for the sample\n",
    "\n",
    "class DestinationsPlugin:\n",
    "    \"\"\"A List of Random Destinations for a vacation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # List of vacation destinations\n",
    "        self.destinations = [\n",
    "            \"Barcelona, Spain\",\n",
    "            \"Paris, France\",\n",
    "            \"Berlin, Germany\",\n",
    "            \"Tokyo, Japan\",\n",
    "            \"Sydney, Australia\",\n",
    "            \"New York, USA\",\n",
    "            \"Cairo, Egypt\",\n",
    "            \"Cape Town, South Africa\",\n",
    "            \"Rio de Janeiro, Brazil\",\n",
    "            \"Bali, Indonesia\"\n",
    "        ]\n",
    "        # Track last destination to avoid repeats\n",
    "        self.last_destination = None\n",
    "\n",
    "    @kernel_function(description=\"Provides a random vacation destination.\")\n",
    "    def get_random_destination(self) -> Annotated[str, \"Returns a random vacation destination.\"]:\n",
    "        # Get available destinations (excluding last one if possible)\n",
    "        available_destinations = self.destinations.copy()\n",
    "        if self.last_destination and len(available_destinations) > 1:\n",
    "            available_destinations.remove(self.last_destination)\n",
    "\n",
    "        # Select a random destination\n",
    "        destination = random.choice(available_destinations)\n",
    "\n",
    "        # Update the last destination\n",
    "        self.last_destination = destination\n",
    "\n",
    "        return destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## יצירת הסוכן\n",
    "\n",
    "כאן אנו יוצרים את הסוכן שנקרא `TravelAgent`.\n",
    "\n",
    "בדוגמה זו, אנו משתמשים בהוראות פשוטות מאוד. ניתן לשנות את ההוראות הללו כדי לראות כיצד הסוכן מגיב בצורה שונה.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service, \n",
    "    plugins=[DestinationsPlugin()],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"You are a helpful AI Agent that can help plan vacations for customers at random destinations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## הפעלת הסוכן\n",
    "\n",
    "כעת נוכל להפעיל את הסוכן על ידי הגדרת שרשור מסוג `ChatHistoryAgentThread`. כל הודעות מערכת נדרשות מסופקות כארגומנט `messages` במילת המפתח של `invoke_stream` של הסוכן.\n",
    "\n",
    "לאחר שהגדרנו זאת, אנו יוצרים `user_inputs`, שיהיה מה שהמשתמש שולח לסוכן. במקרה זה, הגדרנו את ההודעה ל-`Plan me a sunny vacation`.\n",
    "\n",
    "אתם מוזמנים לשנות את ההודעה כדי לראות כיצד הסוכן מגיב באופן שונה.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Create a new thread for the agent\n",
    "    # If no thread is provided, a new thread will be\n",
    "    # created and returned with the initial response\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Plan me a day trip.\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            # 5. Print the response\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(f\"{response}\", end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    # Clean up the thread\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**כתב ויתור**:  \nמסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "9faeec13969c8dff8a53f0933771d228",
   "translation_date": "2025-08-29T18:42:40+00:00",
   "source_file": "01-intro-to-ai-agents/code_samples/01-semantic-kernel.ipynb",
   "language_code": "he"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}