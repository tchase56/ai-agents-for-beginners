<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cdfd0acc8592c1af14f8637833450375",
  "translation_date": "2025-08-29T09:27:27+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "ur"
}
-->
# پروڈکشن میں AI ایجنٹس: مشاہدہ اور جانچ

[![پروڈکشن میں AI ایجنٹس](../../../translated_images/lesson-10-thumbnail.2b79a30773db093e0b4fb47aaa618069e0afb4745fad4836526cf51df87f9ac9.ur.png)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

جب AI ایجنٹس تجرباتی پروٹوٹائپس سے حقیقی دنیا کی ایپلیکیشنز میں منتقل ہوتے ہیں، تو ان کے رویے کو سمجھنے، ان کی کارکردگی کی نگرانی کرنے، اور ان کے نتائج کو منظم طریقے سے جانچنے کی صلاحیت اہم ہو جاتی ہے۔

## سیکھنے کے مقاصد

اس سبق کو مکمل کرنے کے بعد، آپ جان سکیں گے:
- ایجنٹ کے مشاہدے اور جانچ کے بنیادی تصورات
- ایجنٹس کی کارکردگی، لاگت، اور مؤثریت کو بہتر بنانے کی تکنیکیں
- اپنے AI ایجنٹس کو منظم طریقے سے کیسے اور کیا جانچنا ہے
- پروڈکشن میں AI ایجنٹس کو تعینات کرتے وقت لاگت کو کیسے کنٹرول کرنا ہے
- AutoGen کے ساتھ بنائے گئے ایجنٹس کو کیسے انسٹرومنٹ کرنا ہے

مقصد یہ ہے کہ آپ کو یہ علم فراہم کیا جائے کہ آپ اپنے "بلیک باکس" ایجنٹس کو شفاف، قابل انتظام، اور قابل اعتماد نظاموں میں تبدیل کر سکیں۔

_**نوٹ:** یہ ضروری ہے کہ محفوظ اور قابل اعتماد AI ایجنٹس کو تعینات کیا جائے۔ [قابل اعتماد AI ایجنٹس بنانا](./06-building-trustworthy-agents/README.md) سبق کو بھی دیکھیں۔_

## ٹریسز اور اسپینز

مشاہدے کے اوزار جیسے [Langfuse](https://langfuse.com/) یا [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) عام طور پر ایجنٹ کے رنز کو ٹریسز اور اسپینز کے طور پر ظاہر کرتے ہیں۔

- **ٹریس** ایک مکمل ایجنٹ کے کام کو شروع سے آخر تک ظاہر کرتا ہے (جیسے صارف کی درخواست کو ہینڈل کرنا)۔
- **اسپینز** ٹریس کے اندر انفرادی مراحل ہوتے ہیں (جیسے لینگویج ماڈل کو کال کرنا یا ڈیٹا حاصل کرنا)۔

![Langfuse میں ٹریس درخت](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

مشاہدے کے بغیر، ایک AI ایجنٹ "بلیک باکس" کی طرح محسوس ہو سکتا ہے - اس کی اندرونی حالت اور استدلال غیر واضح ہوتے ہیں، جس کی وجہ سے مسائل کی تشخیص یا کارکردگی کو بہتر بنانا مشکل ہو جاتا ہے۔ مشاہدے کے ساتھ، ایجنٹس "گلاس باکس" بن جاتے ہیں، جو شفافیت فراہم کرتے ہیں جو اعتماد پیدا کرنے اور یہ یقینی بنانے کے لیے ضروری ہے کہ وہ مطلوبہ طریقے سے کام کریں۔

## پروڈکشن ماحول میں مشاہدے کی اہمیت

AI ایجنٹس کو پروڈکشن ماحول میں منتقل کرنے سے نئے چیلنجز اور ضروریات سامنے آتی ہیں۔ مشاہدہ اب "اچھا ہو تو بہتر" کی بجائے ایک اہم صلاحیت بن جاتا ہے:

*   **ڈی بگنگ اور جڑ کی وجہ کا تجزیہ:** جب کوئی ایجنٹ ناکام ہو یا غیر متوقع نتیجہ پیدا کرے، تو مشاہدے کے اوزار ان غلطیوں کے ذرائع کی نشاندہی کے لیے ضروری ٹریسز فراہم کرتے ہیں۔ یہ خاص طور پر پیچیدہ ایجنٹس میں اہم ہے جو متعدد LLM کالز، ٹول انٹریکشنز، اور مشروط منطق شامل کر سکتے ہیں۔
*   **لیٹنسی اور لاگت کا انتظام:** AI ایجنٹس اکثر LLMs اور دیگر بیرونی APIs پر انحصار کرتے ہیں جو فی ٹوکن یا فی کال بل کیے جاتے ہیں۔ مشاہدہ ان کالز کو درست طریقے سے ٹریک کرنے کی اجازت دیتا ہے، جس سے ان آپریشنز کی نشاندہی ہوتی ہے جو غیر ضروری طور پر سست یا مہنگے ہیں۔ یہ ٹیموں کو پرامپٹس کو بہتر بنانے، زیادہ مؤثر ماڈلز منتخب کرنے، یا ورک فلو کو دوبارہ ڈیزائن کرنے کے قابل بناتا ہے تاکہ آپریشنل لاگت کا انتظام کیا جا سکے اور صارف کے تجربے کو یقینی بنایا جا سکے۔
*   **اعتماد، حفاظت، اور تعمیل:** بہت سی ایپلیکیشنز میں، یہ یقینی بنانا ضروری ہے کہ ایجنٹس محفوظ اور اخلاقی طور پر کام کریں۔ مشاہدہ ایجنٹ کے اعمال اور فیصلوں کا آڈٹ ٹریل فراہم کرتا ہے۔ یہ پرامپٹ انجیکشن، نقصان دہ مواد کی تخلیق، یا ذاتی طور پر قابل شناخت معلومات (PII) کے غلط استعمال جیسے مسائل کا پتہ لگانے اور ان کو کم کرنے کے لیے استعمال کیا جا سکتا ہے۔ مثال کے طور پر، آپ یہ سمجھنے کے لیے ٹریسز کا جائزہ لے سکتے ہیں کہ ایجنٹ نے کسی خاص جواب یا ٹول کا استعمال کیوں کیا۔
*   **مسلسل بہتری کے لوپس:** مشاہدے کا ڈیٹا ایک تکراری ترقیاتی عمل کی بنیاد ہے۔ یہ دیکھ کر کہ ایجنٹس حقیقی دنیا میں کیسے کام کرتے ہیں، ٹیمیں بہتری کے شعبوں کی نشاندہی کر سکتی ہیں، ماڈلز کو بہتر بنانے کے لیے ڈیٹا اکٹھا کر سکتی ہیں، اور تبدیلیوں کے اثرات کی توثیق کر سکتی ہیں۔ یہ ایک فیڈ بیک لوپ بناتا ہے جہاں آن لائن جانچ سے حاصل کردہ پروڈکشن بصیرتیں آف لائن تجربات اور بہتری کو مطلع کرتی ہیں، جس سے ایجنٹ کی کارکردگی میں بتدریج اضافہ ہوتا ہے۔

## ٹریک کرنے کے لیے اہم میٹرکس

ایجنٹ کے رویے کی نگرانی اور سمجھنے کے لیے، مختلف میٹرکس اور سگنلز کو ٹریک کرنا ضروری ہے۔ اگرچہ مخصوص میٹرکس ایجنٹ کے مقصد پر منحصر ہو سکتے ہیں، کچھ عالمگیر اہمیت رکھتے ہیں۔

یہاں کچھ عام میٹرکس ہیں جن کی مشاہدے کے اوزار نگرانی کرتے ہیں:

**لیٹنسی:** ایجنٹ کتنی جلدی جواب دیتا ہے؟ طویل انتظار کے اوقات صارف کے تجربے پر منفی اثر ڈالتے ہیں۔ آپ کو ایجنٹ کے رنز کو ٹریس کرکے کاموں اور انفرادی مراحل کے لیے لیٹنسی کی پیمائش کرنی چاہیے۔ مثال کے طور پر، ایک ایجنٹ جو تمام ماڈل کالز کے لیے 20 سیکنڈ لیتا ہے، اسے تیز ماڈل استعمال کرکے یا ماڈل کالز کو متوازی طور پر چلا کر تیز کیا جا سکتا ہے۔

**لاگت:** فی ایجنٹ رن خرچ کیا ہے؟ AI ایجنٹس LLM کالز پر انحصار کرتے ہیں جو فی ٹوکن یا بیرونی APIs پر بل کیے جاتے ہیں۔ بار بار ٹول کا استعمال یا متعدد پرامپٹس تیزی سے لاگت میں اضافہ کر سکتے ہیں۔ مثال کے طور پر، اگر ایک ایجنٹ معمولی معیار کی بہتری کے لیے پانچ بار LLM کو کال کرتا ہے، تو آپ کو یہ اندازہ لگانا ہوگا کہ آیا لاگت جائز ہے یا آپ کالز کی تعداد کو کم کر سکتے ہیں یا سستا ماڈل استعمال کر سکتے ہیں۔ حقیقی وقت کی نگرانی غیر متوقع اسپائکس کی نشاندہی کرنے میں بھی مدد کر سکتی ہے (مثلاً، بگز جو ضرورت سے زیادہ API لوپس کا سبب بنتے ہیں)۔

**درخواست کی غلطیاں:** ایجنٹ نے کتنی درخواستیں ناکام کیں؟ اس میں API کی غلطیاں یا ناکام ٹول کالز شامل ہو سکتی ہیں۔ پروڈکشن میں ان کے خلاف اپنے ایجنٹ کو مزید مضبوط بنانے کے لیے، آپ فال بیکس یا ری ٹرائیز ترتیب دے سکتے ہیں۔ مثلاً، اگر LLM فراہم کنندہ A بند ہو، تو آپ بیک اپ کے طور پر LLM فراہم کنندہ B پر سوئچ کر سکتے ہیں۔

**صارف کی رائے:** براہ راست صارف کی تشخیصات قیمتی بصیرت فراہم کرتی ہیں۔ اس میں واضح درجہ بندی (👍تھمز اپ/👎ڈاؤن، ⭐1-5 ستارے) یا متنی تبصرے شامل ہو سکتے ہیں۔ مستقل منفی رائے آپ کو الرٹ کرنی چاہیے کیونکہ یہ اس بات کی علامت ہے کہ ایجنٹ توقع کے مطابق کام نہیں کر رہا۔

**غیر واضح صارف کی رائے:** صارف کے رویے بالواسطہ رائے فراہم کرتے ہیں، چاہے واضح درجہ بندی نہ ہو۔ اس میں فوری سوالات کی دوبارہ ترتیب، بار بار کی گئی درخواستیں یا ری ٹرائی بٹن پر کلک کرنا شامل ہو سکتا ہے۔ مثلاً، اگر آپ دیکھتے ہیں کہ صارفین بار بار ایک ہی سوال پوچھتے ہیں، تو یہ اس بات کی علامت ہے کہ ایجنٹ توقع کے مطابق کام نہیں کر رہا۔

**درستگی:** ایجنٹ کتنی بار درست یا مطلوبہ نتائج پیدا کرتا ہے؟ درستگی کی تعریف مختلف ہو سکتی ہے (مثلاً، مسئلہ حل کرنے کی درستگی، معلومات کی بازیافت کی درستگی، صارف کی اطمینان)۔ پہلا قدم یہ ہے کہ آپ کے ایجنٹ کے لیے کامیابی کی تعریف کی جائے۔ آپ خودکار چیکس، تشخیصی اسکورز، یا کام کی تکمیل کے لیبلز کے ذریعے درستگی کو ٹریک کر سکتے ہیں۔ مثال کے طور پر، ٹریسز کو "کامیاب" یا "ناکام" کے طور پر نشان زد کرنا۔

**خودکار تشخیصی میٹرکس:** آپ خودکار تشخیصات بھی ترتیب دے سکتے ہیں۔ مثال کے طور پر، آپ ایجنٹ کے آؤٹ پٹ کو اسکور کرنے کے لیے LLM استعمال کر سکتے ہیں، مثلاً یہ کہ آیا یہ مددگار، درست، یا نہیں۔ کئی اوپن سورس لائبریریاں بھی دستیاب ہیں جو ایجنٹ کے مختلف پہلوؤں کو اسکور کرنے میں مدد دیتی ہیں۔ مثلاً، [RAGAS](https://docs.ragas.io/) RAG ایجنٹس کے لیے یا [LLM Guard](https://llm-guard.com/) نقصان دہ زبان یا پرامپٹ انجیکشن کا پتہ لگانے کے لیے۔

عملی طور پر، ان میٹرکس کا مجموعہ AI ایجنٹ کی صحت کی بہترین کوریج فراہم کرتا ہے۔ اس باب کے [مثال نوٹ بک](./code_samples/10_autogen_evaluation.ipynb) میں، ہم آپ کو دکھائیں گے کہ یہ میٹرکس حقیقی مثالوں میں کیسے نظر آتے ہیں، لیکن پہلے ہم سیکھیں گے کہ ایک عام تشخیصی ورک فلو کیسا ہوتا ہے۔

## اپنے ایجنٹ کو انسٹرومنٹ کریں

ٹریسنگ ڈیٹا اکٹھا کرنے کے لیے، آپ کو اپنے کوڈ کو انسٹرومنٹ کرنا ہوگا۔ مقصد یہ ہے کہ ایجنٹ کے کوڈ کو اس طرح انسٹرومنٹ کیا جائے کہ وہ ٹریسز اور میٹرکس کو خارج کرے جنہیں مشاہدے کے پلیٹ فارم کے ذریعے پکڑا، پروسیس، اور بصری بنایا جا سکے۔

**اوپن ٹیلیمیٹری (OTel):** [اوپن ٹیلیمیٹری](https://opentelemetry.io/) LLM مشاہدے کے لیے ایک انڈسٹری اسٹینڈرڈ کے طور پر ابھرا ہے۔ یہ APIs، SDKs، اور ٹولز کا ایک سیٹ فراہم کرتا ہے جو ٹیلیمیٹری ڈیٹا کو جنریٹ، اکٹھا، اور ایکسپورٹ کرنے کے لیے استعمال ہوتا ہے۔

بہت سی انسٹرومنٹیشن لائبریریاں موجود ہیں جو موجودہ ایجنٹ فریم ورکس کو ریپ کرتی ہیں اور اوپن ٹیلیمیٹری اسپینز کو مشاہدے کے ٹول میں ایکسپورٹ کرنا آسان بناتی ہیں۔ نیچے ایک مثال دی گئی ہے کہ AutoGen ایجنٹ کو [OpenLit انسٹرومنٹیشن لائبریری](https://github.com/openlit/openlit) کے ساتھ کیسے انسٹرومنٹ کیا جائے:

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

اس باب کے [مثال نوٹ بک](./code_samples/10_autogen_evaluation.ipynb) میں، ہم آپ کو دکھائیں گے کہ اپنے AutoGen ایجنٹ کو کیسے انسٹرومنٹ کریں۔

**دستی اسپین تخلیق:** اگرچہ انسٹرومنٹیشن لائبریریاں ایک اچھا بنیاد فراہم کرتی ہیں، لیکن اکثر ایسے کیسز ہوتے ہیں جہاں مزید تفصیلی یا حسب ضرورت معلومات کی ضرورت ہوتی ہے۔ آپ دستی طور پر اسپینز تخلیق کر سکتے ہیں تاکہ حسب ضرورت ایپلیکیشن منطق شامل کی جا سکے۔ مزید اہم بات یہ ہے کہ آپ خودکار یا دستی طور پر تخلیق کردہ اسپینز کو حسب ضرورت صفات (جنہیں ٹیگز یا میٹا ڈیٹا بھی کہا جاتا ہے) کے ساتھ افزودہ کر سکتے ہیں۔ ان صفات میں کاروباری مخصوص ڈیٹا، درمیانی حسابات، یا کوئی بھی سیاق و سباق شامل ہو سکتا ہے جو ڈی بگنگ یا تجزیہ کے لیے مفید ہو، جیسے `user_id`، `session_id`، یا `model_version`۔

[Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3) کے ساتھ دستی طور پر ٹریسز اور اسپینز تخلیق کرنے کی مثال:

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## ایجنٹ کی جانچ

مشاہدہ ہمیں میٹرکس فراہم کرتا ہے، لیکن جانچ وہ عمل ہے جس میں ان ڈیٹا کا تجزیہ کیا جاتا ہے (اور ٹیسٹ کیے جاتے ہیں) تاکہ یہ معلوم کیا جا سکے کہ AI ایجنٹ کتنی اچھی کارکردگی کا مظاہرہ کر رہا ہے اور اسے کیسے بہتر بنایا جا سکتا ہے۔ دوسرے الفاظ میں، ایک بار جب آپ کے پاس وہ ٹریسز اور میٹرکس ہوں، تو آپ ان کا استعمال ایجنٹ کا جائزہ لینے اور فیصلے کرنے کے لیے کیسے کرتے ہیں؟

باقاعدہ جانچ ضروری ہے کیونکہ AI ایجنٹس اکثر غیر متعین ہوتے ہیں اور ارتقاء پذیر ہو سکتے ہیں (اپ ڈیٹس یا ماڈل کے رویے میں تبدیلی کے ذریعے) – جانچ کے بغیر، آپ کو معلوم نہیں ہوگا کہ آیا آپ کا "سمارٹ ایجنٹ" واقعی اپنا کام اچھے طریقے سے کر رہا ہے یا اس کی کارکردگی خراب ہو گئی ہے۔

AI ایجنٹس کے لیے دو قسم کی جانچ ہوتی ہیں: **آن لائن جانچ** اور **آف لائن جانچ**۔ دونوں قیمتی ہیں اور ایک دوسرے کی تکمیل کرتے ہیں۔ ہم عام طور پر آف لائن جانچ سے شروع کرتے ہیں، کیونکہ یہ کسی بھی ایجنٹ کو تعینات کرنے سے پہلے کم از کم ضروری قدم ہے۔

### آف لائن جانچ

![Langfuse میں ڈیٹاسیٹ آئٹمز](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

یہ ایجنٹ کو ایک کنٹرول شدہ ماحول میں جانچنے کا عمل ہے، عام طور پر ٹیسٹ ڈیٹاسیٹس کا استعمال کرتے ہوئے، نہ کہ لائیو صارف کی درخواستوں کا۔ آپ ایسے منتخب کردہ ڈیٹاسیٹس استعمال کرتے ہیں جہاں آپ کو معلوم ہو کہ متوقع نتیجہ یا درست رویہ کیا ہے، اور پھر اپنے ایجنٹ کو ان پر چلاتے ہیں۔

مثال کے طور پر، اگر آپ نے ایک ریاضی کے لفظی مسئلے کے ایجنٹ کو بنایا ہے، تو آپ کے پاس 100 مسائل کے [ٹیسٹ ڈیٹاسیٹ](https://huggingface.co/datasets/gsm8k) ہو سکتے ہیں جن کے جوابات معلوم ہیں۔ آف لائن جانچ اکثر ترقی کے دوران کی جاتی ہے (اور CI/CD پائپ لائنز کا حصہ ہو سکتی ہے) تاکہ بہتریوں کی جانچ کی جا سکے یا کارکردگی کی خرابیوں کے خلاف حفاظت کی جا سکے۔ اس کا فائدہ یہ ہے کہ یہ **دہرائی جا سکتی ہے اور آپ کو واضح درستگی کے میٹرکس مل سکتے ہیں کیونکہ آپ کے پاس گراؤنڈ ٹروتھ ہے**۔ آپ صارف کی درخواستوں کی نقل بھی کر سکتے ہیں اور ایجنٹ کے جوابات کو مثالی جوابات کے خلاف ماپ سکتے ہیں یا اوپر بیان کردہ خودکار میٹرکس کا استعمال کر سکتے ہیں۔

آف لائن جانچ کے ساتھ کلیدی چیلنج یہ ہے کہ یہ یقینی بنانا کہ آپ کا ٹیسٹ ڈیٹاسیٹ جامع اور متعلقہ رہے – ایجنٹ ایک مقررہ ٹیسٹ سیٹ پر اچھی کارکردگی کا مظاہرہ کر سکتا ہے لیکن پروڈکشن میں بہت مختلف درخواستوں کا سامنا کر سکتا ہے۔ لہذا، آپ کو نئے ایج کیسز اور حقیقی دنیا کے منظرناموں کی عکاسی کرنے والی مثالوں کے ساتھ ٹیسٹ سیٹس کو اپ ڈیٹ رکھنا چاہیے۔ چھوٹے "اسموک ٹیسٹ" کیسز اور بڑے جانچ سیٹس کا امتزاج مفید ہے: فوری چیک کے لیے چھوٹے سیٹس اور وسیع کارکردگی کے میٹرکس کے لیے بڑے سیٹس۔

### آن لائن جانچ

![مشاہدے کے میٹرکس کا جائزہ](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

یہ ایجنٹ کو ایک لائیو، حقیقی دنیا کے ماحول میں جانچنے کا عمل ہے، یعنی پروڈکشن میں اصل استعمال کے دوران۔ آن لائن جانچ میں ایجنٹ کی کارکردگی کو حقیقی صارف کی تعاملات پر مسلسل نگرانی کرنا اور نتائج کا تجزیہ شامل ہے۔

مثال کے طور پر، آپ کامیابی کی شرح، صارف کی اطمینان کے اسکورز، یا لائیو ٹریفک پر دیگر میٹرکس کو ٹریک کر سکتے ہیں۔ آن لائن جانچ کا فائدہ یہ ہے کہ یہ **ایسی چیزوں کو پکڑتی ہے جن کی آپ لیب کے ماحول میں توقع نہیں کر سکتے** – آپ وقت کے ساتھ ماڈل کے انحراف کا مشاہدہ کر سکتے ہیں (اگر ایجنٹ کی مؤثریت ان پٹ پیٹرنز کے بدلنے کے ساتھ کم ہو جائے) اور غیر متوقع درخواستوں یا حالات کو پکڑ سکتے ہیں جو آپ کے ٹیسٹ ڈیٹا میں نہیں تھے۔ یہ اس بات کی حقیقی تصویر فراہم کرتا ہے کہ ایجنٹ جنگلی ماحول میں کیسے برتاؤ کرتا ہے۔

آن لائن جانچ میں اکثر بالواسطہ اور براہ راست صارف کی رائے اکٹھا کرنا شامل ہوتا ہے، جیسا کہ پہلے ذکر کیا گیا، اور ممکنہ طور پر شیڈو ٹیسٹس یا A/B ٹیسٹس چلانا (جہاں ایجنٹ کا نیا ورژن پرانے کے ساتھ موازنہ کرنے کے لیے متوازی طور پر چلتا ہے)۔ چیلنج یہ ہے کہ لائیو تعاملات کے لیے قابل اعتماد لیبلز یا اسکورز حاصل کرنا مشکل ہو سکتا ہے

## ایجنٹ کے مسائل کا حل

### عام مسائل اور ان کے حل

| مسئلہ | حل |
|-------|-----|
| ایجنٹ کی کارکردگی کمزور ہے | - ایجنٹ کے ورک فلو کو بہتر بنانے کے لیے ٹریسز اور میٹرکس کا استعمال کریں۔<br>- ایجنٹ کے پرامپٹس کو بہتر کریں تاکہ وہ زیادہ واضح اور مخصوص ہوں۔ |
| پیچیدہ کاموں کے لیے ماڈل کا انتخاب | - ایسے ماڈلز کا انتخاب کریں جو پیچیدہ کاموں کے لیے بہتر ہوں اور منصوبہ بندی میں مہارت رکھتے ہوں۔ |
| AI ایجنٹ کے ٹول کالز اچھی کارکردگی نہیں دے رہے | - ایجنٹ سسٹم کے باہر ٹول کے آؤٹ پٹ کو ٹیسٹ اور ویلیڈیٹ کریں۔<br>- ٹولز کے پیرامیٹرز، پرامپٹس، اور ناموں کو بہتر کریں۔ |
| ملٹی ایجنٹ سسٹم مستقل کارکردگی نہیں دے رہا | - ہر ایجنٹ کو دیے گئے پرامپٹس کو بہتر کریں تاکہ وہ ایک دوسرے سے واضح طور پر مختلف ہوں۔<br>- ایک "روٹنگ" یا کنٹرولر ایجنٹ کے ذریعے ہائرارکی سسٹم بنائیں تاکہ صحیح ایجنٹ کا انتخاب کیا جا سکے۔ |

ان مسائل کی نشاندہی زیادہ مؤثر طریقے سے کی جا سکتی ہے اگر آپ کے پاس مشاہدہ کرنے کے لیے مناسب ٹولز موجود ہوں۔ پہلے ذکر کیے گئے ٹریسز اور میٹرکس ایجنٹ ورک فلو میں مسائل کی درست جگہ کی نشاندہی کرنے میں مدد دیتے ہیں، جس سے ڈیبگنگ اور آپٹیمائزیشن زیادہ مؤثر ہو جاتی ہے۔

## اخراجات کا انتظام

AI ایجنٹس کو پروڈکشن میں ڈیپلائے کرنے کے اخراجات کو کم کرنے کے لیے درج ذیل حکمت عملیاں استعمال کریں:

**چھوٹے ماڈلز کا استعمال:** چھوٹے لینگویج ماڈلز (SLMs) کچھ ایجنٹک استعمال کے کیسز میں اچھی کارکردگی دے سکتے ہیں اور اخراجات کو نمایاں طور پر کم کر سکتے ہیں۔ جیسا کہ پہلے ذکر کیا گیا، ایک ایویلیویشن سسٹم بنانا جو کارکردگی کا موازنہ بڑے ماڈلز سے کرے، یہ سمجھنے کا بہترین طریقہ ہے کہ SLM آپ کے استعمال کے کیس میں کتنی اچھی کارکردگی دے گا۔ SLMs کو آسان کاموں جیسے کہ انٹینٹ کلاسفیکیشن یا پیرامیٹر ایکسٹریکشن کے لیے استعمال کریں، جبکہ پیچیدہ کاموں کے لیے بڑے ماڈلز محفوظ رکھیں۔

**روٹر ماڈل کا استعمال:** ایک اور حکمت عملی مختلف ماڈلز اور سائزز کا استعمال ہے۔ آپ LLM/SLM یا سرور لیس فنکشن استعمال کر سکتے ہیں تاکہ درخواستوں کو پیچیدگی کی بنیاد پر بہترین ماڈلز کی طرف روٹ کیا جا سکے۔ یہ اخراجات کو کم کرنے میں مدد دے گا اور صحیح کاموں پر کارکردگی کو یقینی بنائے گا۔ مثال کے طور پر، آسان سوالات کو چھوٹے، تیز ماڈلز کی طرف روٹ کریں، اور صرف پیچیدہ کاموں کے لیے مہنگے بڑے ماڈلز استعمال کریں۔

**ریسپانسز کو کیش کرنا:** عام درخواستوں اور کاموں کی نشاندہی کریں اور ان کے جوابات پہلے سے فراہم کریں تاکہ وہ آپ کے ایجنٹک سسٹم سے نہ گزریں۔ آپ ایک فلو بھی نافذ کر سکتے ہیں جو یہ شناخت کرے کہ درخواست کتنی حد تک آپ کے کیش کیے گئے جوابات سے ملتی جلتی ہے، اس کے لیے زیادہ بنیادی AI ماڈلز استعمال کریں۔ یہ حکمت عملی اکثر پوچھے جانے والے سوالات یا عام ورک فلو کے لیے اخراجات کو نمایاں طور پر کم کر سکتی ہے۔

## آئیے دیکھتے ہیں کہ یہ عملی طور پر کیسے کام کرتا ہے

اس سیکشن کے [مثال نوٹ بک](./code_samples/10_autogen_evaluation.ipynb) میں، ہم دیکھیں گے کہ مشاہدہ کرنے والے ٹولز کو ایجنٹ کی نگرانی اور ایویلیویشن کے لیے کیسے استعمال کیا جا سکتا ہے۔

### AI ایجنٹس کے بارے میں مزید سوالات؟

[Azure AI Foundry Discord](https://aka.ms/ai-agents/discord) میں شامل ہوں تاکہ دوسرے سیکھنے والوں سے ملاقات کریں، آفس آورز میں شرکت کریں، اور اپنے AI ایجنٹس کے سوالات کے جوابات حاصل کریں۔

## پچھلا سبق

[Metacognition Design Pattern](../09-metacognition/README.md)

## اگلا سبق

[Agentic Protocols](../11-agentic-protocols/README.md)

---

**ڈس کلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے پوری کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔