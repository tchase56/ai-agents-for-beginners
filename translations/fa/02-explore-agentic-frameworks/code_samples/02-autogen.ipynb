{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# نمونه ساده AutoGen\n",
    "\n",
    "در این نمونه کد، شما از چارچوب هوش مصنوعی [AutoGen](https://aka.ms/ai-agents/autogen) برای ایجاد یک عامل پایه استفاده خواهید کرد.\n",
    "\n",
    "هدف این نمونه این است که مراحل مورد نیاز را به شما نشان دهد که در نمونه‌های کد اضافی بعدی هنگام پیاده‌سازی الگوهای مختلف عامل‌محور استفاده خواهیم کرد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## وارد کردن بسته‌های مورد نیاز پایتون\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ایجاد کلاینت\n",
    "\n",
    "در این نمونه، از [مدل‌های GitHub](https://aka.ms/ai-agents-beginners/github-models) برای دسترسی به LLM استفاده خواهیم کرد.\n",
    "\n",
    "`model` به صورت `gpt-4o-mini` تعریف شده است. مدل را به یکی دیگر از مدل‌های موجود در بازار مدل‌های GitHub تغییر دهید تا نتایج مختلف را مشاهده کنید.\n",
    "\n",
    "به عنوان یک آزمایش سریع، فقط یک درخواست ساده اجرا می‌کنیم - `پایتخت فرانسه چیست؟`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تعریف عامل\n",
    "\n",
    "حالا که `client` را تنظیم کرده‌ایم و تأیید کرده‌ایم که به درستی کار می‌کند، بیایید یک `AssistantAgent` ایجاد کنیم. هر عامل می‌تواند دارای موارد زیر باشد:  \n",
    "**name** - یک نام کوتاه که در جریان‌های چندعاملی برای ارجاع به آن مفید خواهد بود.  \n",
    "**model_client** - کلاینتی که در مرحله قبلی ایجاد کردید.  \n",
    "**tools** - ابزارهایی که عامل می‌تواند برای انجام یک وظیفه از آن‌ها استفاده کند.  \n",
    "**system_message** - پیام سیستمی که وظیفه، رفتار و لحن LLM را تعریف می‌کند.  \n",
    "\n",
    "شما می‌توانید پیام سیستمی را تغییر دهید تا ببینید LLM چگونه پاسخ می‌دهد. ما در درس شماره ۴ به موضوع `tools` خواهیم پرداخت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## اجرای عامل\n",
    "\n",
    "تابع زیر عامل را اجرا می‌کند. ما از متد `on_message` برای به‌روزرسانی وضعیت عامل با پیام جدید استفاده می‌کنیم.\n",
    "\n",
    "در این مثال، وضعیت را با یک پیام جدید از کاربر که عبارت است از `\"برای من یک تعطیلات آفتابی عالی برنامه‌ریزی کن\"` به‌روزرسانی می‌کنیم.\n",
    "\n",
    "می‌توانید محتوای پیام را تغییر دهید تا ببینید مدل زبانی بزرگ (LLM) چگونه به شکل متفاوتی پاسخ می‌دهد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:09:33+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}