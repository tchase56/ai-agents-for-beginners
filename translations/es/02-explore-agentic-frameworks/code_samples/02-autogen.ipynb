{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestra Básica de AutoGen\n",
    "\n",
    "En este ejemplo de código, utilizarás el marco de trabajo de inteligencia artificial [AutoGen](https://aka.ms/ai-agents/autogen) para crear un agente básico.\n",
    "\n",
    "El objetivo de este ejemplo es mostrarte los pasos que luego utilizaremos en los ejemplos de código adicionales al implementar los diferentes patrones de agentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los paquetes de Python necesarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear el Cliente\n",
    "\n",
    "En este ejemplo, usaremos [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) para acceder al LLM.\n",
    "\n",
    "El `model` está definido como `gpt-4o-mini`. Intenta cambiar el modelo a otro disponible en el mercado de GitHub Models para ver diferentes resultados.\n",
    "\n",
    "Como una prueba rápida, simplemente ejecutaremos un prompt sencillo: `¿Cuál es la capital de Francia?`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.getenv(\"GITHUB_TOKEN\")),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo el Agente\n",
    "\n",
    "Ahora que hemos configurado el `client` y confirmado que está funcionando, vamos a crear un `AssistantAgent`. A cada agente se le puede asignar:  \n",
    "**name** - Un nombre corto que será útil para referenciarlo en flujos con múltiples agentes.  \n",
    "**model_client** - El cliente que creaste en el paso anterior.  \n",
    "**tools** - Herramientas disponibles que el Agente puede usar para completar una tarea.  \n",
    "**system_message** - El metaprompt que define la tarea, el comportamiento y el tono del LLM.  \n",
    "\n",
    "Puedes cambiar el mensaje del sistema para ver cómo responde el LLM. Cubriremos `tools` en la Lección #4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[],\n",
    "    system_message=\"You are a travel agent that plans great vacations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar el Agente\n",
    "\n",
    "La función a continuación ejecutará el agente. Usamos el método `on_message` para actualizar el estado del Agente con el nuevo mensaje.\n",
    "\n",
    "En este caso, actualizamos el estado con un nuevo mensaje del usuario que es `\"Planéame unas excelentes vacaciones soleadas\"`.\n",
    "\n",
    "Puedes cambiar el contenido del mensaje para ver cómo responde de manera diferente el LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "async def assistant_run():\n",
    "    # Define the query\n",
    "    user_query = \"Plan me a great sunny vacation\"\n",
    "\n",
    "    # Start building HTML output\n",
    "    html_output = \"<div style='margin-bottom:10px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>User:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px'>{user_query}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Execute the agent response\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    # Add agent response to HTML\n",
    "    html_output += \"<div style='margin-bottom:20px'>\"\n",
    "    html_output += \"<div style='font-weight:bold'>Assistant:</div>\"\n",
    "    html_output += f\"<div style='margin-left:20px; white-space:pre-wrap'>{response.chat_message.content}</div>\"\n",
    "    html_output += \"</div>\"\n",
    "\n",
    "    # Display formatted HTML\n",
    "    display(HTML(html_output))\n",
    "\n",
    "# Run the function\n",
    "await assistant_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisión, tenga en cuenta que las traducciones automáticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "coopTranslator": {
   "original_hash": "aef8b2779015ef9099d6ee3cdacbb35d",
   "translation_date": "2025-08-30T16:09:05+00:00",
   "source_file": "02-explore-agentic-frameworks/code_samples/02-autogen.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}